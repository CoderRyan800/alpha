{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/ryan/venv/alpha/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn_entity_v1.py\n",
    "\n",
    "Initial version by R. Mukai 4 March 2018\n",
    "\n",
    "Updated version 24 December 2018.  This code is used for our\n",
    "initial paper on two cooperating agents with knowledge states\n",
    "solving a simple propositional logic problem.\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Bidirectional, TimeDistributed\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import load_model\n",
    "\n",
    "from nn_utils.problem_generator import *\n",
    "from nn_utils.string_and_array import *\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "\n",
    "class NN_Entity_1:\n",
    "\n",
    "    def __init__(self, id_number,\n",
    "                 initial_sentences = [],\n",
    "                 nn_file = None, data_set_file = None,\n",
    "                 gen_data_sets=True, start_training_epoch=0, max_training_epoch=1024, max_data_sets=64,\n",
    "                 num_instances=10000\n",
    "                 ):\n",
    "        self.DATA_PATH = DATA_PATH\n",
    "        # Create network if nn_file is None.  Otherwise\n",
    "        # just load existing network.\n",
    "\n",
    "        if nn_file is None:\n",
    "\n",
    "            self.generate_network(gen_data_sets, start_training_epoch, max_training_epoch, max_data_sets,\n",
    "                 num_instances)\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.model = load_model(nn_file)\n",
    "\n",
    "            # Now decide whether to use existing data\n",
    "            # if supplied or make new data set.\n",
    "\n",
    "            if data_set_file is not None:\n",
    "\n",
    "                fp = open('%s_X1.npy' % (data_set_file,), 'rb')\n",
    "                X = np.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s_Y1.npy' % (data_set_file,), 'rb')\n",
    "                Y1 = np.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s_Y2.npy' % (data_set_file,), 'rb')\n",
    "                Y2 = np.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s_one_hot_dictionary.pck' % (data_set_file,), 'rb')\n",
    "                one_hot_dictionary = pickle.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s_template_choices.pck' % (data_set_file,), 'rb')\n",
    "                template_choices = pickle.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s_question_template_list.pck' % (data_set_file,), 'rb')\n",
    "                question_template_list = pickle.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s_answer_template_list.pck' % (data_set_file,), 'rb')\n",
    "                answer_template_list = pickle.load(fp)\n",
    "                fp.close()\n",
    "\n",
    "                self.data_set={}\n",
    "\n",
    "                self.data_set['X'] = X\n",
    "                self.data_set['Y1'] = Y1\n",
    "                self.data_set['Y2'] = Y2\n",
    "                self.data_set['one_hot_dictionary'] = one_hot_dictionary\n",
    "                self.data_set['template_choices'] = template_choices\n",
    "                self.data_set['question_template_list'] = question_template_list\n",
    "                self.data_set['answer_template_list'] = answer_template_list\n",
    "\n",
    "                (b, self.m, self.n) = self.data_set['X'].shape\n",
    "\n",
    "            else:\n",
    "\n",
    "                template_list = return_simple_propositional_templates()\n",
    "\n",
    "                main_template_list = []\n",
    "\n",
    "                num_instances = 10000\n",
    "\n",
    "                num_templates = len(template_list)\n",
    "\n",
    "                template_error_scorecard = {}\n",
    "                for index in range(num_templates):\n",
    "                    template_error_scorecard[index] = [0, 0]\n",
    "\n",
    "                template_choices = []\n",
    "\n",
    "                for index in range(num_instances):\n",
    "                    random_index = np.random.randint(0, num_templates)\n",
    "                    template_choices.append(random_index)\n",
    "                    main_template_list.append(template_list[random_index])\n",
    "\n",
    "                result_list, X, Y, one_hot_dictionary = template_list_to_problem_set(num_vars=10,\n",
    "                                                                                     template_list=main_template_list)\n",
    "\n",
    "                data_set = {}\n",
    "                data_set['X'] = X\n",
    "                data_set['Y'] = Y\n",
    "                data_set['one_hot_dictionary'] = one_hot_dictionary\n",
    "                data_set['template_choices'] = template_choices\n",
    "\n",
    "                self.data_set = data_set\n",
    "\n",
    "                (b, self.m, self.n) = self.data_set['X'].shape\n",
    "\n",
    "            # End if-then logic for data set\n",
    "\n",
    "        # End if-then logic for making new network\n",
    "\n",
    "        # Set up an entity number for this entity.\n",
    "        # When referring to itself, it should use \"me\".\n",
    "        # When other entities refer to it, it should be\n",
    "        # \"n<entity_number>\", for example \"n7\" if entity\n",
    "        # number is 7.  Also, set up initial sentences this\n",
    "        # entity knows, if any.\n",
    "\n",
    "        self.entity_id_and_knowledge = {\n",
    "            'id_number' : id_number,\n",
    "            'id_string' : 'n'+str(id_number),\n",
    "            'sentence_list' : copy.deepcopy(initial_sentences)\n",
    "        }\n",
    "\n",
    "    # End initializer\n",
    "\n",
    "    def generate_network(self, gen_data_sets=True, start_training_epoch=0, max_training_epoch=1024, max_data_sets=64,\n",
    "                         num_instances = 10000):\n",
    "        template_list = return_simple_propositional_templates()\n",
    "\n",
    "        # Next, create the list of actual question and answer templates.\n",
    "\n",
    "        new_templates_distilled_question = []\n",
    "\n",
    "        new_templates_answer = []\n",
    "\n",
    "        num_template_repeats = 5\n",
    "\n",
    "        for template in template_list:\n",
    "\n",
    "            for index in range(template['max_instances']):\n",
    "                new_pair = create_problem_with_repetition(template, max_rep=3)\n",
    "\n",
    "                new_templates_distilled_question.append(new_pair[0])\n",
    "                new_templates_answer.append(new_pair[1])\n",
    "\n",
    "        # End loop\n",
    "\n",
    "        num_templates = len(new_templates_distilled_question)\n",
    "\n",
    "        template_error_scorecard = {}\n",
    "        for index in range(num_templates):\n",
    "            template_error_scorecard[index] = [0, 0, 0]\n",
    "\n",
    "        template_choices = []\n",
    "\n",
    "        if gen_data_sets:\n",
    "            for data_set_index in range(max_data_sets):\n",
    "\n",
    "                template_choices = []\n",
    "                question_template_list = []\n",
    "                answer_template_list = []\n",
    "\n",
    "                for index in range(num_instances):\n",
    "                    random_index = np.random.randint(0, num_templates)\n",
    "                    template_choices.append(random_index)\n",
    "                    question_template_list.append(new_templates_distilled_question[random_index])\n",
    "                    answer_template_list.append(new_templates_answer[random_index])\n",
    "\n",
    "                one_hot_dictionary = gen_one_hot_encoding(num_vars=10)\n",
    "\n",
    "                result_list_q, result_list_a, X1, Y1, Y2, one_hot_dictionary = ext_template_list_to_problem_set(num_vars=10,\n",
    "                                                                                                                template_list=(\n",
    "                                                                                                                question_template_list,\n",
    "                                                                                                                answer_template_list),\n",
    "                                                                                                                one_hot_dictionary=one_hot_dictionary)\n",
    "\n",
    "                data_set = {}\n",
    "                data_set['X'] = X1\n",
    "                data_set['Y1'] = Y1\n",
    "                data_set['Y2'] = Y2\n",
    "                data_set['one_hot_dictionary'] = one_hot_dictionary\n",
    "                data_set['template_choices'] = template_choices\n",
    "                data_set['question_template_list'] = question_template_list\n",
    "                data_set['answer_template_list'] = answer_template_list\n",
    "\n",
    "                fp = open('%s/data_set_%d_X1.npy' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                np.save(fp, X1)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s/data_set_%d_Y1.npy' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                np.save(fp, Y1)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s/data_set_%d_Y2.npy' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                np.save(fp, Y2)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s/data_set_%d_one_hot_dictionary.pck' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                pickle.dump(one_hot_dictionary, fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s/data_set_%d_template_choices.pck' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                pickle.dump(template_choices, fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s/data_set_%d_question_template_list.pck' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                pickle.dump(question_template_list, fp)\n",
    "                fp.close()\n",
    "\n",
    "                fp = open('%s/data_set_%d_answer_template_list.pck' % (self.DATA_PATH,data_set_index,), 'wb')\n",
    "                pickle.dump(answer_template_list, fp)\n",
    "                fp.close()\n",
    "\n",
    "            # End data set generator loop\n",
    "\n",
    "        # End data set generator code\n",
    "\n",
    "        if gen_data_sets:\n",
    "\n",
    "            (mx, nx) = X1[0].shape\n",
    "\n",
    "        else:\n",
    "            fp = open('%s/data_set_%d_X1.npy' % (self.DATA_PATH,0,), 'rb')\n",
    "            X1 = np.load(fp)\n",
    "            (mx, nx) = X1[0].shape\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_Y1.npy' % (self.DATA_PATH,0,), 'rb')\n",
    "            Y1 = np.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_Y2.npy' % (self.DATA_PATH,0,), 'rb')\n",
    "            Y2 = np.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_one_hot_dictionary.pck' % (self.DATA_PATH,0,), 'rb')\n",
    "            one_hot_dictionary = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_template_choices.pck' % (self.DATA_PATH,0,), 'rb')\n",
    "            template_choices = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_question_template_list.pck' % (self.DATA_PATH,0,), 'rb')\n",
    "            question_template_list = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_answer_template_list.pck' % (self.DATA_PATH,0,), 'rb')\n",
    "            answer_template_list = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "        if start_training_epoch == 0:\n",
    "\n",
    "            inputs = Input(shape=(None, nx))\n",
    "\n",
    "            x1 = LSTM(256, return_sequences=True)(inputs)\n",
    "\n",
    "            x2 = LSTM(256, return_sequences=True)(x1)\n",
    "\n",
    "            n_y1_batch, n_y1_timesteps, n_y1_size = Y1.shape\n",
    "\n",
    "            n_y2_batch, n_y2_timesteps, n_y2_size = Y2.shape\n",
    "\n",
    "            x3 = (Dense(Y1[0, 0].size))(x1)\n",
    "\n",
    "            y1 = Activation('softmax')(x3)\n",
    "\n",
    "            x4 = (Dense(Y1[0, 0].size))(x2)\n",
    "\n",
    "            y2 = Activation('softmax')(x4)\n",
    "\n",
    "            model = Model(inputs=inputs, outputs=[y1, y2])\n",
    "\n",
    "            model.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.save(\"%s/untrained_dual_output.h5\" % (self.DATA_PATH,))\n",
    "\n",
    "        else:\n",
    "\n",
    "            model = load_model(\"%s/trained_model_prop_new_%d.h5\" % (self.DATA_PATH,start_training_epoch-1,))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        for index in range(start_training_epoch, max_training_epoch):\n",
    "\n",
    "            data_set_index = np.random.randint(0, max_data_sets)\n",
    "\n",
    "            fp = open('%s/data_set_%d_X1.npy' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            X = np.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_Y1.npy' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            Y1 = np.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_Y2.npy' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            Y2 = np.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_one_hot_dictionary.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            one_hot_dictionary = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_one_hot_dictionary.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            one_hot_dictionary = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_template_choices.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            template_choices = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_question_template_list.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            question_template_list = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('%s/data_set_%d_answer_template_list.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "            answer_template_list = pickle.load(fp)\n",
    "            fp.close()\n",
    "\n",
    "            model.fit(X, [Y1, Y2], epochs=1, validation_split=0.2)\n",
    "            # model.fit(X, Y2, epochs=1, validation_split=0.2)\n",
    "\n",
    "            if index % 16 == 0:\n",
    "\n",
    "                model.save(\"%s/trained_model_prop_new_%d.h5\" % (self.DATA_PATH,index,))\n",
    "\n",
    "        [Y1_hat, Y2_hat] = model.predict(X)\n",
    "        # Y2_hat = model.predict(X1)\n",
    "\n",
    "        (b1, m1, n1) = Y1.shape\n",
    "\n",
    "        (b2, m2, n2) = Y2.shape\n",
    "\n",
    "        # Copy key data to self.\n",
    "\n",
    "        self.model = model\n",
    "        data_set = {}\n",
    "        data_set['X'] = X1\n",
    "        data_set['Y1'] = Y1\n",
    "        data_set['Y2'] = Y2\n",
    "        data_set['one_hot_dictionary'] = one_hot_dictionary\n",
    "        data_set['template_choices'] = template_choices\n",
    "        data_set['question_template_list'] = question_template_list\n",
    "        data_set['answer_template_list'] = answer_template_list\n",
    "        self.data_set = data_set\n",
    "\n",
    "        (b, self.m, self.n) = self.data_set['X'].shape\n",
    "\n",
    "        self.m1 = m1\n",
    "\n",
    "        self.n1 = n1\n",
    "\n",
    "        self.m2 = m2\n",
    "\n",
    "        self.n2 = n2\n",
    "        \n",
    "        self.test_on_data_set(0)\n",
    "\n",
    "    # End method generate_network\n",
    "\n",
    "    def test_on_data_set(self, data_set_index):\n",
    "\n",
    "        fp = open('%s/data_set_%d_X1.npy' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        X = np.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_Y1.npy' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        Y1 = np.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_Y2.npy' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        Y2 = np.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_one_hot_dictionary.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        one_hot_dictionary = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_one_hot_dictionary.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        one_hot_dictionary = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_template_choices.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        template_choices = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_question_template_list.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        question_template_list = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        fp = open('%s/data_set_%d_answer_template_list.pck' % (self.DATA_PATH,data_set_index,), 'rb')\n",
    "        answer_template_list = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        data_set = {}\n",
    "        data_set['X'] = X\n",
    "        data_set['Y1'] = Y1\n",
    "        data_set['Y2'] = Y2\n",
    "        data_set['one_hot_dictionary'] = one_hot_dictionary\n",
    "        data_set['template_choices'] = template_choices\n",
    "        data_set['question_template_list'] = question_template_list\n",
    "        data_set['answer_template_list'] = answer_template_list\n",
    "\n",
    "        \n",
    "        # Run regular evaluation too.\n",
    "        \n",
    "        evaluation_result = self.model.evaluate(X, [Y1, Y2])\n",
    "\n",
    "        return evaluation_result\n",
    "    # End method test_on_data_set\n",
    "    \n",
    "    def query_my_knowledge(self, item_to_query):\n",
    "\n",
    "        X = encode_string(item_to_query, self.data_set['one_hot_dictionary'])\n",
    "        (m, n) = X.shape\n",
    "        encoding_of_none = encode_string(None, self.data_set['one_hot_dictionary'])[0]\n",
    "        X_pad = np.ones((1, self.m, self.n)) * encoding_of_none\n",
    "        Y1_pad = np.ones((1, self.m, self.n)) * encoding_of_none\n",
    "        Y2_pad = np.ones((1, self.m, self.n)) * encoding_of_none\n",
    "        X_pad[0, :m, :] = X\n",
    "\n",
    "        x_check = np.sum(X_pad, 2)\n",
    "        y1_check = np.sum(Y1_pad, 2)\n",
    "        y2_check = np.sum(Y2_pad, 2)\n",
    "        [Y1_hat,Y2_hat] = self.model.predict(X_pad)\n",
    "\n",
    "        original_question = inverse_one_hot_dictionary(self.data_set['one_hot_dictionary'],\n",
    "                                                       X_pad[0, :, :])\n",
    "\n",
    "        network_answer_array1 = inverse_one_hot_dictionary(self.data_set['one_hot_dictionary'],\n",
    "                                                    Y1_hat[0, :, :])\n",
    "\n",
    "        network_answer_array2 = inverse_one_hot_dictionary(self.data_set['one_hot_dictionary'],\n",
    "                                                    Y2_hat[0, :, :])\n",
    "\n",
    "        network_answer_string1 = array_to_string(network_answer_array1)\n",
    "\n",
    "        network_answer_string2 = array_to_string(network_answer_array2)\n",
    "\n",
    "        return_dict = {\n",
    "            'original_question' : original_question,\n",
    "\n",
    "            'network_answer_array1': network_answer_array1,\n",
    "\n",
    "            'network_answer_string1': network_answer_string1,\n",
    "\n",
    "            'network_answer_array2' : network_answer_array2,\n",
    "\n",
    "            'network_answer_string2' : network_answer_string2,\n",
    "            'X' : X_pad,\n",
    "            'Y1' : Y1_hat,\n",
    "            'Y2' : Y2_hat\n",
    "        }\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    # End function query_my_knowledge\n",
    "\n",
    "    def add_knowledge(self, knowledge_sentence):\n",
    "\n",
    "        knowledge_sentence = knowledge_sentence.rstrip().lstrip()\n",
    "\n",
    "        self.entity_id_and_knowledge['sentence_list'].append(knowledge_sentence)\n",
    "\n",
    "    # End method add_knowledge\n",
    "\n",
    "    # Ask question method combines knowledge base with the question and then asks.\n",
    "\n",
    "    def ask_question(self, question):\n",
    "\n",
    "        combined_list = copy.deepcopy(self.entity_id_and_knowledge['sentence_list'])\n",
    "\n",
    "        combined_list.append(question)\n",
    "\n",
    "        data_string = \" . \".join(combined_list)\n",
    "\n",
    "        return_dict = self.query_my_knowledge(data_string)\n",
    "\n",
    "        regex_unknown = re.compile('unknown')\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    # End ask_question\n",
    "\n",
    "    def ask_question_remember_answer(self, question):\n",
    "\n",
    "        return_dict = self.ask_question(question)\n",
    "\n",
    "        regex_unknown = re.compile(\"unknown\")\n",
    "\n",
    "        if question != \"help\" and regex_unknown.search(return_dict['network_answer_string2']) is None:\n",
    "\n",
    "            self.add_knowledge(return_dict['network_answer_string2'])\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    # End method ask_question_remember_answer\n",
    "\n",
    "# End class declaration NN_Entity_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 22:21:27.510431 140600702248768 deprecation_wrapper.py:119] From /media/ryan/venv/alpha/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0924 22:21:31.213778 140600702248768 deprecation_wrapper.py:119] From /media/ryan/venv/alpha/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0924 22:21:31.249529 140600702248768 deprecation_wrapper.py:119] From /media/ryan/venv/alpha/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0924 22:21:31.898897 140600702248768 deprecation_wrapper.py:119] From /media/ryan/venv/alpha/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0924 22:21:31.911907 140600702248768 deprecation_wrapper.py:119] From /media/ryan/venv/alpha/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0924 22:21:32.069693 140600702248768 deprecation_wrapper.py:119] From /media/ryan/venv/alpha/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 65)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 256)    329728      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 256)    525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 65)     16705       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 65)     16705       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 65)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 65)     0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 888,450\n",
      "Trainable params: 888,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 22:21:45.597606 140600702248768 deprecation.py:323] From /media/ryan/venv/alpha/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7008 - activation_1_loss: 0.9543 - activation_2_loss: 0.7465 - activation_1_acc: 0.8304 - activation_2_acc: 0.8744 - val_loss: 0.9846 - val_activation_1_loss: 0.5661 - val_activation_2_loss: 0.4186 - val_activation_1_acc: 0.8589 - val_activation_2_acc: 0.8968\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.8825 - activation_1_loss: 0.5329 - activation_2_loss: 0.3496 - activation_1_acc: 0.8602 - activation_2_acc: 0.9096 - val_loss: 0.7802 - val_activation_1_loss: 0.4982 - val_activation_2_loss: 0.2820 - val_activation_1_acc: 0.8659 - val_activation_2_acc: 0.9127\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.6721 - activation_1_loss: 0.4288 - activation_2_loss: 0.2433 - activation_1_acc: 0.8809 - activation_2_acc: 0.9252 - val_loss: 0.5665 - val_activation_1_loss: 0.3644 - val_activation_2_loss: 0.2021 - val_activation_1_acc: 0.8976 - val_activation_2_acc: 0.9377\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.5259 - activation_1_loss: 0.3358 - activation_2_loss: 0.1901 - activation_1_acc: 0.9029 - activation_2_acc: 0.9378 - val_loss: 0.4942 - val_activation_1_loss: 0.3140 - val_activation_2_loss: 0.1802 - val_activation_1_acc: 0.9041 - val_activation_2_acc: 0.9388\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.4721 - activation_1_loss: 0.3001 - activation_2_loss: 0.1719 - activation_1_acc: 0.9068 - activation_2_acc: 0.9399 - val_loss: 0.5112 - val_activation_1_loss: 0.3231 - val_activation_2_loss: 0.1881 - val_activation_1_acc: 0.8959 - val_activation_2_acc: 0.9343\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.4255 - activation_1_loss: 0.2668 - activation_2_loss: 0.1587 - activation_1_acc: 0.9119 - activation_2_acc: 0.9425 - val_loss: 0.4056 - val_activation_1_loss: 0.2495 - val_activation_2_loss: 0.1561 - val_activation_1_acc: 0.9144 - val_activation_2_acc: 0.9437\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3881 - activation_1_loss: 0.2393 - activation_2_loss: 0.1487 - activation_1_acc: 0.9155 - activation_2_acc: 0.9442 - val_loss: 0.3741 - val_activation_1_loss: 0.2282 - val_activation_2_loss: 0.1459 - val_activation_1_acc: 0.9170 - val_activation_2_acc: 0.9446\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3716 - activation_1_loss: 0.2274 - activation_2_loss: 0.1441 - activation_1_acc: 0.9169 - activation_2_acc: 0.9451 - val_loss: 0.3803 - val_activation_1_loss: 0.2327 - val_activation_2_loss: 0.1476 - val_activation_1_acc: 0.9151 - val_activation_2_acc: 0.9446\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3733 - activation_1_loss: 0.2263 - activation_2_loss: 0.1469 - activation_1_acc: 0.9165 - activation_2_acc: 0.9443 - val_loss: 0.3674 - val_activation_1_loss: 0.2218 - val_activation_2_loss: 0.1456 - val_activation_1_acc: 0.9171 - val_activation_2_acc: 0.9436\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3633 - activation_1_loss: 0.2197 - activation_2_loss: 0.1436 - activation_1_acc: 0.9183 - activation_2_acc: 0.9452 - val_loss: 0.3566 - val_activation_1_loss: 0.2187 - val_activation_2_loss: 0.1378 - val_activation_1_acc: 0.9179 - val_activation_2_acc: 0.9472\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3524 - activation_1_loss: 0.2131 - activation_2_loss: 0.1393 - activation_1_acc: 0.9198 - activation_2_acc: 0.9465 - val_loss: 0.3474 - val_activation_1_loss: 0.2095 - val_activation_2_loss: 0.1379 - val_activation_1_acc: 0.9202 - val_activation_2_acc: 0.9465\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3444 - activation_1_loss: 0.2092 - activation_2_loss: 0.1353 - activation_1_acc: 0.9215 - activation_2_acc: 0.9483 - val_loss: 0.3427 - val_activation_1_loss: 0.2058 - val_activation_2_loss: 0.1369 - val_activation_1_acc: 0.9217 - val_activation_2_acc: 0.9471\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3396 - activation_1_loss: 0.2054 - activation_2_loss: 0.1341 - activation_1_acc: 0.9226 - activation_2_acc: 0.9483 - val_loss: 0.3454 - val_activation_1_loss: 0.2090 - val_activation_2_loss: 0.1364 - val_activation_1_acc: 0.9211 - val_activation_2_acc: 0.9471\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3372 - activation_1_loss: 0.2030 - activation_2_loss: 0.1342 - activation_1_acc: 0.9258 - activation_2_acc: 0.9484 - val_loss: 0.3298 - val_activation_1_loss: 0.1989 - val_activation_2_loss: 0.1309 - val_activation_1_acc: 0.9285 - val_activation_2_acc: 0.9496\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3326 - activation_1_loss: 0.1980 - activation_2_loss: 0.1346 - activation_1_acc: 0.9281 - activation_2_acc: 0.9490 - val_loss: 0.3291 - val_activation_1_loss: 0.1964 - val_activation_2_loss: 0.1327 - val_activation_1_acc: 0.9291 - val_activation_2_acc: 0.9501\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3233 - activation_1_loss: 0.1937 - activation_2_loss: 0.1297 - activation_1_acc: 0.9294 - activation_2_acc: 0.9515 - val_loss: 0.3162 - val_activation_1_loss: 0.1907 - val_activation_2_loss: 0.1254 - val_activation_1_acc: 0.9294 - val_activation_2_acc: 0.9531\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3151 - activation_1_loss: 0.1888 - activation_2_loss: 0.1264 - activation_1_acc: 0.9299 - activation_2_acc: 0.9524 - val_loss: 0.3149 - val_activation_1_loss: 0.1890 - val_activation_2_loss: 0.1259 - val_activation_1_acc: 0.9309 - val_activation_2_acc: 0.9530\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3108 - activation_1_loss: 0.1864 - activation_2_loss: 0.1244 - activation_1_acc: 0.9315 - activation_2_acc: 0.9536 - val_loss: 0.3058 - val_activation_1_loss: 0.1843 - val_activation_2_loss: 0.1215 - val_activation_1_acc: 0.9329 - val_activation_2_acc: 0.9551\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.3004 - activation_1_loss: 0.1831 - activation_2_loss: 0.1174 - activation_1_acc: 0.9322 - activation_2_acc: 0.9564 - val_loss: 0.2921 - val_activation_1_loss: 0.1783 - val_activation_2_loss: 0.1138 - val_activation_1_acc: 0.9324 - val_activation_2_acc: 0.9578\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2866 - activation_1_loss: 0.1754 - activation_2_loss: 0.1112 - activation_1_acc: 0.9349 - activation_2_acc: 0.9589 - val_loss: 0.2838 - val_activation_1_loss: 0.1743 - val_activation_2_loss: 0.1095 - val_activation_1_acc: 0.9362 - val_activation_2_acc: 0.9592\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2779 - activation_1_loss: 0.1719 - activation_2_loss: 0.1060 - activation_1_acc: 0.9367 - activation_2_acc: 0.9609 - val_loss: 0.2751 - val_activation_1_loss: 0.1725 - val_activation_2_loss: 0.1026 - val_activation_1_acc: 0.9363 - val_activation_2_acc: 0.9619\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2709 - activation_1_loss: 0.1676 - activation_2_loss: 0.1033 - activation_1_acc: 0.9388 - activation_2_acc: 0.9617 - val_loss: 0.2615 - val_activation_1_loss: 0.1624 - val_activation_2_loss: 0.0991 - val_activation_1_acc: 0.9408 - val_activation_2_acc: 0.9632\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2546 - activation_1_loss: 0.1587 - activation_2_loss: 0.0959 - activation_1_acc: 0.9423 - activation_2_acc: 0.9647 - val_loss: 0.2476 - val_activation_1_loss: 0.1536 - val_activation_2_loss: 0.0939 - val_activation_1_acc: 0.9445 - val_activation_2_acc: 0.9648\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2424 - activation_1_loss: 0.1508 - activation_2_loss: 0.0916 - activation_1_acc: 0.9448 - activation_2_acc: 0.9659 - val_loss: 0.2405 - val_activation_1_loss: 0.1509 - val_activation_2_loss: 0.0896 - val_activation_1_acc: 0.9446 - val_activation_2_acc: 0.9661\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2304 - activation_1_loss: 0.1447 - activation_2_loss: 0.0857 - activation_1_acc: 0.9468 - activation_2_acc: 0.9676 - val_loss: 0.2300 - val_activation_1_loss: 0.1412 - val_activation_2_loss: 0.0888 - val_activation_1_acc: 0.9474 - val_activation_2_acc: 0.9664\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2150 - activation_1_loss: 0.1337 - activation_2_loss: 0.0812 - activation_1_acc: 0.9500 - activation_2_acc: 0.9686 - val_loss: 0.2040 - val_activation_1_loss: 0.1278 - val_activation_2_loss: 0.0762 - val_activation_1_acc: 0.9520 - val_activation_2_acc: 0.9706\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.2005 - activation_1_loss: 0.1241 - activation_2_loss: 0.0764 - activation_1_acc: 0.9538 - activation_2_acc: 0.9700 - val_loss: 0.1924 - val_activation_1_loss: 0.1199 - val_activation_2_loss: 0.0725 - val_activation_1_acc: 0.9557 - val_activation_2_acc: 0.9712\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1915 - activation_1_loss: 0.1171 - activation_2_loss: 0.0744 - activation_1_acc: 0.9561 - activation_2_acc: 0.9708 - val_loss: 0.1833 - val_activation_1_loss: 0.1143 - val_activation_2_loss: 0.0690 - val_activation_1_acc: 0.9569 - val_activation_2_acc: 0.9726\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1765 - activation_1_loss: 0.1089 - activation_2_loss: 0.0676 - activation_1_acc: 0.9586 - activation_2_acc: 0.9732 - val_loss: 0.1600 - val_activation_1_loss: 0.0993 - val_activation_2_loss: 0.0607 - val_activation_1_acc: 0.9620 - val_activation_2_acc: 0.9756\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1646 - activation_1_loss: 0.1006 - activation_2_loss: 0.0641 - activation_1_acc: 0.9618 - activation_2_acc: 0.9747 - val_loss: 0.1632 - val_activation_1_loss: 0.1014 - val_activation_2_loss: 0.0618 - val_activation_1_acc: 0.9621 - val_activation_2_acc: 0.9758\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1535 - activation_1_loss: 0.0935 - activation_2_loss: 0.0600 - activation_1_acc: 0.9642 - activation_2_acc: 0.9762 - val_loss: 0.1418 - val_activation_1_loss: 0.0858 - val_activation_2_loss: 0.0560 - val_activation_1_acc: 0.9671 - val_activation_2_acc: 0.9771\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1418 - activation_1_loss: 0.0866 - activation_2_loss: 0.0552 - activation_1_acc: 0.9670 - activation_2_acc: 0.9781 - val_loss: 0.1287 - val_activation_1_loss: 0.0778 - val_activation_2_loss: 0.0509 - val_activation_1_acc: 0.9704 - val_activation_2_acc: 0.9794\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1374 - activation_1_loss: 0.0828 - activation_2_loss: 0.0547 - activation_1_acc: 0.9686 - activation_2_acc: 0.9783 - val_loss: 0.1339 - val_activation_1_loss: 0.0824 - val_activation_2_loss: 0.0515 - val_activation_1_acc: 0.9693 - val_activation_2_acc: 0.9791\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1250 - activation_1_loss: 0.0764 - activation_2_loss: 0.0486 - activation_1_acc: 0.9709 - activation_2_acc: 0.9803 - val_loss: 0.1183 - val_activation_1_loss: 0.0710 - val_activation_2_loss: 0.0473 - val_activation_1_acc: 0.9723 - val_activation_2_acc: 0.9806\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1152 - activation_1_loss: 0.0699 - activation_2_loss: 0.0453 - activation_1_acc: 0.9731 - activation_2_acc: 0.9818 - val_loss: 0.1188 - val_activation_1_loss: 0.0726 - val_activation_2_loss: 0.0462 - val_activation_1_acc: 0.9720 - val_activation_2_acc: 0.9812\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1122 - activation_1_loss: 0.0675 - activation_2_loss: 0.0447 - activation_1_acc: 0.9745 - activation_2_acc: 0.9821 - val_loss: 0.1282 - val_activation_1_loss: 0.0792 - val_activation_2_loss: 0.0490 - val_activation_1_acc: 0.9696 - val_activation_2_acc: 0.9808\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.1035 - activation_1_loss: 0.0627 - activation_2_loss: 0.0408 - activation_1_acc: 0.9757 - activation_2_acc: 0.9837 - val_loss: 0.1026 - val_activation_1_loss: 0.0618 - val_activation_2_loss: 0.0408 - val_activation_1_acc: 0.9765 - val_activation_2_acc: 0.9839\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0997 - activation_1_loss: 0.0607 - activation_2_loss: 0.0390 - activation_1_acc: 0.9764 - activation_2_acc: 0.9844 - val_loss: 0.0957 - val_activation_1_loss: 0.0580 - val_activation_2_loss: 0.0378 - val_activation_1_acc: 0.9776 - val_activation_2_acc: 0.9850\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0935 - activation_1_loss: 0.0569 - activation_2_loss: 0.0365 - activation_1_acc: 0.9781 - activation_2_acc: 0.9855 - val_loss: 0.1074 - val_activation_1_loss: 0.0653 - val_activation_2_loss: 0.0422 - val_activation_1_acc: 0.9751 - val_activation_2_acc: 0.9833\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0900 - activation_1_loss: 0.0547 - activation_2_loss: 0.0353 - activation_1_acc: 0.9788 - activation_2_acc: 0.9860 - val_loss: 0.0939 - val_activation_1_loss: 0.0563 - val_activation_2_loss: 0.0376 - val_activation_1_acc: 0.9784 - val_activation_2_acc: 0.9852\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0845 - activation_1_loss: 0.0513 - activation_2_loss: 0.0332 - activation_1_acc: 0.9799 - activation_2_acc: 0.9866 - val_loss: 0.0818 - val_activation_1_loss: 0.0488 - val_activation_2_loss: 0.0329 - val_activation_1_acc: 0.9805 - val_activation_2_acc: 0.9862\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0839 - activation_1_loss: 0.0511 - activation_2_loss: 0.0329 - activation_1_acc: 0.9804 - activation_2_acc: 0.9869 - val_loss: 0.0781 - val_activation_1_loss: 0.0470 - val_activation_2_loss: 0.0311 - val_activation_1_acc: 0.9817 - val_activation_2_acc: 0.9876\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0792 - activation_1_loss: 0.0481 - activation_2_loss: 0.0312 - activation_1_acc: 0.9815 - activation_2_acc: 0.9877 - val_loss: 0.0760 - val_activation_1_loss: 0.0457 - val_activation_2_loss: 0.0303 - val_activation_1_acc: 0.9830 - val_activation_2_acc: 0.9880\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0698 - activation_1_loss: 0.0424 - activation_2_loss: 0.0274 - activation_1_acc: 0.9835 - activation_2_acc: 0.9889 - val_loss: 0.0700 - val_activation_1_loss: 0.0417 - val_activation_2_loss: 0.0282 - val_activation_1_acc: 0.9837 - val_activation_2_acc: 0.9886\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0749 - activation_1_loss: 0.0444 - activation_2_loss: 0.0305 - activation_1_acc: 0.9828 - activation_2_acc: 0.9880 - val_loss: 0.0671 - val_activation_1_loss: 0.0397 - val_activation_2_loss: 0.0273 - val_activation_1_acc: 0.9844 - val_activation_2_acc: 0.9890\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0694 - activation_1_loss: 0.0423 - activation_2_loss: 0.0272 - activation_1_acc: 0.9837 - activation_2_acc: 0.9894 - val_loss: 0.0615 - val_activation_1_loss: 0.0369 - val_activation_2_loss: 0.0246 - val_activation_1_acc: 0.9856 - val_activation_2_acc: 0.9898\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0654 - activation_1_loss: 0.0392 - activation_2_loss: 0.0262 - activation_1_acc: 0.9848 - activation_2_acc: 0.9894 - val_loss: 0.0667 - val_activation_1_loss: 0.0407 - val_activation_2_loss: 0.0260 - val_activation_1_acc: 0.9845 - val_activation_2_acc: 0.9902\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0662 - activation_1_loss: 0.0398 - activation_2_loss: 0.0263 - activation_1_acc: 0.9851 - activation_2_acc: 0.9897 - val_loss: 0.0615 - val_activation_1_loss: 0.0369 - val_activation_2_loss: 0.0245 - val_activation_1_acc: 0.9861 - val_activation_2_acc: 0.9901\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0562 - activation_1_loss: 0.0336 - activation_2_loss: 0.0227 - activation_1_acc: 0.9869 - activation_2_acc: 0.9909 - val_loss: 0.0528 - val_activation_1_loss: 0.0313 - val_activation_2_loss: 0.0215 - val_activation_1_acc: 0.9875 - val_activation_2_acc: 0.9913\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0543 - activation_1_loss: 0.0324 - activation_2_loss: 0.0219 - activation_1_acc: 0.9874 - activation_2_acc: 0.9912 - val_loss: 0.0482 - val_activation_1_loss: 0.0291 - val_activation_2_loss: 0.0190 - val_activation_1_acc: 0.9886 - val_activation_2_acc: 0.9925\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0548 - activation_1_loss: 0.0326 - activation_2_loss: 0.0222 - activation_1_acc: 0.9872 - activation_2_acc: 0.9912 - val_loss: 0.0552 - val_activation_1_loss: 0.0332 - val_activation_2_loss: 0.0220 - val_activation_1_acc: 0.9871 - val_activation_2_acc: 0.9910\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0524 - activation_1_loss: 0.0306 - activation_2_loss: 0.0217 - activation_1_acc: 0.9882 - activation_2_acc: 0.9914 - val_loss: 0.0465 - val_activation_1_loss: 0.0280 - val_activation_2_loss: 0.0185 - val_activation_1_acc: 0.9891 - val_activation_2_acc: 0.9923\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0543 - activation_1_loss: 0.0322 - activation_2_loss: 0.0222 - activation_1_acc: 0.9876 - activation_2_acc: 0.9912 - val_loss: 0.0446 - val_activation_1_loss: 0.0268 - val_activation_2_loss: 0.0178 - val_activation_1_acc: 0.9892 - val_activation_2_acc: 0.9929\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0478 - activation_1_loss: 0.0286 - activation_2_loss: 0.0191 - activation_1_acc: 0.9887 - activation_2_acc: 0.9922 - val_loss: 0.0426 - val_activation_1_loss: 0.0253 - val_activation_2_loss: 0.0173 - val_activation_1_acc: 0.9900 - val_activation_2_acc: 0.9932\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0475 - activation_1_loss: 0.0283 - activation_2_loss: 0.0191 - activation_1_acc: 0.9889 - activation_2_acc: 0.9925 - val_loss: 0.0471 - val_activation_1_loss: 0.0289 - val_activation_2_loss: 0.0182 - val_activation_1_acc: 0.9889 - val_activation_2_acc: 0.9924\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0452 - activation_1_loss: 0.0267 - activation_2_loss: 0.0184 - activation_1_acc: 0.9896 - activation_2_acc: 0.9927 - val_loss: 0.0418 - val_activation_1_loss: 0.0251 - val_activation_2_loss: 0.0167 - val_activation_1_acc: 0.9899 - val_activation_2_acc: 0.9929\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0428 - activation_1_loss: 0.0256 - activation_2_loss: 0.0172 - activation_1_acc: 0.9901 - activation_2_acc: 0.9933 - val_loss: 0.0416 - val_activation_1_loss: 0.0246 - val_activation_2_loss: 0.0170 - val_activation_1_acc: 0.9900 - val_activation_2_acc: 0.9930\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0388 - activation_1_loss: 0.0228 - activation_2_loss: 0.0161 - activation_1_acc: 0.9910 - activation_2_acc: 0.9936 - val_loss: 0.0357 - val_activation_1_loss: 0.0214 - val_activation_2_loss: 0.0143 - val_activation_1_acc: 0.9915 - val_activation_2_acc: 0.9941\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0391 - activation_1_loss: 0.0235 - activation_2_loss: 0.0156 - activation_1_acc: 0.9910 - activation_2_acc: 0.9940 - val_loss: 0.0350 - val_activation_1_loss: 0.0204 - val_activation_2_loss: 0.0146 - val_activation_1_acc: 0.9918 - val_activation_2_acc: 0.9939\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0479 - activation_1_loss: 0.0289 - activation_2_loss: 0.0191 - activation_1_acc: 0.9898 - activation_2_acc: 0.9930 - val_loss: 0.0669 - val_activation_1_loss: 0.0397 - val_activation_2_loss: 0.0272 - val_activation_1_acc: 0.9863 - val_activation_2_acc: 0.9902\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0364 - activation_1_loss: 0.0217 - activation_2_loss: 0.0147 - activation_1_acc: 0.9919 - activation_2_acc: 0.9943 - val_loss: 0.0327 - val_activation_1_loss: 0.0195 - val_activation_2_loss: 0.0132 - val_activation_1_acc: 0.9926 - val_activation_2_acc: 0.9950\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0315 - activation_1_loss: 0.0186 - activation_2_loss: 0.0129 - activation_1_acc: 0.9930 - activation_2_acc: 0.9950 - val_loss: 0.0296 - val_activation_1_loss: 0.0179 - val_activation_2_loss: 0.0117 - val_activation_1_acc: 0.9930 - val_activation_2_acc: 0.9955\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0321 - activation_1_loss: 0.0191 - activation_2_loss: 0.0130 - activation_1_acc: 0.9929 - activation_2_acc: 0.9949 - val_loss: 0.0291 - val_activation_1_loss: 0.0170 - val_activation_2_loss: 0.0121 - val_activation_1_acc: 0.9934 - val_activation_2_acc: 0.9951\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0321 - activation_1_loss: 0.0186 - activation_2_loss: 0.0135 - activation_1_acc: 0.9930 - activation_2_acc: 0.9948 - val_loss: 0.0289 - val_activation_1_loss: 0.0160 - val_activation_2_loss: 0.0129 - val_activation_1_acc: 0.9941 - val_activation_2_acc: 0.9949\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0273 - activation_1_loss: 0.0156 - activation_2_loss: 0.0117 - activation_1_acc: 0.9942 - activation_2_acc: 0.9953 - val_loss: 0.0268 - val_activation_1_loss: 0.0154 - val_activation_2_loss: 0.0114 - val_activation_1_acc: 0.9947 - val_activation_2_acc: 0.9955\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0288 - activation_1_loss: 0.0168 - activation_2_loss: 0.0120 - activation_1_acc: 0.9938 - activation_2_acc: 0.9954 - val_loss: 0.0244 - val_activation_1_loss: 0.0139 - val_activation_2_loss: 0.0105 - val_activation_1_acc: 0.9953 - val_activation_2_acc: 0.9956\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0294 - activation_1_loss: 0.0167 - activation_2_loss: 0.0127 - activation_1_acc: 0.9942 - activation_2_acc: 0.9952 - val_loss: 0.0429 - val_activation_1_loss: 0.0265 - val_activation_2_loss: 0.0164 - val_activation_1_acc: 0.9914 - val_activation_2_acc: 0.9942\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0248 - activation_1_loss: 0.0144 - activation_2_loss: 0.0103 - activation_1_acc: 0.9950 - activation_2_acc: 0.9962 - val_loss: 0.0220 - val_activation_1_loss: 0.0120 - val_activation_2_loss: 0.0100 - val_activation_1_acc: 0.9958 - val_activation_2_acc: 0.9962\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0217 - activation_1_loss: 0.0120 - activation_2_loss: 0.0097 - activation_1_acc: 0.9957 - activation_2_acc: 0.9962 - val_loss: 0.0195 - val_activation_1_loss: 0.0106 - val_activation_2_loss: 0.0089 - val_activation_1_acc: 0.9965 - val_activation_2_acc: 0.9966\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0246 - activation_1_loss: 0.0138 - activation_2_loss: 0.0108 - activation_1_acc: 0.9953 - activation_2_acc: 0.9959 - val_loss: 0.0237 - val_activation_1_loss: 0.0126 - val_activation_2_loss: 0.0111 - val_activation_1_acc: 0.9956 - val_activation_2_acc: 0.9960\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0296 - activation_1_loss: 0.0151 - activation_2_loss: 0.0144 - activation_1_acc: 0.9950 - activation_2_acc: 0.9949 - val_loss: 0.0349 - val_activation_1_loss: 0.0141 - val_activation_2_loss: 0.0208 - val_activation_1_acc: 0.9951 - val_activation_2_acc: 0.9925\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0191 - activation_1_loss: 0.0099 - activation_2_loss: 0.0092 - activation_1_acc: 0.9966 - activation_2_acc: 0.9963 - val_loss: 0.0182 - val_activation_1_loss: 0.0093 - val_activation_2_loss: 0.0090 - val_activation_1_acc: 0.9969 - val_activation_2_acc: 0.9961\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0162 - activation_1_loss: 0.0086 - activation_2_loss: 0.0076 - activation_1_acc: 0.9972 - activation_2_acc: 0.9970 - val_loss: 0.0166 - val_activation_1_loss: 0.0086 - val_activation_2_loss: 0.0080 - val_activation_1_acc: 0.9972 - val_activation_2_acc: 0.9968\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0273 - activation_1_loss: 0.0159 - activation_2_loss: 0.0115 - activation_1_acc: 0.9951 - activation_2_acc: 0.9959 - val_loss: 0.0219 - val_activation_1_loss: 0.0117 - val_activation_2_loss: 0.0102 - val_activation_1_acc: 0.9961 - val_activation_2_acc: 0.9961\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0174 - activation_1_loss: 0.0090 - activation_2_loss: 0.0084 - activation_1_acc: 0.9972 - activation_2_acc: 0.9969 - val_loss: 0.0150 - val_activation_1_loss: 0.0076 - val_activation_2_loss: 0.0074 - val_activation_1_acc: 0.9977 - val_activation_2_acc: 0.9972\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0191 - activation_1_loss: 0.0100 - activation_2_loss: 0.0091 - activation_1_acc: 0.9968 - activation_2_acc: 0.9965 - val_loss: 0.0145 - val_activation_1_loss: 0.0072 - val_activation_2_loss: 0.0073 - val_activation_1_acc: 0.9978 - val_activation_2_acc: 0.9972\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0152 - activation_1_loss: 0.0078 - activation_2_loss: 0.0074 - activation_1_acc: 0.9975 - activation_2_acc: 0.9972 - val_loss: 0.0143 - val_activation_1_loss: 0.0069 - val_activation_2_loss: 0.0074 - val_activation_1_acc: 0.9977 - val_activation_2_acc: 0.9971\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0140 - activation_1_loss: 0.0064 - activation_2_loss: 0.0077 - activation_1_acc: 0.9981 - activation_2_acc: 0.9970 - val_loss: 0.0132 - val_activation_1_loss: 0.0064 - val_activation_2_loss: 0.0068 - val_activation_1_acc: 0.9980 - val_activation_2_acc: 0.9973\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0132 - activation_1_loss: 0.0061 - activation_2_loss: 0.0071 - activation_1_acc: 0.9982 - activation_2_acc: 0.9973 - val_loss: 0.0123 - val_activation_1_loss: 0.0056 - val_activation_2_loss: 0.0067 - val_activation_1_acc: 0.9982 - val_activation_2_acc: 0.9974\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0111 - activation_1_loss: 0.0051 - activation_2_loss: 0.0060 - activation_1_acc: 0.9985 - activation_2_acc: 0.9978 - val_loss: 0.0126 - val_activation_1_loss: 0.0054 - val_activation_2_loss: 0.0072 - val_activation_1_acc: 0.9983 - val_activation_2_acc: 0.9971\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0120 - activation_1_loss: 0.0053 - activation_2_loss: 0.0067 - activation_1_acc: 0.9984 - activation_2_acc: 0.9974 - val_loss: 0.0132 - val_activation_1_loss: 0.0062 - val_activation_2_loss: 0.0069 - val_activation_1_acc: 0.9981 - val_activation_2_acc: 0.9972\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0141 - activation_1_loss: 0.0070 - activation_2_loss: 0.0071 - activation_1_acc: 0.9979 - activation_2_acc: 0.9974 - val_loss: 0.0193 - val_activation_1_loss: 0.0091 - val_activation_2_loss: 0.0102 - val_activation_1_acc: 0.9971 - val_activation_2_acc: 0.9963\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0134 - activation_1_loss: 0.0059 - activation_2_loss: 0.0075 - activation_1_acc: 0.9983 - activation_2_acc: 0.9972 - val_loss: 0.0116 - val_activation_1_loss: 0.0047 - val_activation_2_loss: 0.0069 - val_activation_1_acc: 0.9986 - val_activation_2_acc: 0.9973\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0145 - activation_1_loss: 0.0069 - activation_2_loss: 0.0076 - activation_1_acc: 0.9980 - activation_2_acc: 0.9972 - val_loss: 0.0107 - val_activation_1_loss: 0.0046 - val_activation_2_loss: 0.0061 - val_activation_1_acc: 0.9986 - val_activation_2_acc: 0.9976\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0162 - activation_1_loss: 0.0075 - activation_2_loss: 0.0087 - activation_1_acc: 0.9979 - activation_2_acc: 0.9969 - val_loss: 0.0095 - val_activation_1_loss: 0.0040 - val_activation_2_loss: 0.0055 - val_activation_1_acc: 0.9990 - val_activation_2_acc: 0.9980\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0097 - activation_1_loss: 0.0039 - activation_2_loss: 0.0059 - activation_1_acc: 0.9989 - activation_2_acc: 0.9978 - val_loss: 0.0098 - val_activation_1_loss: 0.0039 - val_activation_2_loss: 0.0059 - val_activation_1_acc: 0.9989 - val_activation_2_acc: 0.9978\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0085 - activation_1_loss: 0.0033 - activation_2_loss: 0.0052 - activation_1_acc: 0.9992 - activation_2_acc: 0.9980 - val_loss: 0.0087 - val_activation_1_loss: 0.0032 - val_activation_2_loss: 0.0055 - val_activation_1_acc: 0.9992 - val_activation_2_acc: 0.9977\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0086 - activation_1_loss: 0.0031 - activation_2_loss: 0.0055 - activation_1_acc: 0.9993 - activation_2_acc: 0.9979 - val_loss: 0.0136 - val_activation_1_loss: 0.0068 - val_activation_2_loss: 0.0069 - val_activation_1_acc: 0.9984 - val_activation_2_acc: 0.9977\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0091 - activation_1_loss: 0.0032 - activation_2_loss: 0.0058 - activation_1_acc: 0.9992 - activation_2_acc: 0.9977 - val_loss: 0.0068 - val_activation_1_loss: 0.0022 - val_activation_2_loss: 0.0046 - val_activation_1_acc: 0.9996 - val_activation_2_acc: 0.9980\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0127 - activation_1_loss: 0.0054 - activation_2_loss: 0.0073 - activation_1_acc: 0.9985 - activation_2_acc: 0.9974 - val_loss: 0.0160 - val_activation_1_loss: 0.0066 - val_activation_2_loss: 0.0094 - val_activation_1_acc: 0.9982 - val_activation_2_acc: 0.9967\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0112 - activation_1_loss: 0.0045 - activation_2_loss: 0.0067 - activation_1_acc: 0.9988 - activation_2_acc: 0.9974 - val_loss: 0.0090 - val_activation_1_loss: 0.0032 - val_activation_2_loss: 0.0059 - val_activation_1_acc: 0.9993 - val_activation_2_acc: 0.9978\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0104 - activation_1_loss: 0.0040 - activation_2_loss: 0.0064 - activation_1_acc: 0.9990 - activation_2_acc: 0.9975 - val_loss: 0.0118 - val_activation_1_loss: 0.0047 - val_activation_2_loss: 0.0071 - val_activation_1_acc: 0.9988 - val_activation_2_acc: 0.9972\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0083 - activation_1_loss: 0.0024 - activation_2_loss: 0.0059 - activation_1_acc: 0.9995 - activation_2_acc: 0.9978 - val_loss: 0.0088 - val_activation_1_loss: 0.0025 - val_activation_2_loss: 0.0063 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9976\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0074 - activation_1_loss: 0.0021 - activation_2_loss: 0.0053 - activation_1_acc: 0.9995 - activation_2_acc: 0.9979 - val_loss: 0.0071 - val_activation_1_loss: 0.0016 - val_activation_2_loss: 0.0055 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9978\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0059 - activation_1_loss: 0.0016 - activation_2_loss: 0.0043 - activation_1_acc: 0.9997 - activation_2_acc: 0.9983 - val_loss: 0.0054 - val_activation_1_loss: 0.0015 - val_activation_2_loss: 0.0039 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9984\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0070 - activation_1_loss: 0.0021 - activation_2_loss: 0.0049 - activation_1_acc: 0.9996 - activation_2_acc: 0.9981 - val_loss: 0.0082 - val_activation_1_loss: 0.0018 - val_activation_2_loss: 0.0064 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9975\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0063 - activation_1_loss: 0.0015 - activation_2_loss: 0.0049 - activation_1_acc: 0.9997 - activation_2_acc: 0.9981 - val_loss: 0.0055 - val_activation_1_loss: 0.0015 - val_activation_2_loss: 0.0040 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9984\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0061 - activation_1_loss: 0.0014 - activation_2_loss: 0.0046 - activation_1_acc: 0.9998 - activation_2_acc: 0.9981 - val_loss: 0.0066 - val_activation_1_loss: 0.0013 - val_activation_2_loss: 0.0053 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9978\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0200 - activation_1_loss: 0.0101 - activation_2_loss: 0.0098 - activation_1_acc: 0.9975 - activation_2_acc: 0.9967 - val_loss: 0.0111 - val_activation_1_loss: 0.0041 - val_activation_2_loss: 0.0071 - val_activation_1_acc: 0.9990 - val_activation_2_acc: 0.9972\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0087 - activation_1_loss: 0.0032 - activation_2_loss: 0.0055 - activation_1_acc: 0.9992 - activation_2_acc: 0.9980 - val_loss: 0.0071 - val_activation_1_loss: 0.0017 - val_activation_2_loss: 0.0054 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9978\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0061 - activation_1_loss: 0.0015 - activation_2_loss: 0.0046 - activation_1_acc: 0.9998 - activation_2_acc: 0.9982 - val_loss: 0.0052 - val_activation_1_loss: 0.0012 - val_activation_2_loss: 0.0040 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0056 - activation_1_loss: 0.0011 - activation_2_loss: 0.0045 - activation_1_acc: 0.9998 - activation_2_acc: 0.9982 - val_loss: 0.0054 - val_activation_1_loss: 0.0011 - val_activation_2_loss: 0.0043 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9983\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0055 - activation_1_loss: 0.0010 - activation_2_loss: 0.0045 - activation_1_acc: 0.9998 - activation_2_acc: 0.9982 - val_loss: 0.0048 - val_activation_1_loss: 9.9045e-04 - val_activation_2_loss: 0.0038 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0067 - activation_1_loss: 0.0020 - activation_2_loss: 0.0047 - activation_1_acc: 0.9996 - activation_2_acc: 0.9982 - val_loss: 0.0057 - val_activation_1_loss: 0.0010 - val_activation_2_loss: 0.0047 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9982\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0049 - activation_1_loss: 9.8814e-04 - activation_2_loss: 0.0039 - activation_1_acc: 0.9998 - activation_2_acc: 0.9986 - val_loss: 0.0064 - val_activation_1_loss: 9.8253e-04 - val_activation_2_loss: 0.0054 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9977\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0070 - activation_1_loss: 0.0021 - activation_2_loss: 0.0048 - activation_1_acc: 0.9995 - activation_2_acc: 0.9981 - val_loss: 0.0047 - val_activation_1_loss: 0.0010 - val_activation_2_loss: 0.0037 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9986\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0047 - activation_1_loss: 8.6558e-04 - activation_2_loss: 0.0038 - activation_1_acc: 0.9999 - activation_2_acc: 0.9985 - val_loss: 0.0043 - val_activation_1_loss: 8.1133e-04 - val_activation_2_loss: 0.0035 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0059 - activation_1_loss: 0.0012 - activation_2_loss: 0.0046 - activation_1_acc: 0.9998 - activation_2_acc: 0.9982 - val_loss: 0.0048 - val_activation_1_loss: 8.4647e-04 - val_activation_2_loss: 0.0040 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0068 - activation_1_loss: 0.0018 - activation_2_loss: 0.0050 - activation_1_acc: 0.9996 - activation_2_acc: 0.9980 - val_loss: 0.0067 - val_activation_1_loss: 0.0019 - val_activation_2_loss: 0.0047 - val_activation_1_acc: 0.9996 - val_activation_2_acc: 0.9981\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0050 - activation_1_loss: 0.0010 - activation_2_loss: 0.0040 - activation_1_acc: 0.9998 - activation_2_acc: 0.9985 - val_loss: 0.0046 - val_activation_1_loss: 5.3932e-04 - val_activation_2_loss: 0.0041 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9984\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0050 - activation_1_loss: 8.4667e-04 - activation_2_loss: 0.0041 - activation_1_acc: 0.9999 - activation_2_acc: 0.9983 - val_loss: 0.0046 - val_activation_1_loss: 5.7321e-04 - val_activation_2_loss: 0.0041 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0042 - activation_1_loss: 5.9820e-04 - activation_2_loss: 0.0036 - activation_1_acc: 0.9999 - activation_2_acc: 0.9986 - val_loss: 0.0040 - val_activation_1_loss: 5.4392e-04 - val_activation_2_loss: 0.0035 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0042 - activation_1_loss: 6.0984e-04 - activation_2_loss: 0.0036 - activation_1_acc: 0.9999 - activation_2_acc: 0.9986 - val_loss: 0.0037 - val_activation_1_loss: 5.6979e-04 - val_activation_2_loss: 0.0032 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0040 - activation_1_loss: 5.3233e-04 - activation_2_loss: 0.0035 - activation_1_acc: 0.9999 - activation_2_acc: 0.9986 - val_loss: 0.0042 - val_activation_1_loss: 5.9924e-04 - val_activation_2_loss: 0.0036 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9986\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0043 - activation_1_loss: 5.6148e-04 - activation_2_loss: 0.0038 - activation_1_acc: 0.9999 - activation_2_acc: 0.9986 - val_loss: 0.0035 - val_activation_1_loss: 4.6267e-04 - val_activation_2_loss: 0.0030 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0082 - activation_1_loss: 0.0031 - activation_2_loss: 0.0051 - activation_1_acc: 0.9992 - activation_2_acc: 0.9981 - val_loss: 0.0148 - val_activation_1_loss: 0.0072 - val_activation_2_loss: 0.0076 - val_activation_1_acc: 0.9977 - val_activation_2_acc: 0.9973\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0099 - activation_1_loss: 0.0040 - activation_2_loss: 0.0059 - activation_1_acc: 0.9991 - activation_2_acc: 0.9980 - val_loss: 0.0063 - val_activation_1_loss: 0.0010 - val_activation_2_loss: 0.0053 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9980\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0042 - activation_1_loss: 6.2674e-04 - activation_2_loss: 0.0036 - activation_1_acc: 0.9999 - activation_2_acc: 0.9987 - val_loss: 0.0038 - val_activation_1_loss: 6.6213e-04 - val_activation_2_loss: 0.0031 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0047 - activation_1_loss: 9.5422e-04 - activation_2_loss: 0.0037 - activation_1_acc: 0.9998 - activation_2_acc: 0.9985 - val_loss: 0.0050 - val_activation_1_loss: 0.0010 - val_activation_2_loss: 0.0040 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9983\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0060 - activation_1_loss: 0.0019 - activation_2_loss: 0.0042 - activation_1_acc: 0.9996 - activation_2_acc: 0.9984 - val_loss: 0.0046 - val_activation_1_loss: 6.7652e-04 - val_activation_2_loss: 0.0039 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9984\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0040 - activation_1_loss: 6.0842e-04 - activation_2_loss: 0.0034 - activation_1_acc: 0.9999 - activation_2_acc: 0.9987 - val_loss: 0.0040 - val_activation_1_loss: 4.4915e-04 - val_activation_2_loss: 0.0036 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9986\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0036 - activation_1_loss: 4.0065e-04 - activation_2_loss: 0.0032 - activation_1_acc: 1.0000 - activation_2_acc: 0.9987 - val_loss: 0.0039 - val_activation_1_loss: 4.0385e-04 - val_activation_2_loss: 0.0035 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0042 - activation_1_loss: 8.0446e-04 - activation_2_loss: 0.0034 - activation_1_acc: 0.9999 - activation_2_acc: 0.9987 - val_loss: 0.0042 - val_activation_1_loss: 5.4878e-04 - val_activation_2_loss: 0.0036 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0040 - activation_1_loss: 5.0679e-04 - activation_2_loss: 0.0035 - activation_1_acc: 0.9999 - activation_2_acc: 0.9986 - val_loss: 0.0046 - val_activation_1_loss: 4.8615e-04 - val_activation_2_loss: 0.0041 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9983\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0100 - activation_1_loss: 0.0048 - activation_2_loss: 0.0051 - activation_1_acc: 0.9990 - activation_2_acc: 0.9982 - val_loss: 0.0039 - val_activation_1_loss: 6.8294e-04 - val_activation_2_loss: 0.0032 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0036 - activation_1_loss: 5.5210e-04 - activation_2_loss: 0.0030 - activation_1_acc: 0.9999 - activation_2_acc: 0.9988 - val_loss: 0.0032 - val_activation_1_loss: 7.2813e-04 - val_activation_2_loss: 0.0025 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0039 - activation_1_loss: 7.7701e-04 - activation_2_loss: 0.0031 - activation_1_acc: 0.9999 - activation_2_acc: 0.9988 - val_loss: 0.0039 - val_activation_1_loss: 5.1734e-04 - val_activation_2_loss: 0.0033 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0034 - activation_1_loss: 3.5169e-04 - activation_2_loss: 0.0030 - activation_1_acc: 1.0000 - activation_2_acc: 0.9988 - val_loss: 0.0031 - val_activation_1_loss: 2.9891e-04 - val_activation_2_loss: 0.0028 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0032 - activation_1_loss: 2.8005e-04 - activation_2_loss: 0.0029 - activation_1_acc: 1.0000 - activation_2_acc: 0.9989 - val_loss: 0.0032 - val_activation_1_loss: 3.2989e-04 - val_activation_2_loss: 0.0029 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0059 - activation_1_loss: 0.0014 - activation_2_loss: 0.0045 - activation_1_acc: 0.9997 - activation_2_acc: 0.9984 - val_loss: 0.0046 - val_activation_1_loss: 9.6704e-04 - val_activation_2_loss: 0.0037 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9986\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0036 - activation_1_loss: 5.3252e-04 - activation_2_loss: 0.0031 - activation_1_acc: 0.9999 - activation_2_acc: 0.9988 - val_loss: 0.0032 - val_activation_1_loss: 3.2637e-04 - val_activation_2_loss: 0.0029 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0036 - activation_1_loss: 3.5835e-04 - activation_2_loss: 0.0032 - activation_1_acc: 0.9999 - activation_2_acc: 0.9987 - val_loss: 0.0028 - val_activation_1_loss: 3.3252e-04 - val_activation_2_loss: 0.0025 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 2.8458e-04 - activation_2_loss: 0.0028 - activation_1_acc: 1.0000 - activation_2_acc: 0.9989 - val_loss: 0.0036 - val_activation_1_loss: 2.6774e-04 - val_activation_2_loss: 0.0033 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9986\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 2.8001e-04 - activation_2_loss: 0.0027 - activation_1_acc: 1.0000 - activation_2_acc: 0.9989 - val_loss: 0.0029 - val_activation_1_loss: 2.8495e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0029 - activation_1_loss: 3.1342e-04 - activation_2_loss: 0.0026 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0039 - val_activation_1_loss: 2.3417e-04 - val_activation_2_loss: 0.0037 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0034 - activation_1_loss: 3.3790e-04 - activation_2_loss: 0.0030 - activation_1_acc: 1.0000 - activation_2_acc: 0.9988 - val_loss: 0.0031 - val_activation_1_loss: 5.0503e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0031 - activation_1_loss: 2.4986e-04 - activation_2_loss: 0.0028 - activation_1_acc: 1.0000 - activation_2_acc: 0.9989 - val_loss: 0.0029 - val_activation_1_loss: 3.6124e-04 - val_activation_2_loss: 0.0025 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0037 - activation_1_loss: 6.4847e-04 - activation_2_loss: 0.0030 - activation_1_acc: 0.9998 - activation_2_acc: 0.9989 - val_loss: 0.0047 - val_activation_1_loss: 9.4351e-04 - val_activation_2_loss: 0.0038 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0036 - activation_1_loss: 4.8719e-04 - activation_2_loss: 0.0031 - activation_1_acc: 0.9999 - activation_2_acc: 0.9988 - val_loss: 0.0048 - val_activation_1_loss: 8.3753e-04 - val_activation_2_loss: 0.0039 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0093 - activation_1_loss: 0.0043 - activation_2_loss: 0.0050 - activation_1_acc: 0.9991 - activation_2_acc: 0.9984 - val_loss: 0.0035 - val_activation_1_loss: 5.3658e-04 - val_activation_2_loss: 0.0030 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0033 - activation_1_loss: 3.2821e-04 - activation_2_loss: 0.0030 - activation_1_acc: 1.0000 - activation_2_acc: 0.9988 - val_loss: 0.0029 - val_activation_1_loss: 2.4454e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0031 - activation_1_loss: 2.6321e-04 - activation_2_loss: 0.0029 - activation_1_acc: 1.0000 - activation_2_acc: 0.9989 - val_loss: 0.0029 - val_activation_1_loss: 2.4845e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0029 - activation_1_loss: 2.1355e-04 - activation_2_loss: 0.0027 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0032 - val_activation_1_loss: 4.7528e-04 - val_activation_2_loss: 0.0027 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0028 - activation_1_loss: 2.1911e-04 - activation_2_loss: 0.0026 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0038 - val_activation_1_loss: 2.5037e-04 - val_activation_2_loss: 0.0035 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0029 - activation_1_loss: 2.2530e-04 - activation_2_loss: 0.0027 - activation_1_acc: 1.0000 - activation_2_acc: 0.9989 - val_loss: 0.0027 - val_activation_1_loss: 1.9035e-04 - val_activation_2_loss: 0.0025 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 2.4193e-04 - activation_2_loss: 0.0028 - activation_1_acc: 1.0000 - activation_2_acc: 0.9988 - val_loss: 0.0037 - val_activation_1_loss: 2.9485e-04 - val_activation_2_loss: 0.0034 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9985\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0075 - activation_1_loss: 0.0031 - activation_2_loss: 0.0044 - activation_1_acc: 0.9993 - activation_2_acc: 0.9985 - val_loss: 0.0055 - val_activation_1_loss: 0.0022 - val_activation_2_loss: 0.0033 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0070 - activation_1_loss: 0.0025 - activation_2_loss: 0.0045 - activation_1_acc: 0.9995 - activation_2_acc: 0.9985 - val_loss: 0.0043 - val_activation_1_loss: 4.3169e-04 - val_activation_2_loss: 0.0039 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9984\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 3.6073e-04 - activation_2_loss: 0.0026 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0025 - val_activation_1_loss: 2.1650e-04 - val_activation_2_loss: 0.0023 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0029 - activation_1_loss: 2.2020e-04 - activation_2_loss: 0.0027 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0028 - val_activation_1_loss: 1.9568e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 1.7681e-04 - activation_2_loss: 0.0024 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0021 - val_activation_1_loss: 1.9068e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 1.5789e-04 - activation_2_loss: 0.0023 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0028 - val_activation_1_loss: 1.6498e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0031 - activation_1_loss: 3.9554e-04 - activation_2_loss: 0.0027 - activation_1_acc: 0.9999 - activation_2_acc: 0.9990 - val_loss: 0.0031 - val_activation_1_loss: 2.6038e-04 - val_activation_2_loss: 0.0029 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 3.5037e-04 - activation_2_loss: 0.0026 - activation_1_acc: 0.9999 - activation_2_acc: 0.9991 - val_loss: 0.0023 - val_activation_1_loss: 1.7964e-04 - val_activation_2_loss: 0.0021 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 2.4493e-04 - activation_2_loss: 0.0022 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0022 - val_activation_1_loss: 1.7430e-04 - val_activation_2_loss: 0.0020 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 1.8454e-04 - activation_2_loss: 0.0023 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0032 - val_activation_1_loss: 1.3296e-04 - val_activation_2_loss: 0.0030 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0027 - activation_1_loss: 1.9226e-04 - activation_2_loss: 0.0025 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0025 - val_activation_1_loss: 2.1157e-04 - val_activation_2_loss: 0.0022 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0026 - activation_1_loss: 2.7720e-04 - activation_2_loss: 0.0023 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0032 - val_activation_1_loss: 4.0752e-04 - val_activation_2_loss: 0.0028 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0079 - activation_1_loss: 0.0037 - activation_2_loss: 0.0042 - activation_1_acc: 0.9992 - activation_2_acc: 0.9985 - val_loss: 0.0032 - val_activation_1_loss: 2.6307e-04 - val_activation_2_loss: 0.0029 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0028 - activation_1_loss: 3.2334e-04 - activation_2_loss: 0.0025 - activation_1_acc: 0.9999 - activation_2_acc: 0.9991 - val_loss: 0.0021 - val_activation_1_loss: 2.6369e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0026 - activation_1_loss: 2.9510e-04 - activation_2_loss: 0.0023 - activation_1_acc: 0.9999 - activation_2_acc: 0.9992 - val_loss: 0.0031 - val_activation_1_loss: 3.3438e-04 - val_activation_2_loss: 0.0028 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0031 - activation_1_loss: 4.3246e-04 - activation_2_loss: 0.0026 - activation_1_acc: 0.9999 - activation_2_acc: 0.9991 - val_loss: 0.0025 - val_activation_1_loss: 1.5969e-04 - val_activation_2_loss: 0.0023 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 1.8632e-04 - activation_2_loss: 0.0023 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0025 - val_activation_1_loss: 1.5030e-04 - val_activation_2_loss: 0.0024 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0027 - activation_1_loss: 1.4384e-04 - activation_2_loss: 0.0026 - activation_1_acc: 1.0000 - activation_2_acc: 0.9990 - val_loss: 0.0023 - val_activation_1_loss: 1.9344e-04 - val_activation_2_loss: 0.0021 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0023 - activation_1_loss: 1.5908e-04 - activation_2_loss: 0.0022 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0027 - val_activation_1_loss: 4.0561e-04 - val_activation_2_loss: 0.0023 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0023 - activation_1_loss: 1.2406e-04 - activation_2_loss: 0.0022 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0027 - val_activation_1_loss: 1.5252e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 1.7193e-04 - activation_2_loss: 0.0020 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0027 - val_activation_1_loss: 1.4886e-04 - val_activation_2_loss: 0.0025 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 1.9025e-04 - activation_2_loss: 0.0020 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0039 - val_activation_1_loss: 2.0599e-04 - val_activation_2_loss: 0.0037 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0043 - activation_1_loss: 0.0013 - activation_2_loss: 0.0030 - activation_1_acc: 0.9998 - activation_2_acc: 0.9989 - val_loss: 0.0031 - val_activation_1_loss: 1.6446e-04 - val_activation_2_loss: 0.0029 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 2.4544e-04 - activation_2_loss: 0.0022 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0023 - val_activation_1_loss: 1.8139e-04 - val_activation_2_loss: 0.0021 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0028 - activation_1_loss: 2.0172e-04 - activation_2_loss: 0.0026 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0024 - val_activation_1_loss: 2.5926e-04 - val_activation_2_loss: 0.0021 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0020 - activation_1_loss: 1.8024e-04 - activation_2_loss: 0.0018 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0037 - val_activation_1_loss: 5.1427e-04 - val_activation_2_loss: 0.0032 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9988\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 1.9414e-04 - activation_2_loss: 0.0023 - activation_1_acc: 1.0000 - activation_2_acc: 0.9991 - val_loss: 0.0020 - val_activation_1_loss: 1.2170e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 2.0725e-04 - activation_2_loss: 0.0020 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0021 - val_activation_1_loss: 8.1718e-05 - val_activation_2_loss: 0.0020 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 1.7655e-04 - activation_2_loss: 0.0020 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0016 - val_activation_1_loss: 1.0010e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0031 - activation_1_loss: 4.0681e-04 - activation_2_loss: 0.0027 - activation_1_acc: 0.9999 - activation_2_acc: 0.9990 - val_loss: 0.0021 - val_activation_1_loss: 1.3680e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0054 - activation_1_loss: 0.0022 - activation_2_loss: 0.0032 - activation_1_acc: 0.9995 - activation_2_acc: 0.9989 - val_loss: 0.0031 - val_activation_1_loss: 4.4332e-04 - val_activation_2_loss: 0.0027 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0051 - activation_1_loss: 0.0017 - activation_2_loss: 0.0033 - activation_1_acc: 0.9997 - activation_2_acc: 0.9989 - val_loss: 0.0019 - val_activation_1_loss: 2.7654e-04 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0024 - activation_1_loss: 3.5281e-04 - activation_2_loss: 0.0020 - activation_1_acc: 0.9999 - activation_2_acc: 0.9992 - val_loss: 0.0017 - val_activation_1_loss: 1.7626e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0024 - activation_1_loss: 2.4604e-04 - activation_2_loss: 0.0022 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0043 - val_activation_1_loss: 9.1405e-04 - val_activation_2_loss: 0.0034 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9987\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 1.6620e-04 - activation_2_loss: 0.0019 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0019 - val_activation_1_loss: 1.0870e-04 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 2.2470e-04 - activation_2_loss: 0.0020 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0020 - val_activation_1_loss: 1.5292e-04 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0020 - activation_1_loss: 1.2637e-04 - activation_2_loss: 0.0019 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0019 - val_activation_1_loss: 1.2911e-04 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0033 - activation_1_loss: 8.1510e-04 - activation_2_loss: 0.0025 - activation_1_acc: 0.9998 - activation_2_acc: 0.9991 - val_loss: 0.0030 - val_activation_1_loss: 8.4017e-04 - val_activation_2_loss: 0.0022 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 3.1761e-04 - activation_2_loss: 0.0014 - activation_1_acc: 0.9999 - activation_2_acc: 0.9995 - val_loss: 0.0022 - val_activation_1_loss: 1.3336e-04 - val_activation_2_loss: 0.0021 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 1.4924e-04 - activation_2_loss: 0.0020 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0019 - val_activation_1_loss: 1.6052e-04 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0020 - activation_1_loss: 2.5767e-04 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0031 - val_activation_1_loss: 3.5980e-04 - val_activation_2_loss: 0.0028 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0028 - activation_1_loss: 3.3115e-04 - activation_2_loss: 0.0024 - activation_1_acc: 0.9999 - activation_2_acc: 0.9991 - val_loss: 0.0021 - val_activation_1_loss: 1.6286e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0023 - activation_1_loss: 1.4288e-04 - activation_2_loss: 0.0021 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0019 - val_activation_1_loss: 9.4188e-05 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 1.2283e-04 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0015 - val_activation_1_loss: 8.9244e-05 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 1.1780e-04 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0021 - val_activation_1_loss: 1.1919e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 8.8676e-05 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0018 - val_activation_1_loss: 7.0490e-05 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 1.2918e-04 - activation_2_loss: 0.0018 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0021 - val_activation_1_loss: 1.8472e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 4.4414e-04 - activation_2_loss: 0.0021 - activation_1_acc: 0.9999 - activation_2_acc: 0.9992 - val_loss: 0.0023 - val_activation_1_loss: 2.6859e-04 - val_activation_2_loss: 0.0020 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0049 - activation_1_loss: 0.0017 - activation_2_loss: 0.0032 - activation_1_acc: 0.9996 - activation_2_acc: 0.9989 - val_loss: 0.0022 - val_activation_1_loss: 3.4911e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 1.6686e-04 - activation_2_loss: 0.0019 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0017 - val_activation_1_loss: 8.8860e-05 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 1.1114e-04 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0015 - val_activation_1_loss: 9.0850e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0024 - activation_1_loss: 5.9047e-04 - activation_2_loss: 0.0019 - activation_1_acc: 0.9999 - activation_2_acc: 0.9993 - val_loss: 0.0038 - val_activation_1_loss: 7.2025e-04 - val_activation_2_loss: 0.0031 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 2.7291e-04 - activation_2_loss: 0.0019 - activation_1_acc: 0.9999 - activation_2_acc: 0.9993 - val_loss: 0.0064 - val_activation_1_loss: 0.0024 - val_activation_2_loss: 0.0040 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9990\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0020 - activation_1_loss: 2.1795e-04 - activation_2_loss: 0.0018 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0027 - val_activation_1_loss: 0.0012 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 2.3910e-04 - activation_2_loss: 0.0020 - activation_1_acc: 0.9999 - activation_2_acc: 0.9992 - val_loss: 0.0027 - val_activation_1_loss: 2.3536e-04 - val_activation_2_loss: 0.0024 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 1.9787e-04 - activation_2_loss: 0.0019 - activation_1_acc: 1.0000 - activation_2_acc: 0.9992 - val_loss: 0.0014 - val_activation_1_loss: 1.7069e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0023 - activation_1_loss: 3.9670e-04 - activation_2_loss: 0.0019 - activation_1_acc: 0.9999 - activation_2_acc: 0.9992 - val_loss: 0.0020 - val_activation_1_loss: 1.0364e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 1.0067e-04 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0013 - val_activation_1_loss: 5.8004e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 1.2262e-04 - activation_2_loss: 0.0018 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0019 - val_activation_1_loss: 1.4487e-04 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 1.1212e-04 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0013 - val_activation_1_loss: 6.0460e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 8.3488e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0017 - val_activation_1_loss: 1.6512e-04 - val_activation_2_loss: 0.0016 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 1.2956e-04 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0016 - val_activation_1_loss: 2.0446e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0029 - activation_1_loss: 8.4622e-04 - activation_2_loss: 0.0021 - activation_1_acc: 0.9998 - activation_2_acc: 0.9992 - val_loss: 0.0018 - val_activation_1_loss: 2.9084e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 1.4927e-04 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0020 - val_activation_1_loss: 1.3228e-04 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0016 - activation_1_loss: 1.0763e-04 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0013 - val_activation_1_loss: 8.7894e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 1.1791e-04 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0028 - val_activation_1_loss: 1.8704e-04 - val_activation_2_loss: 0.0026 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0031 - activation_1_loss: 3.5969e-04 - activation_2_loss: 0.0028 - activation_1_acc: 0.9999 - activation_2_acc: 0.9990 - val_loss: 0.0020 - val_activation_1_loss: 1.1384e-04 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 1.2663e-04 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0014 - val_activation_1_loss: 1.1066e-04 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 7.2124e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 9.0568e-04 - val_activation_1_loss: 7.8739e-05 - val_activation_2_loss: 8.2695e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 1.1573e-04 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0020 - val_activation_1_loss: 8.5093e-05 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 4.8034e-05 - activation_2_loss: 9.7354e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0012 - val_activation_1_loss: 7.0145e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 8.2067e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0016 - val_activation_1_loss: 1.5667e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 8.0914e-05 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9993 - val_loss: 0.0023 - val_activation_1_loss: 1.3629e-04 - val_activation_2_loss: 0.0022 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9991\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 7.3598e-05 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0012 - val_activation_1_loss: 5.9187e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 3.2265e-04 - activation_2_loss: 0.0016 - activation_1_acc: 0.9999 - activation_2_acc: 0.9994 - val_loss: 0.0011 - val_activation_1_loss: 1.5247e-04 - val_activation_2_loss: 9.6889e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0064 - activation_1_loss: 0.0030 - activation_2_loss: 0.0034 - activation_1_acc: 0.9994 - activation_2_acc: 0.9989 - val_loss: 0.0019 - val_activation_1_loss: 3.9719e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0025 - activation_1_loss: 7.6759e-04 - activation_2_loss: 0.0017 - activation_1_acc: 0.9999 - activation_2_acc: 0.9994 - val_loss: 0.0016 - val_activation_1_loss: 1.3309e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 1.1420e-04 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0012 - val_activation_1_loss: 1.0583e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 1.0171e-04 - activation_2_loss: 0.0013 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0016 - val_activation_1_loss: 8.9321e-05 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 7.5576e-05 - activation_2_loss: 0.0013 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0012 - val_activation_1_loss: 7.9549e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 6.3181e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0015 - val_activation_1_loss: 1.1501e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 5.8622e-05 - activation_2_loss: 9.4626e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0019 - val_activation_1_loss: 7.2538e-05 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 2.2193e-04 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0013 - val_activation_1_loss: 1.6294e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 1.1157e-04 - activation_2_loss: 0.0017 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0013 - val_activation_1_loss: 7.2260e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0020 - activation_1_loss: 3.4267e-04 - activation_2_loss: 0.0017 - activation_1_acc: 0.9999 - activation_2_acc: 0.9994 - val_loss: 0.0019 - val_activation_1_loss: 2.6325e-04 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 1.4378e-04 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0012 - val_activation_1_loss: 7.9986e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0016 - activation_1_loss: 6.8165e-05 - activation_2_loss: 0.0016 - activation_1_acc: 1.0000 - activation_2_acc: 0.9994 - val_loss: 0.0017 - val_activation_1_loss: 8.0619e-05 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 9.7225e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 9.2681e-04 - val_activation_1_loss: 4.4590e-05 - val_activation_2_loss: 8.8222e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 6.7073e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0014 - val_activation_1_loss: 4.3654e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0016 - activation_1_loss: 1.5389e-04 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0016 - val_activation_1_loss: 1.4265e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 1.1275e-04 - activation_2_loss: 0.0013 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0014 - val_activation_1_loss: 1.1812e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 3.1474e-04 - activation_2_loss: 0.0016 - activation_1_acc: 0.9999 - activation_2_acc: 0.9994 - val_loss: 0.0013 - val_activation_1_loss: 8.2782e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 7.0961e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0016 - val_activation_1_loss: 2.3676e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 3.6451e-04 - activation_2_loss: 0.0014 - activation_1_acc: 0.9999 - activation_2_acc: 0.9995 - val_loss: 0.0020 - val_activation_1_loss: 2.7249e-04 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0016 - activation_1_loss: 1.3826e-04 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0020 - val_activation_1_loss: 9.5319e-05 - val_activation_2_loss: 0.0019 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 7.0558e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 9.9508e-04 - val_activation_1_loss: 6.7846e-05 - val_activation_2_loss: 9.2723e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 8.5459e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0015 - val_activation_1_loss: 9.6064e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 5.3775e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0011 - val_activation_1_loss: 1.0937e-04 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.3445e-04 - activation_1_loss: 5.5182e-05 - activation_2_loss: 7.7927e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0011 - val_activation_1_loss: 6.3974e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 7.8717e-05 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 9.2237e-04 - val_activation_1_loss: 7.4799e-05 - val_activation_2_loss: 8.4757e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 9.2384e-05 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0013 - val_activation_1_loss: 8.7802e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 4.5077e-04 - activation_2_loss: 0.0012 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0039 - val_activation_1_loss: 0.0024 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0075 - activation_1_loss: 0.0036 - activation_2_loss: 0.0039 - activation_1_acc: 0.9993 - activation_2_acc: 0.9990 - val_loss: 0.0042 - val_activation_1_loss: 0.0012 - val_activation_2_loss: 0.0029 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 2.3280e-04 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0013 - val_activation_1_loss: 1.3904e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 1.4616e-04 - activation_2_loss: 0.0013 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 9.4714e-04 - val_activation_1_loss: 1.0228e-04 - val_activation_2_loss: 8.4486e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 7.4275e-05 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0013 - val_activation_1_loss: 6.4741e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 5.9633e-05 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0011 - val_activation_1_loss: 6.5613e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.4240e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0015 - val_activation_1_loss: 8.7304e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 1.4521e-04 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0013 - val_activation_1_loss: 5.6532e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 5.3570e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 8.3131e-04 - val_activation_1_loss: 7.0000e-05 - val_activation_2_loss: 7.6131e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 4.6826e-05 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0011 - val_activation_1_loss: 3.5398e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.8174e-05 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0014 - val_activation_1_loss: 5.1586e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.4469e-05 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0019 - val_activation_1_loss: 9.7116e-05 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 7.0487e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 9.7919e-04 - val_activation_1_loss: 8.2504e-05 - val_activation_2_loss: 8.9669e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.7443e-04 - activation_1_loss: 6.1100e-05 - activation_2_loss: 9.1333e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 6.9681e-04 - val_activation_1_loss: 3.7177e-05 - val_activation_2_loss: 6.5963e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.5738e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0012 - val_activation_1_loss: 4.4780e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 6.8613e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0016 - val_activation_1_loss: 5.7295e-05 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 9.2049e-05 - activation_2_loss: 9.5730e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0017 - val_activation_1_loss: 3.2264e-04 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 4.6685e-04 - activation_2_loss: 0.0016 - activation_1_acc: 0.9999 - activation_2_acc: 0.9995 - val_loss: 0.0014 - val_activation_1_loss: 6.6684e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.3673e-04 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0015 - val_activation_1_loss: 6.2601e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 8.1075e-05 - activation_2_loss: 0.0014 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0018 - val_activation_1_loss: 5.9395e-05 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 6.3641e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0015 - val_activation_1_loss: 5.1050e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.6829e-04 - activation_2_loss: 9.3583e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0015 - val_activation_1_loss: 5.6091e-05 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0020 - activation_1_loss: 5.9315e-04 - activation_2_loss: 0.0014 - activation_1_acc: 0.9999 - activation_2_acc: 0.9995 - val_loss: 0.0100 - val_activation_1_loss: 0.0022 - val_activation_2_loss: 0.0078 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9981\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0026 - activation_1_loss: 7.5241e-04 - activation_2_loss: 0.0018 - activation_1_acc: 0.9998 - activation_2_acc: 0.9994 - val_loss: 0.0023 - val_activation_1_loss: 5.8822e-04 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 9.2326e-05 - activation_2_loss: 9.8655e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0013 - val_activation_1_loss: 4.3731e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 1.2875e-04 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 9.6021e-04 - val_activation_1_loss: 5.6784e-05 - val_activation_2_loss: 9.0343e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 6.5255e-05 - activation_2_loss: 9.6045e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0014 - val_activation_1_loss: 6.0731e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 7.5077e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 7.3442e-04 - val_activation_1_loss: 4.2685e-05 - val_activation_2_loss: 6.9174e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 4.9728e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 6.5037e-04 - val_activation_1_loss: 5.7730e-05 - val_activation_2_loss: 5.9264e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 3.8166e-05 - activation_2_loss: 9.6875e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 9.4705e-04 - val_activation_1_loss: 2.8389e-05 - val_activation_2_loss: 9.1866e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 5.9013e-04 - activation_2_loss: 0.0015 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0036 - val_activation_1_loss: 0.0018 - val_activation_2_loss: 0.0018 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0018 - activation_1_loss: 2.1031e-04 - activation_2_loss: 0.0015 - activation_1_acc: 0.9999 - activation_2_acc: 0.9994 - val_loss: 0.0011 - val_activation_1_loss: 4.3434e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 9.5304e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9995 - val_loss: 0.0011 - val_activation_1_loss: 1.5222e-04 - val_activation_2_loss: 9.0968e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0016 - activation_1_loss: 3.6678e-04 - activation_2_loss: 0.0012 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 5.3886e-04 - val_activation_1_loss: 8.4925e-05 - val_activation_2_loss: 4.5394e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 1.3471e-04 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0011 - val_activation_1_loss: 7.2131e-05 - val_activation_2_loss: 9.7958e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.1546e-05 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 7.5563e-04 - val_activation_1_loss: 2.9836e-05 - val_activation_2_loss: 7.2579e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 5.3906e-05 - activation_2_loss: 9.9470e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0013 - val_activation_1_loss: 3.9455e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9987e-04 - activation_1_loss: 5.6195e-05 - activation_2_loss: 7.4368e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0010 - val_activation_1_loss: 8.3241e-05 - val_activation_2_loss: 9.6466e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 2.5596e-04 - activation_2_loss: 8.1050e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.6385e-04 - val_activation_1_loss: 1.0320e-04 - val_activation_2_loss: 7.6065e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.9735e-05 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0018 - val_activation_1_loss: 4.1999e-05 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 3.8926e-04 - activation_2_loss: 0.0015 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0021 - val_activation_1_loss: 4.3792e-04 - val_activation_2_loss: 0.0016 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9994\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 5.9380e-05 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0015 - val_activation_1_loss: 3.1179e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 1.0516e-04 - activation_2_loss: 9.7301e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 9.8391e-04 - val_activation_1_loss: 4.7828e-05 - val_activation_2_loss: 9.3608e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.7105e-04 - activation_1_loss: 5.5860e-05 - activation_2_loss: 9.1519e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0016 - val_activation_1_loss: 5.7300e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0037 - activation_1_loss: 0.0018 - activation_2_loss: 0.0019 - activation_1_acc: 0.9997 - activation_2_acc: 0.9995 - val_loss: 0.0046 - val_activation_1_loss: 0.0014 - val_activation_2_loss: 0.0032 - val_activation_1_acc: 0.9996 - val_activation_2_acc: 0.9989\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 4.1383e-04 - activation_2_loss: 0.0017 - activation_1_acc: 0.9999 - activation_2_acc: 0.9994 - val_loss: 0.0011 - val_activation_1_loss: 1.3370e-04 - val_activation_2_loss: 9.8287e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 8.6089e-05 - activation_2_loss: 9.4385e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.2347e-04 - val_activation_1_loss: 5.1140e-05 - val_activation_2_loss: 6.7232e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 5.5528e-05 - activation_2_loss: 9.9802e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.9041e-04 - val_activation_1_loss: 5.8526e-05 - val_activation_2_loss: 8.3188e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 4.2528e-05 - activation_2_loss: 9.6317e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.5211e-04 - val_activation_1_loss: 6.3384e-05 - val_activation_2_loss: 6.8873e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 1.4791e-04 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0014 - val_activation_1_loss: 2.1695e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.5290e-04 - activation_1_loss: 6.2004e-05 - activation_2_loss: 7.9089e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.5563e-04 - val_activation_1_loss: 5.0497e-05 - val_activation_2_loss: 7.0513e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.2453e-04 - activation_1_loss: 6.3254e-05 - activation_2_loss: 7.6128e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0010 - val_activation_1_loss: 3.5606e-05 - val_activation_2_loss: 9.7530e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.2753e-04 - activation_1_loss: 2.9323e-05 - activation_2_loss: 7.9821e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.4885e-04 - val_activation_1_loss: 4.0716e-05 - val_activation_2_loss: 9.0814e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 0.0013 - activation_2_loss: 0.0017 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0030 - val_activation_1_loss: 8.4762e-04 - val_activation_2_loss: 0.0022 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 1.1709e-04 - activation_2_loss: 0.0013 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0011 - val_activation_1_loss: 5.6607e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.4279e-04 - activation_1_loss: 5.1998e-05 - activation_2_loss: 7.9079e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.5231e-04 - val_activation_1_loss: 4.9959e-05 - val_activation_2_loss: 8.0235e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.0406e-04 - activation_1_loss: 5.3894e-05 - activation_2_loss: 6.5017e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.3750e-04 - val_activation_1_loss: 6.1932e-05 - val_activation_2_loss: 5.7557e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 1.4879e-04 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0017 - val_activation_1_loss: 5.7504e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.6947e-04 - activation_1_loss: 6.9403e-05 - activation_2_loss: 7.0007e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.2712e-04 - val_activation_1_loss: 6.8881e-05 - val_activation_2_loss: 6.5824e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.6899e-04 - activation_1_loss: 1.1571e-04 - activation_2_loss: 8.5328e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 5.8848e-04 - val_activation_1_loss: 5.6663e-05 - val_activation_2_loss: 5.3182e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.4914e-04 - activation_1_loss: 7.5050e-05 - activation_2_loss: 8.7409e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0016 - val_activation_1_loss: 6.8069e-05 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.3426e-04 - activation_1_loss: 5.7443e-05 - activation_2_loss: 8.7682e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 4.6992e-04 - val_activation_1_loss: 7.0777e-05 - val_activation_2_loss: 3.9915e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.2948e-04 - activation_1_loss: 5.5977e-05 - activation_2_loss: 6.7351e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.7052e-04 - val_activation_1_loss: 1.2821e-04 - val_activation_2_loss: 6.4231e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 6.9507e-05 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0010 - val_activation_1_loss: 4.3396e-05 - val_activation_2_loss: 9.7601e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 3.9649e-05 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.5409e-04 - val_activation_1_loss: 6.1111e-05 - val_activation_2_loss: 6.9297e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 1.2797e-04 - activation_2_loss: 0.0011 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 6.3239e-04 - val_activation_1_loss: 4.3783e-05 - val_activation_2_loss: 5.8861e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.1137e-04 - activation_1_loss: 3.6884e-05 - activation_2_loss: 8.7449e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.1913e-04 - val_activation_1_loss: 6.2658e-05 - val_activation_2_loss: 7.5647e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9979e-04 - activation_1_loss: 4.8389e-05 - activation_2_loss: 5.5140e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0014 - val_activation_1_loss: 4.4703e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4948e-04 - activation_1_loss: 6.4437e-05 - activation_2_loss: 5.8504e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.2247e-04 - val_activation_1_loss: 5.8629e-05 - val_activation_2_loss: 5.6384e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0023 - activation_1_loss: 6.8211e-04 - activation_2_loss: 0.0016 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0012 - val_activation_1_loss: 2.3647e-04 - val_activation_2_loss: 9.5658e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 1.0543e-04 - activation_2_loss: 0.0012 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0016 - val_activation_1_loss: 5.4508e-05 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.5784e-04 - activation_1_loss: 5.3144e-05 - activation_2_loss: 9.0469e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.1250e-04 - val_activation_1_loss: 7.0631e-05 - val_activation_2_loss: 7.4187e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.6365e-04 - activation_1_loss: 4.5164e-05 - activation_2_loss: 7.1848e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.5224e-04 - val_activation_1_loss: 1.3737e-04 - val_activation_2_loss: 6.1487e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0066 - activation_1_loss: 0.0031 - activation_2_loss: 0.0035 - activation_1_acc: 0.9994 - activation_2_acc: 0.9992 - val_loss: 0.0012 - val_activation_1_loss: 2.1205e-04 - val_activation_2_loss: 9.6485e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.2327e-04 - activation_1_loss: 1.1978e-04 - activation_2_loss: 8.0349e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.1407e-04 - val_activation_1_loss: 5.9062e-05 - val_activation_2_loss: 8.5501e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.0842e-04 - activation_1_loss: 9.7402e-05 - activation_2_loss: 7.1102e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0013 - val_activation_1_loss: 1.1377e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 4.9432e-05 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0013 - val_activation_1_loss: 5.3153e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.3021e-04 - activation_1_loss: 4.3654e-05 - activation_2_loss: 8.8656e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.3392e-04 - val_activation_1_loss: 6.8162e-05 - val_activation_2_loss: 6.6576e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7346e-04 - activation_1_loss: 3.7359e-05 - activation_2_loss: 7.3610e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0010 - val_activation_1_loss: 3.4904e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.2295e-04 - activation_1_loss: 3.3491e-05 - activation_2_loss: 5.8946e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.1444e-04 - val_activation_1_loss: 2.6053e-05 - val_activation_2_loss: 6.8838e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.1471e-04 - activation_1_loss: 3.9401e-05 - activation_2_loss: 7.7531e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 4.0971e-04 - val_activation_1_loss: 4.4516e-05 - val_activation_2_loss: 3.6519e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.0406e-04 - activation_1_loss: 6.1651e-05 - activation_2_loss: 7.4241e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.9218e-04 - val_activation_1_loss: 1.0979e-04 - val_activation_2_loss: 8.8238e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.8705e-04 - activation_1_loss: 5.3724e-05 - activation_2_loss: 7.3333e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.5390e-04 - val_activation_1_loss: 4.0850e-05 - val_activation_2_loss: 7.1305e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7671e-04 - activation_1_loss: 9.1517e-05 - activation_2_loss: 6.8519e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.2452e-04 - val_activation_1_loss: 3.0540e-05 - val_activation_2_loss: 5.9398e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.3372e-04 - activation_1_loss: 6.6693e-05 - activation_2_loss: 7.6702e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 6.8242e-04 - val_activation_1_loss: 4.1066e-05 - val_activation_2_loss: 6.4135e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7892e-04 - activation_1_loss: 3.6756e-05 - activation_2_loss: 7.4216e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.4637e-04 - val_activation_1_loss: 2.9274e-05 - val_activation_2_loss: 9.1710e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.5825e-04 - activation_1_loss: 4.4092e-05 - activation_2_loss: 8.1416e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.5483e-04 - val_activation_1_loss: 7.3915e-05 - val_activation_2_loss: 8.8091e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 6.1754e-04 - activation_2_loss: 0.0015 - activation_1_acc: 0.9998 - activation_2_acc: 0.9995 - val_loss: 0.0017 - val_activation_1_loss: 3.4165e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.1323e-04 - activation_1_loss: 1.7887e-04 - activation_2_loss: 7.3436e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.2769e-04 - val_activation_1_loss: 3.2377e-05 - val_activation_2_loss: 7.9532e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.7002e-04 - activation_1_loss: 4.1919e-05 - activation_2_loss: 9.2810e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.9328e-04 - val_activation_1_loss: 1.2465e-04 - val_activation_2_loss: 8.6863e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.4966e-04 - activation_1_loss: 3.0069e-05 - activation_2_loss: 8.1959e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0011 - val_activation_1_loss: 3.6319e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.0943e-04 - activation_1_loss: 7.1998e-05 - activation_2_loss: 7.3743e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.5976e-04 - val_activation_1_loss: 2.9212e-05 - val_activation_2_loss: 9.3055e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 1.7596e-04 - activation_2_loss: 0.0010 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0013 - val_activation_1_loss: 1.3037e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 2.0935e-04 - activation_2_loss: 0.0011 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0015 - val_activation_1_loss: 5.5719e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.9692e-04 - activation_1_loss: 7.6157e-05 - activation_2_loss: 9.2076e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 5.7740e-04 - val_activation_1_loss: 4.1788e-05 - val_activation_2_loss: 5.3561e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.0751e-04 - activation_1_loss: 2.1515e-04 - activation_2_loss: 5.9237e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.7628e-04 - val_activation_1_loss: 2.3718e-05 - val_activation_2_loss: 4.5256e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.8887e-04 - activation_1_loss: 4.0744e-05 - activation_2_loss: 8.4813e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0011 - val_activation_1_loss: 5.4393e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.3176e-04 - activation_1_loss: 4.2953e-05 - activation_2_loss: 7.8880e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.8205e-04 - val_activation_1_loss: 2.7399e-05 - val_activation_2_loss: 5.5466e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.4519e-04 - activation_1_loss: 2.7012e-05 - activation_2_loss: 7.1818e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 3.6068e-04 - val_activation_1_loss: 4.4328e-05 - val_activation_2_loss: 3.1636e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0307e-04 - activation_1_loss: 2.5616e-05 - activation_2_loss: 3.7745e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.6332e-04 - val_activation_1_loss: 2.0271e-05 - val_activation_2_loss: 5.4305e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7481e-04 - activation_1_loss: 5.4075e-05 - activation_2_loss: 7.2074e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.2321e-04 - val_activation_1_loss: 3.2971e-05 - val_activation_2_loss: 7.9024e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.5277e-04 - activation_1_loss: 3.9695e-05 - activation_2_loss: 7.1307e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0010 - val_activation_1_loss: 3.4678e-05 - val_activation_2_loss: 9.8075e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 9.2236e-05 - activation_2_loss: 9.3112e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9996 - val_loss: 0.0012 - val_activation_1_loss: 6.9462e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 7.5876e-04 - activation_2_loss: 9.8716e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9997 - val_loss: 8.6894e-04 - val_activation_1_loss: 1.3798e-04 - val_activation_2_loss: 7.3096e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 3.8834e-04 - activation_2_loss: 0.0011 - activation_1_acc: 0.9999 - activation_2_acc: 0.9997 - val_loss: 6.1110e-04 - val_activation_1_loss: 5.7025e-05 - val_activation_2_loss: 5.5408e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.5992e-04 - activation_1_loss: 4.4735e-05 - activation_2_loss: 7.1519e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.2619e-04 - val_activation_1_loss: 3.1896e-05 - val_activation_2_loss: 6.9429e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.3442e-04 - activation_1_loss: 4.8195e-05 - activation_2_loss: 6.8623e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.4429e-04 - val_activation_1_loss: 2.6850e-05 - val_activation_2_loss: 8.1744e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9748e-04 - activation_1_loss: 2.3712e-05 - activation_2_loss: 7.7376e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0011 - val_activation_1_loss: 2.5573e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.8616e-04 - activation_1_loss: 4.4392e-05 - activation_2_loss: 7.4176e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.2337e-04 - val_activation_1_loss: 9.0328e-05 - val_activation_2_loss: 3.3304e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5724e-04 - activation_1_loss: 4.7561e-05 - activation_2_loss: 4.0968e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.1436e-04 - val_activation_1_loss: 2.4801e-05 - val_activation_2_loss: 8.8956e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.7435e-04 - activation_1_loss: 4.8772e-05 - activation_2_loss: 5.2558e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.5570e-04 - val_activation_1_loss: 2.2158e-05 - val_activation_2_loss: 6.3354e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7018e-04 - activation_1_loss: 2.4860e-05 - activation_2_loss: 4.4532e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.8481e-04 - val_activation_1_loss: 2.4049e-05 - val_activation_2_loss: 4.6076e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.8766e-04 - activation_1_loss: 3.8868e-05 - activation_2_loss: 9.4880e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 6.5051e-04 - val_activation_1_loss: 4.9112e-05 - val_activation_2_loss: 6.0140e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.5885e-04 - activation_1_loss: 5.5745e-05 - activation_2_loss: 8.0311e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.1441e-04 - val_activation_1_loss: 2.8518e-05 - val_activation_2_loss: 8.8589e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 4.0408e-04 - activation_2_loss: 0.0011 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0013 - val_activation_1_loss: 9.8345e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7018e-04 - activation_1_loss: 5.7247e-05 - activation_2_loss: 7.1294e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 5.4281e-04 - val_activation_1_loss: 4.3507e-05 - val_activation_2_loss: 4.9930e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.7981e-04 - activation_1_loss: 3.4551e-05 - activation_2_loss: 8.4526e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 5.9630e-04 - val_activation_1_loss: 7.2507e-05 - val_activation_2_loss: 5.2379e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.5829e-04 - activation_1_loss: 4.1296e-05 - activation_2_loss: 6.1700e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.0229e-04 - val_activation_1_loss: 5.5141e-05 - val_activation_2_loss: 6.4715e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4265e-04 - activation_1_loss: 6.2364e-05 - activation_2_loss: 5.8029e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.3068e-04 - val_activation_1_loss: 5.4349e-05 - val_activation_2_loss: 6.7633e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.4525e-04 - activation_1_loss: 2.7171e-05 - activation_2_loss: 7.1808e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 5.7445e-04 - val_activation_1_loss: 1.5957e-05 - val_activation_2_loss: 5.5850e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9633e-04 - activation_1_loss: 4.4736e-05 - activation_2_loss: 7.5160e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.7128e-04 - val_activation_1_loss: 2.6126e-05 - val_activation_2_loss: 9.4516e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.2883e-04 - activation_1_loss: 4.3119e-05 - activation_2_loss: 5.8571e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.3982e-04 - val_activation_1_loss: 2.3922e-04 - val_activation_2_loss: 5.0061e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 4.1283e-04 - activation_2_loss: 6.1965e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 0.0012 - val_activation_1_loss: 1.2234e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 3.4380e-04 - activation_2_loss: 0.0012 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 9.0996e-04 - val_activation_1_loss: 1.8691e-04 - val_activation_2_loss: 7.2305e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.1837e-04 - activation_1_loss: 3.8550e-05 - activation_2_loss: 5.7982e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.9175e-04 - val_activation_1_loss: 2.0610e-05 - val_activation_2_loss: 4.7114e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.0481e-04 - activation_1_loss: 4.8811e-05 - activation_2_loss: 6.5600e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.9536e-04 - val_activation_1_loss: 2.8998e-05 - val_activation_2_loss: 9.6637e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.9579e-04 - activation_2_loss: 8.9464e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9997 - val_loss: 0.0018 - val_activation_1_loss: 2.3373e-04 - val_activation_2_loss: 0.0016 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.7461e-04 - activation_1_loss: 8.4931e-05 - activation_2_loss: 7.8968e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 3.9777e-04 - val_activation_1_loss: 1.0543e-04 - val_activation_2_loss: 2.9234e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.0659e-04 - activation_1_loss: 5.5793e-05 - activation_2_loss: 5.5080e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0010 - val_activation_1_loss: 7.4231e-05 - val_activation_2_loss: 9.3969e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 7.1348e-04 - activation_2_loss: 0.0015 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0015 - val_activation_1_loss: 4.9281e-04 - val_activation_2_loss: 9.6459e-04 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.4740e-04 - activation_1_loss: 1.1163e-04 - activation_2_loss: 7.3578e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.6005e-04 - val_activation_1_loss: 7.0268e-05 - val_activation_2_loss: 7.8978e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4613e-04 - activation_1_loss: 2.7289e-05 - activation_2_loss: 6.1884e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.5430e-04 - val_activation_1_loss: 4.2389e-05 - val_activation_2_loss: 7.1191e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.9725e-04 - activation_1_loss: 7.1163e-05 - activation_2_loss: 9.2609e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 6.8948e-04 - val_activation_1_loss: 2.6910e-05 - val_activation_2_loss: 6.6257e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.6399e-04 - activation_1_loss: 1.1899e-04 - activation_2_loss: 6.4501e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.1699e-04 - val_activation_1_loss: 8.2472e-05 - val_activation_2_loss: 5.3452e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.5883e-04 - activation_1_loss: 2.5916e-05 - activation_2_loss: 6.3291e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.4336e-04 - val_activation_1_loss: 3.0661e-05 - val_activation_2_loss: 6.1270e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.6454e-04 - activation_1_loss: 5.6622e-05 - activation_2_loss: 8.0792e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 5.2375e-04 - val_activation_1_loss: 2.3772e-05 - val_activation_2_loss: 4.9997e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0024e-04 - activation_1_loss: 4.4456e-05 - activation_2_loss: 3.5578e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2713e-04 - val_activation_1_loss: 7.4866e-05 - val_activation_2_loss: 3.5227e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1889e-04 - activation_1_loss: 3.1698e-05 - activation_2_loss: 4.8719e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0156e-04 - val_activation_1_loss: 5.1816e-05 - val_activation_2_loss: 3.4974e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.2156e-04 - activation_1_loss: 1.6123e-04 - activation_2_loss: 5.6033e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.3648e-04 - val_activation_1_loss: 3.7096e-05 - val_activation_2_loss: 5.9938e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0032 - activation_1_loss: 0.0012 - activation_2_loss: 0.0020 - activation_1_acc: 0.9998 - activation_2_acc: 0.9995 - val_loss: 0.0011 - val_activation_1_loss: 9.8016e-05 - val_activation_2_loss: 9.9806e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.7416e-04 - activation_1_loss: 9.5967e-05 - activation_2_loss: 7.7819e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0017 - val_activation_1_loss: 3.3802e-04 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 8.3605e-04 - activation_2_loss: 0.0013 - activation_1_acc: 0.9998 - activation_2_acc: 0.9996 - val_loss: 7.7136e-04 - val_activation_1_loss: 7.8791e-05 - val_activation_2_loss: 6.9257e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4049e-04 - activation_1_loss: 5.4396e-05 - activation_2_loss: 5.8609e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.1478e-04 - val_activation_1_loss: 3.2261e-05 - val_activation_2_loss: 4.8252e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.3863e-04 - activation_1_loss: 4.3113e-05 - activation_2_loss: 4.9551e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.0594e-04 - val_activation_1_loss: 3.1517e-05 - val_activation_2_loss: 5.7442e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9478e-04 - activation_1_loss: 8.9281e-05 - activation_2_loss: 5.0550e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.3398e-04 - val_activation_1_loss: 4.0816e-05 - val_activation_2_loss: 8.9316e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.8742e-04 - activation_1_loss: 8.3741e-05 - activation_2_loss: 9.0368e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0011 - val_activation_1_loss: 2.2051e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6308e-04 - activation_1_loss: 2.2637e-05 - activation_2_loss: 5.4044e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.7683e-04 - val_activation_1_loss: 2.8431e-05 - val_activation_2_loss: 4.4840e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.1635e-04 - activation_1_loss: 2.0939e-05 - activation_2_loss: 3.9541e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.9032e-04 - val_activation_1_loss: 1.8808e-05 - val_activation_2_loss: 3.7151e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9390e-04 - activation_1_loss: 2.0156e-05 - activation_2_loss: 5.7374e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.6469e-04 - val_activation_1_loss: 3.1625e-05 - val_activation_2_loss: 9.3307e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0732e-04 - activation_1_loss: 2.1838e-05 - activation_2_loss: 4.8548e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.4708e-04 - val_activation_1_loss: 1.5104e-05 - val_activation_2_loss: 3.3198e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.9425e-04 - activation_1_loss: 2.5599e-05 - activation_2_loss: 6.6865e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.4229e-04 - val_activation_1_loss: 2.1899e-05 - val_activation_2_loss: 6.2039e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.5078e-04 - activation_1_loss: 2.7106e-05 - activation_2_loss: 6.2367e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.7736e-04 - val_activation_1_loss: 2.2954e-05 - val_activation_2_loss: 9.5441e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.7027e-04 - activation_1_loss: 3.6969e-05 - activation_2_loss: 6.3330e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.8146e-04 - val_activation_1_loss: 6.1812e-05 - val_activation_2_loss: 4.1965e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.1027e-04 - activation_1_loss: 1.4895e-04 - activation_2_loss: 7.6132e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.3499e-04 - val_activation_1_loss: 3.5351e-05 - val_activation_2_loss: 6.9964e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8639e-04 - activation_1_loss: 4.0933e-05 - activation_2_loss: 6.4545e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.8081e-04 - val_activation_1_loss: 4.5224e-05 - val_activation_2_loss: 9.3559e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.1177e-04 - activation_1_loss: 3.7896e-05 - activation_2_loss: 6.7387e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.1177e-04 - val_activation_1_loss: 3.0887e-05 - val_activation_2_loss: 5.8089e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7169e-04 - activation_1_loss: 6.0054e-05 - activation_2_loss: 4.1164e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 2.2969e-04 - val_activation_1_loss: 1.6683e-05 - val_activation_2_loss: 2.1301e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.7424e-04 - activation_1_loss: 1.6071e-04 - activation_2_loss: 5.1353e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0010 - val_activation_1_loss: 9.9233e-05 - val_activation_2_loss: 9.3784e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.5989e-04 - activation_1_loss: 6.8624e-05 - activation_2_loss: 6.9126e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.3473e-04 - val_activation_1_loss: 3.1784e-05 - val_activation_2_loss: 7.0295e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1148e-04 - activation_1_loss: 3.5190e-05 - activation_2_loss: 4.7629e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.3091e-04 - val_activation_1_loss: 1.1825e-04 - val_activation_2_loss: 5.1266e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.4120e-04 - activation_1_loss: 4.5803e-05 - activation_2_loss: 7.9540e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 9.3662e-04 - val_activation_1_loss: 2.5692e-05 - val_activation_2_loss: 9.1093e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0392e-04 - activation_1_loss: 3.8384e-05 - activation_2_loss: 4.6554e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.4147e-04 - val_activation_1_loss: 2.5378e-05 - val_activation_2_loss: 3.1609e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.3317e-04 - activation_1_loss: 6.3064e-05 - activation_2_loss: 7.7011e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0011 - val_activation_1_loss: 6.7043e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0024 - activation_1_loss: 0.0011 - activation_2_loss: 0.0014 - activation_1_acc: 0.9998 - activation_2_acc: 0.9996 - val_loss: 5.2878e-04 - val_activation_1_loss: 5.9046e-05 - val_activation_2_loss: 4.6973e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2059e-04 - activation_1_loss: 5.4840e-05 - activation_2_loss: 4.6575e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.9908e-04 - val_activation_1_loss: 2.6635e-05 - val_activation_2_loss: 6.7245e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2204e-04 - activation_1_loss: 3.4082e-05 - activation_2_loss: 4.8796e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.8877e-04 - val_activation_1_loss: 3.0563e-05 - val_activation_2_loss: 3.5821e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.8819e-04 - activation_1_loss: 2.3917e-05 - activation_2_loss: 4.6428e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.8787e-04 - val_activation_1_loss: 3.0848e-05 - val_activation_2_loss: 6.5702e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0023 - activation_1_loss: 6.5061e-04 - activation_2_loss: 0.0017 - activation_1_acc: 0.9999 - activation_2_acc: 0.9996 - val_loss: 0.0072 - val_activation_1_loss: 0.0040 - val_activation_2_loss: 0.0033 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9992\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.3856e-04 - activation_2_loss: 9.5602e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 8.4350e-04 - val_activation_1_loss: 9.0521e-05 - val_activation_2_loss: 7.5298e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.4953e-04 - activation_1_loss: 1.1529e-04 - activation_2_loss: 6.3424e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.6347e-04 - val_activation_1_loss: 3.1883e-05 - val_activation_2_loss: 6.3159e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2059e-04 - activation_1_loss: 2.3024e-05 - activation_2_loss: 3.9756e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.3249e-04 - val_activation_1_loss: 1.1293e-04 - val_activation_2_loss: 5.1956e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5662e-04 - activation_1_loss: 3.0983e-05 - activation_2_loss: 4.2564e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.3456e-04 - val_activation_1_loss: 2.3948e-05 - val_activation_2_loss: 4.1061e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6558e-04 - activation_1_loss: 2.7422e-05 - activation_2_loss: 5.3816e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.8103e-04 - val_activation_1_loss: 2.8005e-05 - val_activation_2_loss: 3.5302e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.3547e-04 - activation_1_loss: 1.7726e-05 - activation_2_loss: 5.1774e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.7579e-04 - val_activation_1_loss: 3.0523e-05 - val_activation_2_loss: 8.4527e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8212e-04 - activation_1_loss: 2.0042e-05 - activation_2_loss: 3.6208e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.2482e-04 - val_activation_1_loss: 3.2131e-05 - val_activation_2_loss: 4.9268e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9383e-04 - activation_1_loss: 2.0940e-05 - activation_2_loss: 5.7289e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.5973e-04 - val_activation_1_loss: 8.3760e-05 - val_activation_2_loss: 6.7597e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8030e-04 - activation_1_loss: 8.8356e-05 - activation_2_loss: 5.9194e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.2139e-04 - val_activation_1_loss: 1.8406e-05 - val_activation_2_loss: 5.0298e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7579e-04 - activation_1_loss: 2.0400e-05 - activation_2_loss: 4.5539e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.5853e-04 - val_activation_1_loss: 5.0535e-05 - val_activation_2_loss: 4.0800e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0799e-04 - activation_1_loss: 2.6696e-05 - activation_2_loss: 4.8130e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.3252e-04 - val_activation_1_loss: 1.6751e-05 - val_activation_2_loss: 3.1577e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.7926e-04 - activation_1_loss: 1.7003e-04 - activation_2_loss: 4.0924e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0216e-04 - val_activation_1_loss: 9.0433e-05 - val_activation_2_loss: 4.1173e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.7036e-04 - activation_2_loss: 9.1471e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 7.0342e-04 - val_activation_1_loss: 1.0691e-04 - val_activation_2_loss: 5.9650e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2813e-04 - activation_1_loss: 3.5942e-05 - activation_2_loss: 4.9219e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6772e-04 - val_activation_1_loss: 3.6626e-05 - val_activation_2_loss: 3.3109e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1760e-04 - activation_1_loss: 4.0620e-05 - activation_2_loss: 4.7698e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.5905e-04 - val_activation_1_loss: 2.7910e-05 - val_activation_2_loss: 3.3114e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1674e-04 - activation_1_loss: 3.8085e-05 - activation_2_loss: 4.7866e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.9747e-04 - val_activation_1_loss: 1.7685e-05 - val_activation_2_loss: 5.7979e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.2148e-04 - activation_1_loss: 4.2550e-05 - activation_2_loss: 8.7893e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 0.0012 - val_activation_1_loss: 3.1300e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0024 - activation_1_loss: 7.6526e-04 - activation_2_loss: 0.0016 - activation_1_acc: 0.9998 - activation_2_acc: 0.9996 - val_loss: 9.5308e-04 - val_activation_1_loss: 6.0088e-05 - val_activation_2_loss: 8.9299e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9570e-04 - activation_1_loss: 4.7643e-05 - activation_2_loss: 7.4806e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 4.0633e-04 - val_activation_1_loss: 3.7468e-05 - val_activation_2_loss: 3.6886e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.8373e-04 - activation_1_loss: 4.8800e-05 - activation_2_loss: 4.3493e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5352e-04 - val_activation_1_loss: 1.3204e-05 - val_activation_2_loss: 3.4032e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8391e-04 - activation_1_loss: 2.1932e-05 - activation_2_loss: 3.6198e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0683e-04 - val_activation_1_loss: 1.5394e-05 - val_activation_2_loss: 1.9143e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9938e-04 - activation_1_loss: 1.3878e-05 - activation_2_loss: 1.8550e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4208e-04 - val_activation_1_loss: 1.3446e-05 - val_activation_2_loss: 2.2863e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1982e-04 - activation_1_loss: 1.9788e-05 - activation_2_loss: 3.0003e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2198e-04 - val_activation_1_loss: 1.7774e-05 - val_activation_2_loss: 4.0420e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.6675e-04 - activation_1_loss: 1.8998e-05 - activation_2_loss: 4.4775e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5618e-04 - val_activation_1_loss: 1.3951e-05 - val_activation_2_loss: 2.4223e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0560e-04 - activation_1_loss: 1.7619e-05 - activation_2_loss: 3.8798e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7192e-04 - val_activation_1_loss: 1.6531e-05 - val_activation_2_loss: 2.5539e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5297e-04 - activation_1_loss: 3.4170e-05 - activation_2_loss: 3.1880e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.1635e-04 - val_activation_1_loss: 3.3169e-05 - val_activation_2_loss: 5.8318e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9280e-04 - activation_1_loss: 3.8832e-05 - activation_2_loss: 7.5397e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.9808e-04 - val_activation_1_loss: 7.3915e-05 - val_activation_2_loss: 4.2417e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0019 - activation_1_loss: 0.0011 - activation_2_loss: 8.1307e-04 - activation_1_acc: 0.9998 - activation_2_acc: 0.9998 - val_loss: 3.7562e-04 - val_activation_1_loss: 3.6990e-05 - val_activation_2_loss: 3.3863e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5837e-04 - activation_1_loss: 4.3141e-05 - activation_2_loss: 4.1523e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.2460e-04 - val_activation_1_loss: 5.3159e-05 - val_activation_2_loss: 7.7144e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7066e-04 - activation_1_loss: 5.5267e-05 - activation_2_loss: 4.1539e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.2889e-04 - val_activation_1_loss: 1.5754e-05 - val_activation_2_loss: 4.1314e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.8017e-04 - activation_1_loss: 5.4730e-05 - activation_2_loss: 5.2544e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.0744e-04 - val_activation_1_loss: 5.7183e-05 - val_activation_2_loss: 5.5026e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.4608e-04 - activation_1_loss: 2.2555e-05 - activation_2_loss: 4.2352e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.8699e-04 - val_activation_1_loss: 1.5670e-05 - val_activation_2_loss: 7.7132e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.5192e-04 - activation_1_loss: 2.7549e-05 - activation_2_loss: 5.2437e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.1151e-04 - val_activation_1_loss: 2.5664e-05 - val_activation_2_loss: 7.8585e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.6940e-04 - activation_1_loss: 1.0181e-04 - activation_2_loss: 3.6759e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1114e-04 - val_activation_1_loss: 2.3347e-05 - val_activation_2_loss: 2.8779e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3986e-04 - activation_1_loss: 1.9017e-05 - activation_2_loss: 3.2084e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.4147e-04 - val_activation_1_loss: 3.6310e-05 - val_activation_2_loss: 7.0516e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4700e-04 - activation_1_loss: 8.1178e-05 - activation_2_loss: 5.6582e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0012 - val_activation_1_loss: 6.6096e-04 - val_activation_2_loss: 5.4254e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6177e-04 - activation_1_loss: 3.3633e-05 - activation_2_loss: 5.2814e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.2509e-04 - val_activation_1_loss: 1.7603e-05 - val_activation_2_loss: 4.0749e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7455e-04 - activation_1_loss: 8.7040e-05 - activation_2_loss: 6.8751e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0011 - val_activation_1_loss: 3.6003e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5791e-04 - activation_1_loss: 2.1387e-05 - activation_2_loss: 3.3652e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.9660e-04 - val_activation_1_loss: 1.2451e-05 - val_activation_2_loss: 4.8415e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2004e-04 - activation_1_loss: 3.8416e-05 - activation_2_loss: 4.8163e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.7500e-04 - val_activation_1_loss: 1.7325e-04 - val_activation_2_loss: 5.0175e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.4860e-04 - activation_1_loss: 9.0646e-05 - activation_2_loss: 4.5795e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 6.1172e-04 - val_activation_2_loss: 4.2101e-04 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.0942e-04 - activation_1_loss: 1.1586e-04 - activation_2_loss: 6.9356e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.3037e-04 - val_activation_1_loss: 1.7639e-05 - val_activation_2_loss: 8.1274e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9056e-04 - activation_1_loss: 2.8157e-05 - activation_2_loss: 4.6241e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.9832e-04 - val_activation_1_loss: 3.0994e-05 - val_activation_2_loss: 3.6732e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3627e-04 - activation_1_loss: 2.0394e-05 - activation_2_loss: 4.1588e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.9773e-04 - val_activation_1_loss: 2.6108e-04 - val_activation_2_loss: 4.3665e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6748e-04 - activation_1_loss: 2.5516e-05 - activation_2_loss: 3.4197e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.6396e-04 - val_activation_1_loss: 2.1380e-04 - val_activation_2_loss: 6.5016e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.9726e-04 - activation_2_loss: 8.7083e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 0.0011 - val_activation_1_loss: 5.0468e-05 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.6634e-04 - activation_1_loss: 3.9342e-05 - activation_2_loss: 6.2700e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.1579e-04 - val_activation_1_loss: 4.1184e-05 - val_activation_2_loss: 6.7460e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6307e-04 - activation_1_loss: 6.7107e-05 - activation_2_loss: 4.9597e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.0067e-04 - val_activation_1_loss: 8.7048e-05 - val_activation_2_loss: 3.1363e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7654e-04 - activation_1_loss: 3.6888e-05 - activation_2_loss: 4.3965e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7905e-04 - val_activation_1_loss: 1.3986e-05 - val_activation_2_loss: 2.6507e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.0593e-04 - activation_1_loss: 3.4570e-05 - activation_2_loss: 5.7136e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.4775e-04 - val_activation_1_loss: 1.4426e-05 - val_activation_2_loss: 3.3333e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8525e-04 - activation_1_loss: 1.8141e-04 - activation_2_loss: 5.0383e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.9222e-04 - val_activation_1_loss: 8.5685e-05 - val_activation_2_loss: 8.0653e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.5149e-04 - activation_1_loss: 1.3087e-04 - activation_2_loss: 4.2061e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0010 - val_activation_1_loss: 2.3930e-04 - val_activation_2_loss: 8.0459e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 1.7615e-04 - activation_2_loss: 8.8233e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9997 - val_loss: 6.2774e-04 - val_activation_1_loss: 5.4736e-05 - val_activation_2_loss: 5.7301e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.8031e-04 - activation_1_loss: 3.2567e-05 - activation_2_loss: 5.4774e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.0436e-04 - val_activation_1_loss: 3.6850e-05 - val_activation_2_loss: 5.6751e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5071e-04 - activation_1_loss: 2.3743e-05 - activation_2_loss: 3.2697e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.6813e-04 - val_activation_1_loss: 2.1756e-05 - val_activation_2_loss: 4.4637e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.8712e-04 - activation_1_loss: 2.3032e-05 - activation_2_loss: 4.6409e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.9418e-04 - val_activation_1_loss: 4.5028e-05 - val_activation_2_loss: 5.4916e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0810e-04 - activation_1_loss: 2.8615e-05 - activation_2_loss: 4.7948e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.5885e-04 - val_activation_1_loss: 2.3686e-05 - val_activation_2_loss: 3.3516e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1856e-04 - activation_1_loss: 2.1427e-05 - activation_2_loss: 4.9714e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.5864e-04 - val_activation_1_loss: 1.5414e-05 - val_activation_2_loss: 3.4322e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.4451e-04 - activation_1_loss: 1.1274e-04 - activation_2_loss: 6.3176e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.5462e-04 - val_activation_1_loss: 1.3698e-05 - val_activation_2_loss: 5.4092e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9098e-04 - activation_1_loss: 8.4781e-05 - activation_2_loss: 5.0619e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.7797e-04 - val_activation_1_loss: 2.0709e-04 - val_activation_2_loss: 3.7088e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0712e-04 - activation_1_loss: 1.3214e-04 - activation_2_loss: 3.7498e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.3532e-04 - val_activation_1_loss: 2.3168e-05 - val_activation_2_loss: 4.1216e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5755e-04 - activation_1_loss: 3.3541e-05 - activation_2_loss: 4.2401e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8080e-04 - val_activation_1_loss: 5.6907e-05 - val_activation_2_loss: 2.2389e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4055e-04 - activation_1_loss: 1.8166e-05 - activation_2_loss: 3.2239e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0381e-04 - val_activation_1_loss: 1.7678e-05 - val_activation_2_loss: 4.8613e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5788e-04 - activation_1_loss: 1.5814e-05 - activation_2_loss: 3.4206e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2577e-04 - val_activation_1_loss: 7.9627e-06 - val_activation_2_loss: 1.1780e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0408e-04 - activation_1_loss: 1.6475e-05 - activation_2_loss: 2.8760e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0550e-04 - val_activation_1_loss: 1.2831e-05 - val_activation_2_loss: 9.2671e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3386e-04 - activation_1_loss: 1.8890e-05 - activation_2_loss: 4.1497e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2302e-04 - val_activation_1_loss: 2.9408e-05 - val_activation_2_loss: 9.3610e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9757e-04 - activation_1_loss: 3.7045e-05 - activation_2_loss: 3.6053e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.5373e-04 - val_activation_1_loss: 5.9989e-05 - val_activation_2_loss: 3.9374e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.2494e-04 - activation_1_loss: 2.8136e-05 - activation_2_loss: 5.9680e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.4593e-04 - val_activation_1_loss: 1.4412e-04 - val_activation_2_loss: 7.0181e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2427e-04 - activation_1_loss: 2.5868e-05 - activation_2_loss: 3.9840e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2515e-04 - val_activation_1_loss: 2.8278e-05 - val_activation_2_loss: 1.9687e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0279e-04 - activation_1_loss: 2.1655e-05 - activation_2_loss: 1.8113e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9162e-04 - val_activation_1_loss: 1.2541e-05 - val_activation_2_loss: 2.7908e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0022 - activation_1_loss: 9.3005e-04 - activation_2_loss: 0.0013 - activation_1_acc: 0.9998 - activation_2_acc: 0.9997 - val_loss: 0.0015 - val_activation_1_loss: 3.0911e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.3578e-04 - activation_1_loss: 2.1135e-04 - activation_2_loss: 7.2443e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.1385e-04 - val_activation_1_loss: 2.6514e-05 - val_activation_2_loss: 2.8733e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.5658e-04 - activation_1_loss: 3.1467e-05 - activation_2_loss: 6.2511e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 2.0148e-04 - val_activation_1_loss: 1.9922e-05 - val_activation_2_loss: 1.8156e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.7214e-04 - activation_1_loss: 2.9720e-05 - activation_2_loss: 5.4242e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4877e-04 - val_activation_1_loss: 2.0166e-05 - val_activation_2_loss: 3.2861e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.6963e-04 - activation_1_loss: 1.3314e-05 - activation_2_loss: 2.5631e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0989e-04 - val_activation_1_loss: 1.1018e-05 - val_activation_2_loss: 2.9888e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7939e-04 - activation_1_loss: 1.5378e-05 - activation_2_loss: 2.6401e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8436e-04 - val_activation_1_loss: 1.0488e-05 - val_activation_2_loss: 3.7387e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9720e-04 - activation_1_loss: 2.0495e-05 - activation_2_loss: 2.7670e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0013 - val_activation_1_loss: 4.0817e-04 - val_activation_2_loss: 9.3752e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9783e-04 - activation_1_loss: 2.0000e-05 - activation_2_loss: 2.7783e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1071e-04 - val_activation_1_loss: 8.1707e-06 - val_activation_2_loss: 1.0254e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0761e-04 - activation_1_loss: 1.4056e-05 - activation_2_loss: 2.9355e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5199e-04 - val_activation_1_loss: 9.8149e-06 - val_activation_2_loss: 3.4218e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0049e-04 - activation_1_loss: 1.5541e-05 - activation_2_loss: 4.8495e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.5999e-04 - val_activation_1_loss: 2.3401e-05 - val_activation_2_loss: 3.3659e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4519e-04 - activation_1_loss: 2.0875e-05 - activation_2_loss: 2.2431e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.3578e-04 - val_activation_1_loss: 7.5556e-05 - val_activation_2_loss: 5.6022e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2252e-04 - activation_1_loss: 3.9048e-05 - activation_2_loss: 3.8347e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0336e-04 - val_activation_1_loss: 7.5277e-05 - val_activation_2_loss: 4.2809e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.4464e-04 - activation_1_loss: 1.7556e-05 - activation_2_loss: 4.2709e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.8447e-04 - val_activation_1_loss: 2.0758e-05 - val_activation_2_loss: 5.6371e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4055e-04 - activation_1_loss: 2.2379e-05 - activation_2_loss: 3.1817e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 3.4514e-04 - val_activation_2_loss: 6.8595e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7949e-04 - activation_1_loss: 4.4061e-05 - activation_2_loss: 3.3543e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.7486e-04 - val_activation_1_loss: 2.2865e-05 - val_activation_2_loss: 4.5200e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0017 - activation_1_loss: 4.8839e-04 - activation_2_loss: 0.0012 - activation_1_acc: 0.9999 - activation_2_acc: 0.9997 - val_loss: 6.6368e-04 - val_activation_1_loss: 1.0337e-04 - val_activation_2_loss: 5.6031e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1366e-04 - activation_1_loss: 9.8059e-05 - activation_2_loss: 4.1561e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7437e-04 - val_activation_1_loss: 4.7402e-05 - val_activation_2_loss: 2.2697e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.0061e-04 - activation_1_loss: 9.7739e-05 - activation_2_loss: 5.0287e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.7967e-04 - val_activation_1_loss: 2.4771e-05 - val_activation_2_loss: 4.5489e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.5271e-04 - activation_1_loss: 1.1364e-04 - activation_2_loss: 5.3907e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.3343e-04 - val_activation_1_loss: 5.5192e-05 - val_activation_2_loss: 4.7824e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6006e-04 - activation_1_loss: 2.2646e-05 - activation_2_loss: 5.3741e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.6159e-04 - val_activation_1_loss: 4.1692e-05 - val_activation_2_loss: 6.1990e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9234e-04 - activation_1_loss: 3.4166e-05 - activation_2_loss: 2.5817e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4569e-04 - val_activation_1_loss: 1.9149e-05 - val_activation_2_loss: 4.2654e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0864e-04 - activation_1_loss: 1.8867e-05 - activation_2_loss: 3.8978e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4887e-04 - val_activation_1_loss: 1.7215e-05 - val_activation_2_loss: 2.3166e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6941e-04 - activation_1_loss: 1.3345e-05 - activation_2_loss: 3.5606e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0855e-04 - val_activation_1_loss: 1.1183e-05 - val_activation_2_loss: 2.9737e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.1870e-04 - activation_1_loss: 1.6909e-04 - activation_2_loss: 7.4961e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0013 - val_activation_1_loss: 6.1355e-04 - val_activation_2_loss: 6.7764e-04 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0029 - activation_1_loss: 0.0017 - activation_2_loss: 0.0012 - activation_1_acc: 0.9998 - activation_2_acc: 0.9997 - val_loss: 8.9564e-04 - val_activation_1_loss: 3.0633e-04 - val_activation_2_loss: 5.8931e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.1528e-04 - activation_1_loss: 1.3100e-04 - activation_2_loss: 4.8428e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.7523e-04 - val_activation_1_loss: 2.8848e-05 - val_activation_2_loss: 3.4639e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.1370e-04 - activation_1_loss: 2.9798e-05 - activation_2_loss: 3.8390e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0085e-04 - val_activation_1_loss: 3.4128e-05 - val_activation_2_loss: 4.6672e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6756e-04 - activation_1_loss: 2.5574e-05 - activation_2_loss: 3.4199e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9443e-04 - val_activation_1_loss: 1.8938e-05 - val_activation_2_loss: 3.7549e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5725e-04 - activation_1_loss: 2.4130e-05 - activation_2_loss: 3.3312e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8798e-04 - val_activation_1_loss: 1.1801e-05 - val_activation_2_loss: 3.7618e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6537e-04 - activation_1_loss: 4.6014e-05 - activation_2_loss: 3.1936e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9245e-04 - val_activation_1_loss: 1.2478e-05 - val_activation_2_loss: 1.7997e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6102e-04 - activation_1_loss: 5.4721e-05 - activation_2_loss: 5.0630e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.8725e-04 - val_activation_1_loss: 5.2441e-05 - val_activation_2_loss: 8.3481e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7140e-04 - activation_1_loss: 2.0675e-05 - activation_2_loss: 2.5073e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0868e-04 - val_activation_1_loss: 7.8415e-06 - val_activation_2_loss: 3.0084e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7073e-04 - activation_1_loss: 1.4815e-05 - activation_2_loss: 3.5592e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.3327e-04 - val_activation_1_loss: 2.8826e-05 - val_activation_2_loss: 4.0445e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9433e-04 - activation_1_loss: 4.1156e-05 - activation_2_loss: 3.5318e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.2469e-04 - val_activation_1_loss: 3.3281e-05 - val_activation_2_loss: 2.9141e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8652e-04 - activation_1_loss: 2.0959e-05 - activation_2_loss: 3.6556e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.4283e-04 - val_activation_1_loss: 1.7607e-05 - val_activation_2_loss: 8.2522e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7190e-04 - activation_1_loss: 1.3048e-05 - activation_2_loss: 2.5886e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6769e-04 - val_activation_1_loss: 8.5871e-06 - val_activation_2_loss: 2.5911e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.8694e-04 - activation_1_loss: 2.5483e-05 - activation_2_loss: 4.6146e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.2545e-04 - val_activation_1_loss: 3.5185e-05 - val_activation_2_loss: 2.9027e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3340e-04 - activation_1_loss: 2.1714e-05 - activation_2_loss: 2.1169e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.1380e-04 - val_activation_1_loss: 6.2545e-05 - val_activation_2_loss: 3.5125e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3478e-04 - activation_1_loss: 4.0726e-05 - activation_2_loss: 1.9405e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4202e-04 - val_activation_1_loss: 8.6786e-06 - val_activation_2_loss: 2.3334e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7030e-04 - activation_1_loss: 2.4532e-05 - activation_2_loss: 2.4577e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7154e-04 - val_activation_1_loss: 1.5115e-05 - val_activation_2_loss: 1.5642e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5145e-04 - activation_1_loss: 1.2693e-05 - activation_2_loss: 1.3876e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4356e-04 - val_activation_1_loss: 6.3835e-05 - val_activation_2_loss: 8.7972e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0015 - activation_1_loss: 6.4280e-04 - activation_2_loss: 8.7567e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 3.5756e-04 - val_activation_1_loss: 9.3592e-05 - val_activation_2_loss: 2.6397e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.6238e-04 - activation_1_loss: 2.6446e-04 - activation_2_loss: 4.9791e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 9.6299e-04 - val_activation_1_loss: 6.1907e-04 - val_activation_2_loss: 3.4391e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9660e-04 - activation_1_loss: 2.2971e-04 - activation_2_loss: 5.6688e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.5093e-04 - val_activation_1_loss: 7.1957e-05 - val_activation_2_loss: 5.7897e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.7556e-04 - activation_1_loss: 3.5720e-05 - activation_2_loss: 5.3984e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.3718e-04 - val_activation_1_loss: 7.2585e-05 - val_activation_2_loss: 2.6459e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.8533e-04 - activation_1_loss: 1.5979e-04 - activation_2_loss: 6.2554e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 6.6575e-04 - val_activation_1_loss: 4.9763e-05 - val_activation_2_loss: 6.1599e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6440e-04 - activation_1_loss: 4.6891e-05 - activation_2_loss: 5.1751e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.7458e-04 - val_activation_1_loss: 1.2258e-05 - val_activation_2_loss: 3.6232e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2492e-04 - activation_1_loss: 1.4877e-05 - activation_2_loss: 2.1004e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6639e-04 - val_activation_1_loss: 3.2917e-05 - val_activation_2_loss: 2.3348e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2124e-04 - activation_1_loss: 1.2098e-05 - activation_2_loss: 1.0914e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9882e-04 - val_activation_1_loss: 2.1745e-05 - val_activation_2_loss: 2.7707e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6789e-04 - activation_1_loss: 1.4527e-05 - activation_2_loss: 5.5336e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.5308e-04 - val_activation_1_loss: 1.8717e-05 - val_activation_2_loss: 3.3437e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6665e-04 - activation_1_loss: 4.7109e-05 - activation_2_loss: 3.1954e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1559e-04 - val_activation_1_loss: 1.7665e-05 - val_activation_2_loss: 1.9793e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2383e-04 - activation_1_loss: 1.7152e-05 - activation_2_loss: 4.0668e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2625e-04 - val_activation_1_loss: 3.1526e-05 - val_activation_2_loss: 1.9472e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5568e-04 - activation_1_loss: 1.4552e-05 - activation_2_loss: 2.4112e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0408e-04 - val_activation_1_loss: 2.6780e-05 - val_activation_2_loss: 1.7730e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.6073e-04 - activation_1_loss: 7.9424e-05 - activation_2_loss: 3.8131e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0015 - val_activation_1_loss: 8.5072e-05 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8331e-04 - activation_1_loss: 3.0137e-05 - activation_2_loss: 3.5318e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1273e-04 - val_activation_1_loss: 5.0693e-05 - val_activation_2_loss: 1.6204e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3115e-04 - activation_1_loss: 2.1777e-05 - activation_2_loss: 4.0938e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7530e-04 - val_activation_1_loss: 1.4824e-05 - val_activation_2_loss: 1.6048e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0998e-04 - activation_1_loss: 3.6822e-05 - activation_2_loss: 3.7316e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 2.1136e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0251e-04 - activation_1_loss: 5.7141e-05 - activation_2_loss: 4.4537e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.7494e-04 - val_activation_1_loss: 4.1104e-05 - val_activation_2_loss: 5.3384e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7819e-04 - activation_1_loss: 2.4388e-05 - activation_2_loss: 3.5381e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 1.5430e-05 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4302e-04 - activation_1_loss: 4.2816e-05 - activation_2_loss: 6.0021e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9864e-04 - val_activation_1_loss: 9.4052e-06 - val_activation_2_loss: 1.8923e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.8094e-04 - activation_1_loss: 1.2119e-04 - activation_2_loss: 6.5975e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0013 - val_activation_1_loss: 3.4110e-05 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3847e-04 - activation_1_loss: 9.7356e-05 - activation_2_loss: 3.4111e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3930e-04 - val_activation_1_loss: 3.4361e-05 - val_activation_2_loss: 2.0494e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.3647e-04 - activation_1_loss: 1.9668e-04 - activation_2_loss: 5.3980e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.9234e-04 - val_activation_1_loss: 1.1179e-04 - val_activation_2_loss: 6.8055e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0759e-04 - activation_1_loss: 2.4310e-05 - activation_2_loss: 3.8328e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 4.5715e-04 - val_activation_1_loss: 1.4894e-05 - val_activation_2_loss: 4.4226e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.5367e-04 - activation_1_loss: 4.1578e-05 - activation_2_loss: 5.1209e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.3432e-04 - val_activation_1_loss: 4.2426e-05 - val_activation_2_loss: 4.9189e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0639e-04 - activation_1_loss: 3.2286e-05 - activation_2_loss: 3.7410e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 7.8041e-06 - val_activation_2_loss: 0.0010 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 3.6474e-04 - activation_2_loss: 7.9172e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 9.9525e-04 - val_activation_1_loss: 5.2914e-04 - val_activation_2_loss: 4.6611e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.3676e-04 - activation_1_loss: 1.6660e-04 - activation_2_loss: 4.7016e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2880e-04 - val_activation_1_loss: 1.3956e-05 - val_activation_2_loss: 4.1485e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4411e-04 - activation_1_loss: 2.3476e-05 - activation_2_loss: 3.2064e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.3087e-04 - val_activation_1_loss: 1.7486e-05 - val_activation_2_loss: 7.1339e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7333e-04 - activation_1_loss: 1.6206e-05 - activation_2_loss: 3.5713e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8804e-04 - val_activation_1_loss: 2.0991e-05 - val_activation_2_loss: 2.6705e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3201e-04 - activation_1_loss: 1.2470e-05 - activation_2_loss: 3.1954e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6309e-04 - val_activation_1_loss: 1.5703e-05 - val_activation_2_loss: 2.4739e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.9630e-04 - activation_1_loss: 1.5792e-04 - activation_2_loss: 5.3838e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0013 - val_activation_1_loss: 8.8178e-04 - val_activation_2_loss: 4.1213e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.9032e-04 - activation_1_loss: 3.6215e-04 - activation_2_loss: 6.2818e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0015 - val_activation_1_loss: 4.3330e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 4.4860e-04 - activation_2_loss: 6.2601e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 1.7429e-04 - val_activation_1_loss: 2.4010e-05 - val_activation_2_loss: 1.5028e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.1285e-04 - activation_1_loss: 3.7136e-05 - activation_2_loss: 3.7571e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.7213e-04 - val_activation_1_loss: 1.7974e-05 - val_activation_2_loss: 5.5416e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8066e-04 - activation_1_loss: 3.4980e-05 - activation_2_loss: 2.4568e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1156e-04 - val_activation_1_loss: 1.1887e-05 - val_activation_2_loss: 9.9675e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0701e-04 - activation_1_loss: 2.2429e-05 - activation_2_loss: 3.8458e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7659e-04 - val_activation_1_loss: 2.0386e-05 - val_activation_2_loss: 3.5621e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2559e-04 - activation_1_loss: 1.8524e-05 - activation_2_loss: 2.0707e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7567e-04 - val_activation_1_loss: 1.5939e-05 - val_activation_2_loss: 1.5973e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1548e-04 - activation_1_loss: 1.7364e-05 - activation_2_loss: 2.9811e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6885e-04 - val_activation_1_loss: 1.0666e-05 - val_activation_2_loss: 3.5818e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1768e-04 - activation_1_loss: 1.5075e-05 - activation_2_loss: 2.0260e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9079e-04 - val_activation_1_loss: 1.0428e-05 - val_activation_2_loss: 2.8037e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.3032e-04 - activation_1_loss: 2.1918e-05 - activation_2_loss: 5.0840e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.2665e-04 - val_activation_1_loss: 1.3641e-05 - val_activation_2_loss: 3.1301e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7528e-04 - activation_1_loss: 1.6504e-05 - activation_2_loss: 2.5877e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7423e-04 - val_activation_1_loss: 1.1363e-05 - val_activation_2_loss: 1.6287e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9837e-04 - activation_1_loss: 1.0765e-05 - activation_2_loss: 1.8761e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4561e-04 - val_activation_1_loss: 3.3474e-05 - val_activation_2_loss: 1.1213e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.0971e-04 - activation_1_loss: 2.0105e-04 - activation_2_loss: 3.0867e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0115e-04 - val_activation_1_loss: 1.6950e-05 - val_activation_2_loss: 1.8420e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9174e-04 - activation_1_loss: 3.1685e-05 - activation_2_loss: 4.6006e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.8192e-04 - val_activation_1_loss: 1.7917e-05 - val_activation_2_loss: 5.6401e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2843e-04 - activation_1_loss: 7.0066e-05 - activation_2_loss: 3.5837e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.4650e-04 - val_activation_1_loss: 2.7569e-05 - val_activation_2_loss: 6.1893e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0197e-04 - activation_1_loss: 2.1398e-05 - activation_2_loss: 2.8057e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.6525e-04 - val_activation_1_loss: 2.6822e-05 - val_activation_2_loss: 5.3843e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.8803e-04 - activation_1_loss: 4.2147e-05 - activation_2_loss: 5.4588e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 2.3519e-04 - val_activation_1_loss: 3.2779e-05 - val_activation_2_loss: 2.0241e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3517e-04 - activation_1_loss: 6.5607e-05 - activation_2_loss: 3.6956e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6708e-04 - val_activation_1_loss: 1.6358e-05 - val_activation_2_loss: 1.5072e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.4340e-04 - activation_1_loss: 2.4460e-05 - activation_2_loss: 5.1894e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5603e-04 - val_activation_1_loss: 1.2756e-05 - val_activation_2_loss: 3.4328e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7977e-04 - activation_1_loss: 3.8231e-05 - activation_2_loss: 2.4154e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9256e-04 - val_activation_1_loss: 3.9654e-05 - val_activation_2_loss: 1.5291e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9716e-04 - activation_1_loss: 5.0957e-05 - activation_2_loss: 4.4620e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.2170e-04 - val_activation_1_loss: 1.7469e-05 - val_activation_2_loss: 5.0423e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3821e-04 - activation_1_loss: 3.8350e-05 - activation_2_loss: 2.9986e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6570e-04 - val_activation_1_loss: 2.1252e-05 - val_activation_2_loss: 2.4445e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5876e-04 - activation_1_loss: 2.9136e-05 - activation_2_loss: 4.2963e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1694e-04 - val_activation_1_loss: 1.8350e-05 - val_activation_2_loss: 1.9859e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 7.8568e-04 - activation_2_loss: 0.0013 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 0.0019 - val_activation_1_loss: 4.1612e-04 - val_activation_2_loss: 0.0015 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9995\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.5487e-04 - activation_1_loss: 1.2709e-04 - activation_2_loss: 6.2778e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 8.3242e-04 - val_activation_1_loss: 1.0130e-04 - val_activation_2_loss: 7.3112e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6818e-04 - activation_1_loss: 5.7187e-05 - activation_2_loss: 3.1100e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.8690e-04 - val_activation_1_loss: 4.3134e-05 - val_activation_2_loss: 4.4376e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9001e-04 - activation_1_loss: 3.8321e-05 - activation_2_loss: 3.5168e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1285e-04 - val_activation_1_loss: 1.0681e-05 - val_activation_2_loss: 1.0216e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9442e-04 - activation_1_loss: 2.3193e-05 - activation_2_loss: 3.7123e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7697e-04 - val_activation_1_loss: 4.7310e-05 - val_activation_2_loss: 1.2966e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7548e-04 - activation_1_loss: 2.3116e-05 - activation_2_loss: 2.5236e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.1648e-04 - val_activation_1_loss: 9.7899e-06 - val_activation_2_loss: 4.0669e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6072e-04 - activation_1_loss: 2.1363e-05 - activation_2_loss: 3.3935e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.0070e-04 - val_activation_1_loss: 1.2520e-05 - val_activation_2_loss: 5.8818e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7605e-04 - activation_1_loss: 9.1697e-06 - activation_2_loss: 1.6688e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0953e-04 - val_activation_1_loss: 1.9877e-05 - val_activation_2_loss: 1.8965e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0590e-04 - activation_1_loss: 1.3870e-05 - activation_2_loss: 1.9203e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.1790e-04 - val_activation_1_loss: 2.8856e-05 - val_activation_2_loss: 5.8905e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1569e-04 - activation_1_loss: 2.1247e-05 - activation_2_loss: 2.9445e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6732e-04 - val_activation_1_loss: 4.4343e-05 - val_activation_2_loss: 2.2298e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0913e-04 - activation_1_loss: 1.0874e-05 - activation_2_loss: 1.9825e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7806e-04 - val_activation_1_loss: 6.3255e-06 - val_activation_2_loss: 1.7174e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2452e-04 - activation_1_loss: 9.8056e-06 - activation_2_loss: 1.1471e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6951e-04 - val_activation_1_loss: 7.4240e-06 - val_activation_2_loss: 4.6209e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3116e-04 - activation_1_loss: 7.2305e-05 - activation_2_loss: 3.5886e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5141e-04 - val_activation_1_loss: 2.4725e-05 - val_activation_2_loss: 3.2669e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.4731e-04 - activation_1_loss: 4.0711e-05 - activation_2_loss: 5.0660e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0021 - val_activation_1_loss: 6.8730e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9558e-04 - activation_1_loss: 1.0607e-05 - activation_2_loss: 1.8498e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3100e-04 - val_activation_1_loss: 1.4953e-05 - val_activation_2_loss: 1.1605e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8269e-04 - activation_1_loss: 3.0829e-05 - activation_2_loss: 3.5186e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1387e-04 - val_activation_1_loss: 9.8102e-06 - val_activation_2_loss: 3.0406e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3969e-04 - activation_1_loss: 7.0474e-05 - activation_2_loss: 2.6922e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.1418e-04 - val_activation_1_loss: 2.0319e-05 - val_activation_2_loss: 4.9386e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6565e-04 - activation_1_loss: 1.9099e-05 - activation_2_loss: 3.4655e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2873e-04 - val_activation_1_loss: 3.6464e-05 - val_activation_2_loss: 3.9227e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4339e-04 - activation_1_loss: 2.0960e-05 - activation_2_loss: 3.2243e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2222e-04 - val_activation_1_loss: 8.3381e-06 - val_activation_2_loss: 4.1389e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.5380e-04 - activation_1_loss: 6.4668e-05 - activation_2_loss: 5.8913e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.0629e-04 - val_activation_1_loss: 2.7558e-04 - val_activation_2_loss: 4.3071e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0301e-04 - activation_1_loss: 9.5358e-05 - activation_2_loss: 2.0765e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.9394e-04 - val_activation_1_loss: 9.0393e-05 - val_activation_2_loss: 5.0355e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.3648e-04 - activation_1_loss: 3.6966e-04 - activation_2_loss: 5.6683e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 0.0011 - val_activation_1_loss: 2.3013e-04 - val_activation_2_loss: 9.1449e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3595e-04 - activation_1_loss: 7.1011e-05 - activation_2_loss: 3.6494e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1539e-04 - val_activation_1_loss: 2.0638e-05 - val_activation_2_loss: 2.9475e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.1395e-04 - activation_1_loss: 8.4816e-05 - activation_2_loss: 3.2914e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4441e-04 - val_activation_1_loss: 1.5716e-05 - val_activation_2_loss: 4.2869e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0810e-04 - activation_1_loss: 1.6443e-05 - activation_2_loss: 1.9165e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0778e-04 - val_activation_1_loss: 6.7490e-06 - val_activation_2_loss: 3.0103e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2201e-04 - activation_1_loss: 9.2045e-06 - activation_2_loss: 2.1281e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.3045e-04 - val_activation_1_loss: 1.0005e-05 - val_activation_2_loss: 7.2045e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9590e-04 - activation_1_loss: 1.2230e-05 - activation_2_loss: 2.8367e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6791e-04 - val_activation_1_loss: 9.9637e-06 - val_activation_2_loss: 2.5794e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4627e-04 - activation_1_loss: 1.3552e-05 - activation_2_loss: 1.3272e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6629e-04 - val_activation_1_loss: 5.4885e-06 - val_activation_2_loss: 1.6080e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3689e-04 - activation_1_loss: 8.1616e-06 - activation_2_loss: 2.2872e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.6156e-04 - val_activation_1_loss: 8.1327e-06 - val_activation_2_loss: 7.5343e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1272e-04 - activation_1_loss: 1.7988e-05 - activation_2_loss: 2.9474e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2971e-04 - val_activation_1_loss: 1.2706e-05 - val_activation_2_loss: 4.1700e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1765e-04 - activation_1_loss: 8.5710e-06 - activation_2_loss: 2.0908e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4629e-04 - val_activation_1_loss: 5.3083e-06 - val_activation_2_loss: 4.4098e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 0.0016 - activation_2_loss: 0.0014 - activation_1_acc: 0.9998 - activation_2_acc: 0.9998 - val_loss: 0.0062 - val_activation_1_loss: 0.0030 - val_activation_2_loss: 0.0031 - val_activation_1_acc: 0.9995 - val_activation_2_acc: 0.9993\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.6612e-04 - activation_1_loss: 3.8214e-04 - activation_2_loss: 5.8398e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 3.0238e-04 - val_activation_1_loss: 3.3228e-05 - val_activation_2_loss: 2.6915e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6714e-04 - activation_1_loss: 2.7791e-05 - activation_2_loss: 3.3935e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.8230e-04 - val_activation_1_loss: 2.0620e-04 - val_activation_2_loss: 3.7610e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3419e-04 - activation_1_loss: 3.5219e-05 - activation_2_loss: 1.9897e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2976e-04 - val_activation_1_loss: 1.2842e-05 - val_activation_2_loss: 2.1692e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.9937e-04 - activation_1_loss: 3.7032e-05 - activation_2_loss: 7.6234e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 7.3697e-04 - val_activation_1_loss: 6.4572e-05 - val_activation_2_loss: 6.7240e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4175e-04 - activation_1_loss: 2.7531e-05 - activation_2_loss: 3.1422e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.8145e-04 - val_activation_1_loss: 3.7345e-05 - val_activation_2_loss: 4.4411e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3478e-04 - activation_1_loss: 1.4210e-05 - activation_2_loss: 2.2057e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.9195e-04 - val_activation_1_loss: 2.0084e-05 - val_activation_2_loss: 4.7187e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.6612e-04 - activation_1_loss: 1.4329e-05 - activation_2_loss: 1.5179e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3264e-04 - val_activation_1_loss: 5.4116e-06 - val_activation_2_loss: 1.2723e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8826e-04 - activation_1_loss: 1.7239e-05 - activation_2_loss: 1.7102e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6305e-04 - val_activation_1_loss: 9.2632e-06 - val_activation_2_loss: 3.5379e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2754e-04 - activation_1_loss: 1.0659e-05 - activation_2_loss: 1.1688e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9113e-04 - val_activation_1_loss: 8.7158e-06 - val_activation_2_loss: 1.8241e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9609e-04 - activation_1_loss: 1.5355e-05 - activation_2_loss: 1.8074e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4614e-04 - val_activation_1_loss: 8.1556e-06 - val_activation_2_loss: 3.3799e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4524e-04 - activation_1_loss: 5.2981e-05 - activation_2_loss: 1.9226e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4685e-04 - val_activation_1_loss: 7.4690e-06 - val_activation_2_loss: 3.3938e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1002e-04 - activation_1_loss: 3.3341e-05 - activation_2_loss: 7.6680e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0588e-04 - val_activation_1_loss: 8.2201e-06 - val_activation_2_loss: 9.7657e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9455e-04 - activation_1_loss: 5.2381e-05 - activation_2_loss: 4.4217e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0498e-04 - val_activation_1_loss: 5.1621e-05 - val_activation_2_loss: 4.5336e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 5.6851e-04 - activation_2_loss: 5.5837e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 0.0011 - val_activation_1_loss: 2.3223e-04 - val_activation_2_loss: 8.9439e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9840e-04 - activation_1_loss: 1.0978e-04 - activation_2_loss: 4.8863e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4298e-04 - val_activation_1_loss: 1.4109e-04 - val_activation_2_loss: 2.0189e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4839e-04 - activation_1_loss: 5.1266e-05 - activation_2_loss: 2.9713e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6724e-04 - val_activation_1_loss: 1.7202e-05 - val_activation_2_loss: 1.5004e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9390e-04 - activation_1_loss: 1.7723e-05 - activation_2_loss: 3.7617e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4137e-04 - val_activation_1_loss: 1.8841e-05 - val_activation_2_loss: 2.2253e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1138e-04 - activation_1_loss: 1.3890e-05 - activation_2_loss: 1.9749e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3507e-04 - val_activation_1_loss: 1.9664e-05 - val_activation_2_loss: 1.1541e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9230e-04 - activation_1_loss: 2.5034e-05 - activation_2_loss: 1.6727e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2095e-04 - val_activation_1_loss: 1.7225e-05 - val_activation_2_loss: 1.0372e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8610e-04 - activation_1_loss: 1.3018e-05 - activation_2_loss: 1.7308e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3238e-04 - val_activation_1_loss: 2.9608e-05 - val_activation_2_loss: 1.0277e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3481e-04 - activation_1_loss: 1.6972e-05 - activation_2_loss: 4.1784e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5060e-04 - val_activation_1_loss: 1.3570e-05 - val_activation_2_loss: 2.3703e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2764e-04 - activation_1_loss: 2.0287e-05 - activation_2_loss: 5.0735e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 5.1438e-04 - val_activation_1_loss: 3.1900e-05 - val_activation_2_loss: 4.8248e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0594e-04 - activation_1_loss: 2.7080e-05 - activation_2_loss: 2.7886e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8680e-04 - val_activation_1_loss: 1.2803e-05 - val_activation_2_loss: 1.7400e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1325e-04 - activation_1_loss: 1.4324e-05 - activation_2_loss: 2.9893e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6825e-04 - val_activation_1_loss: 1.6243e-05 - val_activation_2_loss: 3.5201e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5696e-04 - activation_1_loss: 2.2044e-05 - activation_2_loss: 2.3491e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.2620e-04 - val_activation_1_loss: 2.7551e-05 - val_activation_2_loss: 2.9864e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.3062e-04 - activation_1_loss: 6.8375e-05 - activation_2_loss: 4.6224e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.6029e-04 - val_activation_1_loss: 4.1921e-05 - val_activation_2_loss: 3.1837e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8246e-04 - activation_1_loss: 5.5711e-05 - activation_2_loss: 3.2675e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1291e-04 - val_activation_1_loss: 1.3265e-05 - val_activation_2_loss: 1.9964e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8033e-04 - activation_1_loss: 5.2240e-05 - activation_2_loss: 3.2809e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5995e-04 - val_activation_1_loss: 1.3184e-05 - val_activation_2_loss: 2.4676e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9448e-04 - activation_1_loss: 1.9896e-05 - activation_2_loss: 2.7458e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9604e-04 - val_activation_1_loss: 1.2025e-05 - val_activation_2_loss: 1.8401e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0104e-04 - activation_1_loss: 2.1847e-05 - activation_2_loss: 2.7920e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.5193e-04 - val_activation_1_loss: 4.3971e-05 - val_activation_2_loss: 4.0796e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.1323e-04 - activation_1_loss: 1.7993e-04 - activation_2_loss: 3.3330e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9352e-04 - val_activation_1_loss: 4.2228e-05 - val_activation_2_loss: 3.5129e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9039e-04 - activation_1_loss: 1.4570e-05 - activation_2_loss: 2.7582e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.5415e-04 - val_activation_1_loss: 4.0312e-05 - val_activation_2_loss: 4.1383e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9071e-04 - activation_1_loss: 1.8036e-05 - activation_2_loss: 3.7267e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2824e-04 - val_activation_1_loss: 1.9070e-05 - val_activation_2_loss: 2.0917e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.2292e-04 - activation_1_loss: 1.9127e-04 - activation_2_loss: 6.3166e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 0.0016 - val_activation_1_loss: 8.2645e-04 - val_activation_2_loss: 7.4516e-04 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 4.8553e-04 - activation_2_loss: 6.4902e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 3.2527e-04 - val_activation_1_loss: 4.2595e-05 - val_activation_2_loss: 2.8267e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1823e-04 - activation_1_loss: 3.8137e-05 - activation_2_loss: 1.8009e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6063e-04 - val_activation_1_loss: 3.8580e-05 - val_activation_2_loss: 3.2205e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8557e-04 - activation_1_loss: 2.4168e-05 - activation_2_loss: 1.6140e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5850e-04 - val_activation_1_loss: 2.1413e-05 - val_activation_2_loss: 2.3709e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0223e-04 - activation_1_loss: 2.2853e-05 - activation_2_loss: 3.7937e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.9097e-04 - val_activation_1_loss: 2.4261e-05 - val_activation_2_loss: 7.6671e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3192e-04 - activation_1_loss: 1.8444e-05 - activation_2_loss: 4.1347e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0931e-04 - val_activation_1_loss: 9.4968e-05 - val_activation_2_loss: 2.1435e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 4.7097e-04 - activation_2_loss: 8.1772e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 8.4790e-04 - val_activation_1_loss: 5.5983e-05 - val_activation_2_loss: 7.9192e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.0778e-04 - activation_1_loss: 1.4963e-04 - activation_2_loss: 4.5815e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0718e-04 - val_activation_1_loss: 2.9269e-05 - val_activation_2_loss: 3.7791e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9103e-04 - activation_1_loss: 1.8342e-05 - activation_2_loss: 2.7269e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0878e-04 - val_activation_1_loss: 1.7723e-05 - val_activation_2_loss: 2.9106e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.6489e-04 - activation_1_loss: 2.2303e-05 - activation_2_loss: 4.4259e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.7787e-04 - val_activation_1_loss: 1.4360e-05 - val_activation_2_loss: 4.6351e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8538e-04 - activation_1_loss: 1.7426e-05 - activation_2_loss: 1.6795e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4180e-04 - val_activation_1_loss: 6.2770e-06 - val_activation_2_loss: 3.3552e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5726e-04 - activation_1_loss: 1.9523e-05 - activation_2_loss: 3.3774e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3281e-04 - val_activation_1_loss: 6.8358e-06 - val_activation_2_loss: 1.2597e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1344e-04 - activation_1_loss: 7.7404e-05 - activation_2_loss: 2.3603e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0347e-04 - val_activation_1_loss: 4.7783e-05 - val_activation_2_loss: 1.5569e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2273e-04 - activation_1_loss: 9.4096e-05 - activation_2_loss: 3.2864e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7524e-04 - val_activation_1_loss: 1.5156e-05 - val_activation_2_loss: 1.6008e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7765e-04 - activation_1_loss: 3.4061e-05 - activation_2_loss: 2.4359e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.8735e-05 - val_activation_1_loss: 2.2089e-05 - val_activation_2_loss: 7.6646e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8106e-04 - activation_1_loss: 1.2552e-05 - activation_2_loss: 1.6850e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9407e-04 - val_activation_1_loss: 1.5040e-05 - val_activation_2_loss: 1.7903e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8392e-04 - activation_1_loss: 7.7182e-06 - activation_2_loss: 1.7620e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9755e-04 - val_activation_1_loss: 5.1917e-06 - val_activation_2_loss: 2.9235e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7839e-04 - activation_1_loss: 1.1623e-05 - activation_2_loss: 2.6677e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9220e-04 - val_activation_1_loss: 1.5282e-05 - val_activation_2_loss: 2.7692e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7744e-04 - activation_1_loss: 1.4498e-05 - activation_2_loss: 3.6294e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0786e-04 - val_activation_1_loss: 4.0011e-05 - val_activation_2_loss: 2.6785e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2954e-04 - activation_1_loss: 3.0934e-05 - activation_2_loss: 2.9860e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0050 - val_activation_1_loss: 0.0022 - val_activation_2_loss: 0.0027 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9996\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.7623e-04 - activation_1_loss: 3.6094e-04 - activation_2_loss: 6.1528e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.8612e-04 - val_activation_1_loss: 4.7950e-05 - val_activation_2_loss: 5.3817e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7263e-04 - activation_1_loss: 1.4708e-05 - activation_2_loss: 3.5792e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2424e-04 - val_activation_1_loss: 2.1207e-05 - val_activation_2_loss: 4.0303e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5863e-04 - activation_1_loss: 2.6074e-05 - activation_2_loss: 1.3256e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9637e-04 - val_activation_1_loss: 1.3929e-05 - val_activation_2_loss: 4.8244e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1300e-04 - activation_1_loss: 9.0958e-06 - activation_2_loss: 2.0391e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8279e-04 - val_activation_1_loss: 1.9784e-05 - val_activation_2_loss: 2.6301e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5316e-04 - activation_1_loss: 2.0619e-05 - activation_2_loss: 2.3254e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3649e-04 - val_activation_1_loss: 6.2918e-05 - val_activation_2_loss: 7.3573e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3069e-04 - activation_1_loss: 1.4263e-05 - activation_2_loss: 3.1642e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1981e-04 - val_activation_1_loss: 5.1848e-06 - val_activation_2_loss: 2.1462e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8235e-04 - activation_1_loss: 1.3083e-05 - activation_2_loss: 1.6927e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.6276e-05 - val_activation_1_loss: 5.1783e-06 - val_activation_2_loss: 5.1098e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9379e-04 - activation_1_loss: 2.2519e-05 - activation_2_loss: 1.7128e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9603e-04 - val_activation_1_loss: 8.1461e-06 - val_activation_2_loss: 1.8789e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8504e-04 - activation_1_loss: 5.9745e-06 - activation_2_loss: 2.7907e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8991e-04 - val_activation_1_loss: 1.3654e-05 - val_activation_2_loss: 2.7626e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9936e-04 - activation_1_loss: 2.1899e-05 - activation_2_loss: 4.7746e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0854e-04 - val_activation_1_loss: 2.1609e-05 - val_activation_2_loss: 3.8693e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.3148e-04 - activation_1_loss: 1.7814e-05 - activation_2_loss: 6.1366e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.0627e-04 - val_activation_1_loss: 2.7741e-05 - val_activation_2_loss: 2.7853e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8223e-04 - activation_1_loss: 1.1674e-05 - activation_2_loss: 2.7055e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9844e-04 - val_activation_1_loss: 8.6307e-06 - val_activation_2_loss: 1.8981e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3361e-04 - activation_1_loss: 1.0645e-04 - activation_2_loss: 2.2716e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 6.7423e-04 - val_activation_2_loss: 3.4019e-04 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7144e-04 - activation_1_loss: 3.7968e-05 - activation_2_loss: 2.3347e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.3772e-04 - val_activation_1_loss: 1.6404e-05 - val_activation_2_loss: 5.2132e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8493e-04 - activation_1_loss: 1.5068e-05 - activation_2_loss: 3.6986e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4825e-04 - val_activation_1_loss: 1.9825e-05 - val_activation_2_loss: 2.2843e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 2.7729e-04 - activation_2_loss: 8.7546e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 3.3033e-04 - val_activation_1_loss: 4.8068e-05 - val_activation_2_loss: 2.8226e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2579e-04 - activation_1_loss: 1.9833e-05 - activation_2_loss: 2.0596e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.2708e-04 - val_activation_1_loss: 1.0740e-05 - val_activation_2_loss: 3.1634e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7887e-04 - activation_1_loss: 3.7122e-05 - activation_2_loss: 3.4174e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5104e-04 - val_activation_1_loss: 1.5890e-05 - val_activation_2_loss: 1.3515e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9140e-04 - activation_1_loss: 1.9510e-05 - activation_2_loss: 3.7189e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9769e-04 - val_activation_1_loss: 6.1512e-06 - val_activation_2_loss: 1.9153e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.7693e-04 - activation_1_loss: 2.3969e-04 - activation_2_loss: 4.3724e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0011 - val_activation_1_loss: 4.9312e-04 - val_activation_2_loss: 5.7606e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2968e-04 - activation_1_loss: 7.8420e-05 - activation_2_loss: 4.5126e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.6230e-04 - val_activation_1_loss: 4.2394e-04 - val_activation_2_loss: 4.3836e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1797e-04 - activation_1_loss: 3.4492e-05 - activation_2_loss: 1.8348e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0448e-04 - val_activation_1_loss: 9.8760e-06 - val_activation_2_loss: 2.9460e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.6544e-04 - activation_1_loss: 1.1324e-05 - activation_2_loss: 1.5412e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4555e-04 - val_activation_1_loss: 7.5591e-06 - val_activation_2_loss: 3.3799e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1878e-04 - activation_1_loss: 9.6700e-06 - activation_2_loss: 2.0911e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7223e-04 - val_activation_1_loss: 3.3705e-06 - val_activation_2_loss: 1.6886e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0283e-04 - activation_1_loss: 4.7625e-06 - activation_2_loss: 9.8068e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7689e-05 - val_activation_1_loss: 7.5067e-06 - val_activation_2_loss: 5.0182e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7630e-04 - activation_1_loss: 5.8937e-05 - activation_2_loss: 3.1736e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1630e-04 - val_activation_1_loss: 2.8391e-05 - val_activation_2_loss: 8.7913e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4782e-04 - activation_1_loss: 3.0447e-05 - activation_2_loss: 2.1738e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8439e-04 - val_activation_1_loss: 2.0409e-05 - val_activation_2_loss: 1.6398e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2467e-04 - activation_1_loss: 2.8261e-05 - activation_2_loss: 2.9641e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5006e-04 - val_activation_1_loss: 2.0320e-05 - val_activation_2_loss: 3.2975e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.0209e-04 - activation_1_loss: 5.9715e-05 - activation_2_loss: 3.4238e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2673e-04 - val_activation_1_loss: 3.4366e-05 - val_activation_2_loss: 1.9237e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5456e-04 - activation_1_loss: 1.3954e-05 - activation_2_loss: 1.4060e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.1286e-04 - val_activation_1_loss: 3.2012e-05 - val_activation_2_loss: 5.8085e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8091e-04 - activation_1_loss: 1.7817e-04 - activation_2_loss: 5.0274e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.1933e-04 - val_activation_1_loss: 4.3518e-05 - val_activation_2_loss: 6.7581e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0799e-04 - activation_1_loss: 1.9641e-05 - activation_2_loss: 2.8835e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9169e-04 - val_activation_1_loss: 1.9942e-05 - val_activation_2_loss: 2.7175e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1453e-04 - activation_1_loss: 1.3524e-05 - activation_2_loss: 2.0101e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.9119e-04 - val_activation_1_loss: 2.1180e-05 - val_activation_2_loss: 7.7001e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7928e-04 - activation_1_loss: 1.6498e-05 - activation_2_loss: 4.6278e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 1.2403e-04 - val_activation_1_loss: 1.2469e-05 - val_activation_2_loss: 1.1156e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9136e-04 - activation_1_loss: 2.5650e-05 - activation_2_loss: 2.6571e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4975e-04 - val_activation_1_loss: 3.1775e-05 - val_activation_2_loss: 1.1798e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.2904e-04 - activation_1_loss: 2.5546e-04 - activation_2_loss: 3.7359e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 6.3933e-04 - val_activation_1_loss: 2.5174e-05 - val_activation_2_loss: 6.1416e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8297e-04 - activation_1_loss: 4.3797e-05 - activation_2_loss: 3.3918e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2114e-04 - val_activation_1_loss: 4.5834e-05 - val_activation_2_loss: 7.5303e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6251e-04 - activation_1_loss: 3.0956e-05 - activation_2_loss: 3.3155e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0230e-04 - val_activation_1_loss: 9.0426e-05 - val_activation_2_loss: 3.1187e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2731e-04 - activation_1_loss: 1.9061e-04 - activation_2_loss: 2.3669e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5170e-04 - val_activation_1_loss: 2.0894e-05 - val_activation_2_loss: 2.3080e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9661e-04 - activation_1_loss: 1.4824e-04 - activation_2_loss: 4.4837e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0564e-04 - val_activation_1_loss: 3.5622e-05 - val_activation_2_loss: 1.7002e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.5804e-04 - activation_1_loss: 3.5608e-04 - activation_2_loss: 2.0195e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7655e-04 - val_activation_1_loss: 2.3273e-05 - val_activation_2_loss: 1.5328e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1907e-04 - activation_1_loss: 1.6078e-05 - activation_2_loss: 2.0299e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2901e-04 - val_activation_1_loss: 3.2131e-05 - val_activation_2_loss: 1.9688e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1501e-04 - activation_1_loss: 1.9014e-05 - activation_2_loss: 2.9600e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2302e-04 - val_activation_1_loss: 6.8695e-06 - val_activation_2_loss: 1.1615e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5241e-04 - activation_1_loss: 7.9346e-05 - activation_2_loss: 2.7307e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0683e-04 - val_activation_1_loss: 1.7149e-05 - val_activation_2_loss: 8.9682e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3178e-04 - activation_1_loss: 2.5905e-05 - activation_2_loss: 2.0588e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8195e-04 - val_activation_1_loss: 1.6133e-05 - val_activation_2_loss: 3.6582e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0960e-04 - activation_1_loss: 1.5117e-05 - activation_2_loss: 2.9448e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0982e-04 - val_activation_1_loss: 4.8284e-05 - val_activation_2_loss: 1.6153e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2058e-04 - activation_1_loss: 1.1466e-05 - activation_2_loss: 3.0911e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5441e-04 - val_activation_1_loss: 1.7811e-05 - val_activation_2_loss: 2.3660e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4567e-04 - activation_1_loss: 2.0387e-05 - activation_2_loss: 2.2528e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8412e-04 - val_activation_1_loss: 1.7265e-05 - val_activation_2_loss: 1.6686e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2921e-04 - activation_1_loss: 1.9950e-05 - activation_2_loss: 1.0926e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6703e-05 - val_activation_1_loss: 8.3089e-06 - val_activation_2_loss: 3.8394e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5998e-04 - activation_1_loss: 2.2778e-05 - activation_2_loss: 4.3720e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.6977e-04 - val_activation_1_loss: 7.5031e-05 - val_activation_2_loss: 3.9474e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4405e-04 - activation_1_loss: 1.5668e-04 - activation_2_loss: 4.8736e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4159e-04 - val_activation_1_loss: 3.9670e-05 - val_activation_2_loss: 2.0192e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.4901e-04 - activation_1_loss: 2.5663e-04 - activation_2_loss: 5.9237e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.6160e-04 - val_activation_1_loss: 2.4714e-05 - val_activation_2_loss: 5.3688e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.6600e-04 - activation_1_loss: 2.1922e-05 - activation_2_loss: 1.4408e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8292e-04 - val_activation_1_loss: 1.4894e-05 - val_activation_2_loss: 6.6802e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8862e-04 - activation_1_loss: 1.4014e-05 - activation_2_loss: 1.7460e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9410e-05 - val_activation_1_loss: 8.9344e-06 - val_activation_2_loss: 7.0475e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0970e-04 - activation_1_loss: 9.6259e-06 - activation_2_loss: 1.0007e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4940e-04 - val_activation_1_loss: 9.9674e-06 - val_activation_2_loss: 1.3944e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4385e-04 - activation_1_loss: 1.3091e-05 - activation_2_loss: 2.3076e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4975e-04 - val_activation_1_loss: 8.8543e-06 - val_activation_2_loss: 1.4090e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4948e-04 - activation_1_loss: 1.5593e-05 - activation_2_loss: 2.3389e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6417e-04 - val_activation_1_loss: 9.8020e-06 - val_activation_2_loss: 1.5437e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4720e-04 - activation_1_loss: 9.4875e-06 - activation_2_loss: 2.3771e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4544e-04 - val_activation_1_loss: 1.9543e-05 - val_activation_2_loss: 2.2590e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8290e-04 - activation_1_loss: 1.2421e-05 - activation_2_loss: 2.7048e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8360e-04 - val_activation_1_loss: 2.3328e-04 - val_activation_2_loss: 5.0317e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0030 - activation_1_loss: 0.0015 - activation_2_loss: 0.0015 - activation_1_acc: 0.9998 - activation_2_acc: 0.9997 - val_loss: 8.5885e-04 - val_activation_1_loss: 1.2798e-04 - val_activation_2_loss: 7.3086e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.9883e-04 - activation_1_loss: 4.9198e-05 - activation_2_loss: 5.4964e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 2.7166e-04 - val_activation_1_loss: 5.6314e-05 - val_activation_2_loss: 2.1535e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7043e-04 - activation_1_loss: 2.2932e-05 - activation_2_loss: 2.4750e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0025e-04 - val_activation_1_loss: 2.4776e-05 - val_activation_2_loss: 7.5472e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0341e-04 - activation_1_loss: 1.8391e-05 - activation_2_loss: 1.8502e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8193e-04 - val_activation_1_loss: 1.0102e-05 - val_activation_2_loss: 2.7183e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2794e-04 - activation_1_loss: 1.4268e-05 - activation_2_loss: 1.1367e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8429e-04 - val_activation_1_loss: 2.1511e-05 - val_activation_2_loss: 2.6278e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.6884e-04 - activation_1_loss: 1.1624e-05 - activation_2_loss: 2.5722e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.4008e-05 - val_activation_1_loss: 7.4020e-06 - val_activation_2_loss: 8.6606e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2519e-04 - activation_1_loss: 1.1116e-05 - activation_2_loss: 1.1407e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8072e-04 - val_activation_1_loss: 2.7095e-05 - val_activation_2_loss: 1.5362e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4397e-04 - activation_1_loss: 7.6616e-06 - activation_2_loss: 1.3631e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8464e-04 - val_activation_1_loss: 3.2605e-05 - val_activation_2_loss: 1.5204e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2670e-04 - activation_1_loss: 2.1690e-05 - activation_2_loss: 2.0501e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5196e-04 - val_activation_1_loss: 1.7006e-05 - val_activation_2_loss: 2.3495e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2625e-04 - activation_1_loss: 1.2095e-05 - activation_2_loss: 1.1416e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1514e-04 - val_activation_1_loss: 7.3935e-06 - val_activation_2_loss: 1.0774e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.6468e-04 - activation_1_loss: 1.9779e-05 - activation_2_loss: 2.4490e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1286e-04 - val_activation_1_loss: 5.2878e-06 - val_activation_2_loss: 1.0758e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.3372e-05 - activation_1_loss: 1.1174e-05 - activation_2_loss: 5.2199e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.1557e-05 - val_activation_1_loss: 1.7094e-05 - val_activation_2_loss: 4.4463e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1306e-04 - activation_1_loss: 2.0155e-05 - activation_2_loss: 9.2908e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.5476e-05 - val_activation_1_loss: 6.3777e-06 - val_activation_2_loss: 4.9099e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2893e-04 - activation_1_loss: 7.9886e-06 - activation_2_loss: 2.2094e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.0644e-05 - val_activation_1_loss: 1.2505e-05 - val_activation_2_loss: 7.8139e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9496e-04 - activation_1_loss: 2.7649e-05 - activation_2_loss: 1.6731e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5413e-04 - val_activation_1_loss: 1.2955e-05 - val_activation_2_loss: 1.4118e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8207e-04 - activation_1_loss: 2.3171e-05 - activation_2_loss: 2.5890e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0641e-04 - val_activation_1_loss: 1.4259e-04 - val_activation_2_loss: 1.6382e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4425e-04 - activation_1_loss: 2.8061e-05 - activation_2_loss: 2.1619e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3485e-04 - val_activation_1_loss: 2.3869e-05 - val_activation_2_loss: 1.1098e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9332e-04 - activation_1_loss: 9.2166e-06 - activation_2_loss: 4.8411e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5666e-04 - val_activation_1_loss: 1.2437e-05 - val_activation_2_loss: 3.4423e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4359e-04 - activation_1_loss: 9.3334e-06 - activation_2_loss: 2.3426e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.8472e-05 - val_activation_1_loss: 1.1359e-05 - val_activation_2_loss: 5.7113e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2470e-04 - activation_1_loss: 1.7073e-05 - activation_2_loss: 2.0763e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0745e-04 - val_activation_1_loss: 1.2725e-05 - val_activation_2_loss: 2.9473e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8183e-04 - activation_1_loss: 1.2296e-05 - activation_2_loss: 2.6954e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6388e-04 - val_activation_1_loss: 1.3428e-05 - val_activation_2_loss: 1.5046e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4993e-04 - activation_1_loss: 1.1352e-05 - activation_2_loss: 2.3858e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.3465e-04 - val_activation_1_loss: 8.5824e-05 - val_activation_2_loss: 2.4883e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2515e-04 - activation_1_loss: 2.9785e-05 - activation_2_loss: 2.9536e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.6701e-05 - val_activation_1_loss: 1.4071e-05 - val_activation_2_loss: 7.2629e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2682e-04 - activation_1_loss: 2.7862e-05 - activation_2_loss: 1.9896e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0756e-04 - val_activation_1_loss: 2.1684e-05 - val_activation_2_loss: 2.8587e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.6060e-04 - activation_1_loss: 1.7388e-05 - activation_2_loss: 1.4321e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7479e-04 - val_activation_1_loss: 1.2942e-05 - val_activation_2_loss: 5.6184e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.1762e-04 - activation_1_loss: 1.0882e-04 - activation_2_loss: 3.0881e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9218e-04 - val_activation_1_loss: 1.2460e-05 - val_activation_2_loss: 3.7972e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5622e-04 - activation_1_loss: 2.3678e-05 - activation_2_loss: 2.3255e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4086e-04 - val_activation_1_loss: 2.1106e-05 - val_activation_2_loss: 3.1975e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.4108e-04 - activation_1_loss: 2.2891e-04 - activation_2_loss: 5.1217e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 4.9987e-04 - val_activation_1_loss: 5.6100e-05 - val_activation_2_loss: 4.4377e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2483e-04 - activation_1_loss: 3.4400e-05 - activation_2_loss: 2.9043e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0827e-04 - val_activation_1_loss: 1.2941e-05 - val_activation_2_loss: 3.9533e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4952e-04 - activation_1_loss: 1.2360e-05 - activation_2_loss: 3.3716e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4055e-04 - val_activation_1_loss: 2.9854e-05 - val_activation_2_loss: 1.1070e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6391e-04 - activation_1_loss: 2.0232e-04 - activation_2_loss: 3.6159e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2629e-04 - val_activation_1_loss: 3.5372e-05 - val_activation_2_loss: 9.0916e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9342e-04 - activation_1_loss: 1.9299e-05 - activation_2_loss: 1.7412e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5908e-04 - val_activation_1_loss: 1.1905e-05 - val_activation_2_loss: 2.4718e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5713e-04 - activation_1_loss: 1.1968e-05 - activation_2_loss: 1.4516e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.9511e-05 - val_activation_1_loss: 1.6855e-05 - val_activation_2_loss: 8.2655e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4484e-04 - activation_1_loss: 1.3025e-05 - activation_2_loss: 2.3182e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.2316e-04 - val_activation_1_loss: 5.3218e-05 - val_activation_2_loss: 5.6994e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1730e-04 - activation_1_loss: 1.4027e-05 - activation_2_loss: 2.0327e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6568e-04 - val_activation_1_loss: 9.2892e-06 - val_activation_2_loss: 3.5639e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0400e-04 - activation_1_loss: 1.4872e-05 - activation_2_loss: 8.9127e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7017e-04 - val_activation_1_loss: 6.8147e-06 - val_activation_2_loss: 2.6336e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9596e-04 - activation_1_loss: 2.6500e-05 - activation_2_loss: 2.6946e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.9412e-05 - val_activation_1_loss: 3.5245e-05 - val_activation_2_loss: 6.4167e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1344e-04 - activation_1_loss: 2.0165e-05 - activation_2_loss: 9.3272e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4748e-04 - val_activation_1_loss: 6.6046e-06 - val_activation_2_loss: 2.4088e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9332e-04 - activation_1_loss: 3.9972e-05 - activation_2_loss: 2.5335e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.2982e-05 - val_activation_1_loss: 3.0037e-05 - val_activation_2_loss: 5.2945e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0249e-04 - activation_1_loss: 2.3346e-05 - activation_2_loss: 1.7914e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2973e-04 - val_activation_1_loss: 2.0553e-05 - val_activation_2_loss: 3.0918e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.3755e-04 - activation_1_loss: 1.2491e-05 - activation_2_loss: 4.2506e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0012 - val_activation_1_loss: 4.4149e-05 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.5130e-04 - activation_1_loss: 2.7530e-05 - activation_2_loss: 7.2377e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 2.9660e-04 - val_activation_1_loss: 2.2405e-05 - val_activation_2_loss: 2.7419e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0957e-04 - activation_1_loss: 1.6920e-05 - activation_2_loss: 2.9265e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8867e-04 - val_activation_1_loss: 5.3555e-05 - val_activation_2_loss: 2.3511e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9554e-04 - activation_1_loss: 2.3073e-05 - activation_2_loss: 2.7247e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0352e-04 - val_activation_1_loss: 5.5054e-06 - val_activation_2_loss: 1.9802e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3775e-04 - activation_1_loss: 1.2060e-05 - activation_2_loss: 2.2569e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1984e-04 - val_activation_1_loss: 6.6602e-06 - val_activation_2_loss: 2.1318e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.4896e-04 - activation_1_loss: 1.8168e-04 - activation_2_loss: 2.6727e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9908e-04 - val_activation_1_loss: 2.3163e-05 - val_activation_2_loss: 1.7592e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3234e-04 - activation_1_loss: 1.7212e-05 - activation_2_loss: 2.1513e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0252e-04 - val_activation_1_loss: 1.5767e-05 - val_activation_2_loss: 1.8675e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2948e-04 - activation_1_loss: 2.1154e-05 - activation_2_loss: 2.0833e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.1934e-05 - val_activation_1_loss: 3.5353e-05 - val_activation_2_loss: 4.6581e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7520e-04 - activation_1_loss: 2.3976e-05 - activation_2_loss: 1.5123e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2991e-04 - val_activation_1_loss: 9.0936e-06 - val_activation_2_loss: 2.2081e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2888e-04 - activation_1_loss: 1.6887e-05 - activation_2_loss: 2.1199e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.1586e-05 - val_activation_1_loss: 1.0921e-05 - val_activation_2_loss: 7.0665e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7700e-04 - activation_1_loss: 1.1536e-05 - activation_2_loss: 2.6547e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1164e-04 - val_activation_1_loss: 8.5112e-06 - val_activation_2_loss: 2.0313e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5272e-04 - activation_1_loss: 7.9928e-06 - activation_2_loss: 1.4473e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6594e-04 - val_activation_1_loss: 2.3193e-04 - val_activation_2_loss: 2.3401e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7426e-04 - activation_1_loss: 1.5061e-05 - activation_2_loss: 1.5920e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5415e-04 - val_activation_1_loss: 4.5233e-06 - val_activation_2_loss: 3.4963e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0284e-04 - activation_1_loss: 1.4532e-05 - activation_2_loss: 8.8313e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6044e-04 - val_activation_1_loss: 3.7338e-05 - val_activation_2_loss: 1.2310e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8052e-04 - activation_1_loss: 7.3399e-06 - activation_2_loss: 1.7318e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8875e-04 - val_activation_1_loss: 1.2934e-05 - val_activation_2_loss: 2.7582e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2400e-04 - activation_1_loss: 5.3439e-06 - activation_2_loss: 1.1865e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4074e-04 - val_activation_1_loss: 6.4190e-06 - val_activation_2_loss: 2.3432e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.7840e-05 - activation_1_loss: 1.5133e-05 - activation_2_loss: 8.2708e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2063e-04 - val_activation_1_loss: 9.1833e-06 - val_activation_2_loss: 3.1145e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1254e-04 - activation_1_loss: 8.9873e-06 - activation_2_loss: 2.0356e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7615e-04 - val_activation_1_loss: 1.7460e-05 - val_activation_2_loss: 3.5869e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2384e-04 - activation_1_loss: 3.2344e-05 - activation_2_loss: 2.9149e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2344e-04 - val_activation_1_loss: 4.4683e-05 - val_activation_2_loss: 1.7876e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3795e-04 - activation_1_loss: 3.7125e-05 - activation_2_loss: 3.0083e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9025e-04 - val_activation_1_loss: 2.3046e-05 - val_activation_2_loss: 1.6720e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7052e-05 - activation_1_loss: 1.1799e-05 - activation_2_loss: 6.5253e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0261e-04 - val_activation_1_loss: 1.2376e-05 - val_activation_2_loss: 1.9023e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2088e-04 - activation_1_loss: 2.3472e-05 - activation_2_loss: 9.7413e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0592e-05 - val_activation_1_loss: 1.0123e-05 - val_activation_2_loss: 5.0469e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2418e-04 - activation_1_loss: 2.0466e-05 - activation_2_loss: 3.0371e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9646e-04 - val_activation_1_loss: 1.8651e-05 - val_activation_2_loss: 3.7781e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.2560e-04 - activation_1_loss: 1.9280e-04 - activation_2_loss: 4.3280e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.2969e-04 - val_activation_1_loss: 4.4323e-05 - val_activation_2_loss: 2.8537e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 4.7916e-04 - activation_2_loss: 5.5559e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 4.1938e-04 - val_activation_1_loss: 5.5077e-05 - val_activation_2_loss: 3.6430e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4045e-04 - activation_1_loss: 5.6683e-05 - activation_2_loss: 2.8376e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5800e-04 - val_activation_1_loss: 4.3186e-05 - val_activation_2_loss: 2.1481e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.0131e-05 - activation_1_loss: 1.7187e-05 - activation_2_loss: 6.2944e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5343e-04 - val_activation_1_loss: 6.6578e-05 - val_activation_2_loss: 2.8686e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0942e-04 - activation_1_loss: 4.5354e-05 - activation_2_loss: 1.6407e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0093e-04 - val_activation_1_loss: 8.3300e-06 - val_activation_2_loss: 9.2598e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3265e-04 - activation_1_loss: 1.4511e-05 - activation_2_loss: 1.1814e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6548e-04 - val_activation_1_loss: 1.2467e-05 - val_activation_2_loss: 1.5301e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7105e-04 - activation_1_loss: 3.9918e-05 - activation_2_loss: 2.3114e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4155e-04 - val_activation_1_loss: 6.5696e-06 - val_activation_2_loss: 2.3498e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8121e-04 - activation_1_loss: 2.9843e-05 - activation_2_loss: 2.5136e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4302e-04 - val_activation_1_loss: 1.4171e-05 - val_activation_2_loss: 3.2885e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5123e-04 - activation_1_loss: 1.4385e-05 - activation_2_loss: 2.3684e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.5204e-05 - val_activation_1_loss: 1.3882e-05 - val_activation_2_loss: 5.1321e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0852e-04 - activation_1_loss: 3.4886e-05 - activation_2_loss: 2.7364e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8088e-04 - val_activation_1_loss: 6.1941e-06 - val_activation_2_loss: 3.7469e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0894e-04 - activation_1_loss: 2.2776e-05 - activation_2_loss: 1.8616e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1251e-04 - val_activation_1_loss: 4.5790e-06 - val_activation_2_loss: 2.0793e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8592e-04 - activation_1_loss: 1.2702e-05 - activation_2_loss: 2.7322e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2551e-04 - val_activation_1_loss: 2.4867e-05 - val_activation_2_loss: 1.0064e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7725e-04 - activation_1_loss: 1.2887e-05 - activation_2_loss: 1.6436e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.4086e-05 - val_activation_1_loss: 1.2581e-05 - val_activation_2_loss: 8.1505e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2273e-04 - activation_1_loss: 1.4866e-04 - activation_2_loss: 1.7407e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2348e-05 - val_activation_1_loss: 1.6006e-05 - val_activation_2_loss: 2.6342e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0490e-04 - activation_1_loss: 7.3834e-06 - activation_2_loss: 9.7515e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.1651e-05 - val_activation_1_loss: 5.6676e-06 - val_activation_2_loss: 8.5984e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1793e-05 - activation_1_loss: 1.6296e-05 - activation_2_loss: 3.5497e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.5412e-05 - val_activation_1_loss: 4.4304e-05 - val_activation_2_loss: 3.1108e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7872e-04 - activation_1_loss: 1.5253e-04 - activation_2_loss: 2.2619e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0495e-04 - val_activation_1_loss: 1.8096e-05 - val_activation_2_loss: 8.6853e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7801e-04 - activation_1_loss: 2.7855e-05 - activation_2_loss: 3.5016e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6338e-04 - val_activation_1_loss: 8.1311e-06 - val_activation_2_loss: 2.5525e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.3568e-04 - activation_1_loss: 1.4216e-04 - activation_2_loss: 4.9352e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2298e-04 - val_activation_1_loss: 5.6659e-06 - val_activation_2_loss: 1.1731e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4418e-04 - activation_1_loss: 1.7160e-05 - activation_2_loss: 3.2702e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2302e-04 - val_activation_1_loss: 2.8748e-05 - val_activation_2_loss: 1.9428e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3540e-04 - activation_1_loss: 1.7586e-05 - activation_2_loss: 1.1782e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3385e-04 - val_activation_1_loss: 3.4914e-05 - val_activation_2_loss: 2.9894e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8204e-04 - activation_1_loss: 8.1608e-05 - activation_2_loss: 2.0044e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8349e-04 - val_activation_1_loss: 1.7401e-05 - val_activation_2_loss: 1.6609e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8425e-04 - activation_1_loss: 3.2832e-05 - activation_2_loss: 2.5142e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.5394e-05 - val_activation_1_loss: 6.6429e-06 - val_activation_2_loss: 7.8751e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.9164e-05 - activation_1_loss: 5.3572e-06 - activation_2_loss: 9.3807e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3170e-04 - val_activation_1_loss: 5.9634e-06 - val_activation_2_loss: 1.2574e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8068e-04 - activation_1_loss: 1.7086e-04 - activation_2_loss: 2.0982e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1026e-04 - val_activation_1_loss: 1.2723e-05 - val_activation_2_loss: 9.7542e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7302e-04 - activation_1_loss: 1.8749e-05 - activation_2_loss: 1.5427e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7117e-04 - val_activation_1_loss: 5.8952e-05 - val_activation_2_loss: 1.1222e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0216e-04 - activation_1_loss: 2.2844e-05 - activation_2_loss: 2.7932e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6548e-04 - val_activation_1_loss: 9.2968e-05 - val_activation_2_loss: 2.7251e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7742e-04 - activation_1_loss: 2.9463e-05 - activation_2_loss: 3.4796e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.1890e-04 - val_activation_1_loss: 6.1925e-05 - val_activation_2_loss: 3.5697e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.4238e-04 - activation_1_loss: 3.2018e-04 - activation_2_loss: 4.2219e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9578e-04 - val_activation_1_loss: 4.2474e-05 - val_activation_2_loss: 3.5331e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8204e-04 - activation_1_loss: 8.8768e-05 - activation_2_loss: 1.9327e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.2961e-05 - val_activation_1_loss: 1.3048e-05 - val_activation_2_loss: 7.9914e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8817e-04 - activation_1_loss: 2.3112e-05 - activation_2_loss: 3.6506e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7771e-04 - val_activation_1_loss: 1.2230e-05 - val_activation_2_loss: 1.6548e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5875e-04 - activation_1_loss: 1.1890e-04 - activation_2_loss: 1.3984e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.0868e-05 - val_activation_1_loss: 1.4078e-05 - val_activation_2_loss: 5.6790e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.6331e-04 - activation_1_loss: 1.0843e-05 - activation_2_loss: 1.5246e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5154e-04 - val_activation_1_loss: 4.1135e-06 - val_activation_2_loss: 1.4742e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.6339e-05 - activation_1_loss: 5.8387e-06 - activation_2_loss: 7.0500e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3092e-04 - val_activation_1_loss: 4.4452e-06 - val_activation_2_loss: 1.2647e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8481e-04 - activation_1_loss: 6.4424e-06 - activation_2_loss: 1.7837e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.8327e-05 - val_activation_1_loss: 1.8766e-05 - val_activation_2_loss: 5.9560e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4782e-04 - activation_1_loss: 1.7324e-05 - activation_2_loss: 1.3050e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7550e-04 - val_activation_1_loss: 1.6224e-04 - val_activation_2_loss: 1.1326e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8214e-04 - activation_1_loss: 1.2885e-04 - activation_2_loss: 5.5330e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.3214e-04 - val_activation_1_loss: 6.9330e-06 - val_activation_2_loss: 5.2521e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.0000e-04 - activation_1_loss: 3.3045e-04 - activation_2_loss: 3.6955e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 3.5600e-04 - val_activation_1_loss: 8.6367e-05 - val_activation_2_loss: 2.6964e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.1483e-04 - activation_1_loss: 4.0250e-05 - activation_2_loss: 2.7458e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5272e-04 - val_activation_1_loss: 5.1198e-05 - val_activation_2_loss: 1.0153e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1127e-04 - activation_1_loss: 4.3887e-05 - activation_2_loss: 6.7381e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3049e-05 - val_activation_1_loss: 9.2750e-06 - val_activation_2_loss: 3.3774e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.6050e-04 - activation_1_loss: 2.1931e-05 - activation_2_loss: 2.3857e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1531e-04 - val_activation_1_loss: 8.1323e-05 - val_activation_2_loss: 1.3399e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.6037e-04 - activation_1_loss: 9.9235e-06 - activation_2_loss: 1.5045e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.8359e-05 - val_activation_1_loss: 1.1048e-05 - val_activation_2_loss: 4.7311e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5463e-04 - activation_1_loss: 6.4778e-06 - activation_2_loss: 2.4816e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2279e-04 - val_activation_1_loss: 6.5677e-06 - val_activation_2_loss: 2.1622e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6858e-04 - activation_1_loss: 8.7185e-06 - activation_2_loss: 3.5986e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0656e-04 - val_activation_1_loss: 3.2396e-05 - val_activation_2_loss: 2.7416e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2464e-04 - activation_1_loss: 6.7357e-06 - activation_2_loss: 1.1791e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.6604e-05 - val_activation_1_loss: 4.3169e-06 - val_activation_2_loss: 6.2287e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.3965e-05 - activation_1_loss: 2.0571e-05 - activation_2_loss: 7.3394e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2713e-05 - val_activation_1_loss: 5.6888e-06 - val_activation_2_loss: 3.7024e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9862e-04 - activation_1_loss: 6.6082e-06 - activation_2_loss: 1.9201e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2833e-04 - val_activation_1_loss: 8.1764e-06 - val_activation_2_loss: 1.2016e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.6345e-05 - activation_1_loss: 8.4192e-06 - activation_2_loss: 3.7926e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3427e-04 - val_activation_1_loss: 1.3313e-05 - val_activation_2_loss: 1.2096e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5601e-04 - activation_1_loss: 1.5187e-05 - activation_2_loss: 2.4083e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.0304e-05 - val_activation_1_loss: 1.0187e-05 - val_activation_2_loss: 5.0117e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.4019e-04 - activation_1_loss: 1.3818e-05 - activation_2_loss: 3.2637e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4282e-04 - val_activation_1_loss: 4.8979e-05 - val_activation_2_loss: 9.3839e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1685e-04 - activation_1_loss: 1.1956e-05 - activation_2_loss: 2.0490e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.7093e-04 - val_activation_1_loss: 5.6690e-04 - val_activation_2_loss: 4.0402e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0014 - activation_1_loss: 6.7539e-04 - activation_2_loss: 7.3421e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 0.0016 - val_activation_1_loss: 6.3482e-04 - val_activation_2_loss: 9.9494e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2630e-04 - activation_1_loss: 7.5763e-05 - activation_2_loss: 4.5053e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.0623e-04 - val_activation_1_loss: 7.0067e-05 - val_activation_2_loss: 5.3616e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.4074e-04 - activation_1_loss: 1.2118e-04 - activation_2_loss: 3.1957e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7385e-04 - val_activation_1_loss: 4.3815e-05 - val_activation_2_loss: 3.3003e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.4177e-04 - activation_1_loss: 9.5510e-05 - activation_2_loss: 5.4626e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9998 - val_loss: 2.9591e-04 - val_activation_1_loss: 7.9287e-05 - val_activation_2_loss: 2.1662e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1416e-04 - activation_1_loss: 1.2604e-05 - activation_2_loss: 2.0156e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0333e-04 - val_activation_1_loss: 1.2034e-05 - val_activation_2_loss: 4.9129e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3667e-04 - activation_1_loss: 2.0868e-05 - activation_2_loss: 2.1580e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0453e-04 - val_activation_1_loss: 1.9693e-05 - val_activation_2_loss: 8.4834e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5160e-04 - activation_1_loss: 1.1477e-05 - activation_2_loss: 1.4013e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4285e-04 - val_activation_1_loss: 1.2759e-05 - val_activation_2_loss: 1.3009e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.6735e-04 - activation_1_loss: 2.0254e-04 - activation_2_loss: 2.6481e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6536e-04 - val_activation_1_loss: 6.3077e-05 - val_activation_2_loss: 3.0228e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1140e-04 - activation_1_loss: 2.6442e-05 - activation_2_loss: 8.4957e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4391e-04 - val_activation_1_loss: 8.0648e-06 - val_activation_2_loss: 1.3584e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9666e-04 - activation_1_loss: 8.1902e-06 - activation_2_loss: 1.8847e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2231e-04 - val_activation_1_loss: 9.3773e-06 - val_activation_2_loss: 1.1294e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9609e-04 - activation_1_loss: 8.9672e-06 - activation_2_loss: 1.8712e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.9941e-04 - val_activation_1_loss: 1.0326e-05 - val_activation_2_loss: 5.8908e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5999e-04 - activation_1_loss: 1.2891e-05 - activation_2_loss: 2.4710e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9157e-04 - val_activation_1_loss: 3.1453e-05 - val_activation_2_loss: 1.6012e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0537e-04 - activation_1_loss: 6.9685e-06 - activation_2_loss: 1.9841e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5531e-04 - val_activation_1_loss: 5.2551e-06 - val_activation_2_loss: 1.5006e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0990e-04 - activation_1_loss: 6.1139e-05 - activation_2_loss: 2.4876e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.8474e-05 - val_activation_1_loss: 2.6517e-05 - val_activation_2_loss: 4.1957e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6069e-04 - activation_1_loss: 4.7940e-05 - activation_2_loss: 3.1275e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.4977e-04 - val_activation_1_loss: 1.6799e-05 - val_activation_2_loss: 5.3297e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4925e-04 - activation_1_loss: 1.3422e-05 - activation_2_loss: 2.3583e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.3750e-05 - val_activation_1_loss: 1.2728e-05 - val_activation_2_loss: 7.1022e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.4946e-04 - activation_1_loss: 8.1815e-05 - activation_2_loss: 3.6765e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6605e-04 - val_activation_1_loss: 1.1329e-05 - val_activation_2_loss: 1.5472e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1387e-04 - activation_1_loss: 2.9234e-05 - activation_2_loss: 8.4639e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8140e-04 - val_activation_1_loss: 4.0075e-05 - val_activation_2_loss: 1.4133e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0690e-04 - activation_1_loss: 7.8441e-06 - activation_2_loss: 9.9057e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0640e-04 - val_activation_1_loss: 2.9634e-05 - val_activation_2_loss: 2.7676e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9352e-04 - activation_1_loss: 1.2719e-05 - activation_2_loss: 1.8080e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5468e-04 - val_activation_1_loss: 1.0045e-05 - val_activation_2_loss: 3.4464e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0981e-04 - activation_1_loss: 6.0696e-06 - activation_2_loss: 1.0374e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7655e-04 - val_activation_1_loss: 5.2529e-06 - val_activation_2_loss: 1.7130e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1127e-04 - activation_1_loss: 2.4332e-05 - activation_2_loss: 1.8694e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3784e-04 - val_activation_1_loss: 8.7905e-05 - val_activation_2_loss: 1.4993e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7748e-04 - activation_1_loss: 1.1034e-05 - activation_2_loss: 2.6644e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3913e-04 - val_activation_1_loss: 6.0055e-05 - val_activation_2_loss: 7.9072e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2290e-04 - activation_1_loss: 3.1168e-05 - activation_2_loss: 1.9173e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4245e-04 - val_activation_1_loss: 7.8927e-06 - val_activation_2_loss: 2.3456e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5342e-04 - activation_1_loss: 1.2492e-05 - activation_2_loss: 1.4092e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4897e-05 - val_activation_1_loss: 1.0808e-05 - val_activation_2_loss: 8.4089e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5560e-04 - activation_1_loss: 1.0959e-05 - activation_2_loss: 2.4464e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9181e-04 - val_activation_1_loss: 4.3817e-06 - val_activation_2_loss: 1.8743e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4768e-04 - activation_1_loss: 2.5492e-05 - activation_2_loss: 2.2219e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.1257e-04 - val_activation_1_loss: 4.7484e-06 - val_activation_2_loss: 5.0782e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2086e-04 - activation_1_loss: 8.0896e-06 - activation_2_loss: 2.1277e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2886e-04 - val_activation_1_loss: 6.9612e-05 - val_activation_2_loss: 5.9248e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4980e-04 - activation_1_loss: 4.3440e-05 - activation_2_loss: 2.0636e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.3854e-04 - val_activation_1_loss: 2.9109e-04 - val_activation_2_loss: 2.4745e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.6885e-04 - activation_1_loss: 3.2312e-05 - activation_2_loss: 2.3654e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5256e-04 - val_activation_1_loss: 1.8358e-05 - val_activation_2_loss: 3.3420e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7009e-04 - activation_1_loss: 1.8409e-05 - activation_2_loss: 1.5168e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8035e-04 - val_activation_1_loss: 1.3369e-05 - val_activation_2_loss: 2.6698e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5375e-04 - activation_1_loss: 1.1180e-05 - activation_2_loss: 3.4257e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7423e-04 - val_activation_1_loss: 1.4218e-05 - val_activation_2_loss: 3.6001e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2462e-04 - activation_1_loss: 1.1385e-05 - activation_2_loss: 2.1324e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2888e-04 - val_activation_1_loss: 1.0628e-05 - val_activation_2_loss: 1.1825e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3875e-04 - activation_1_loss: 8.9456e-06 - activation_2_loss: 1.2981e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4299e-04 - val_activation_1_loss: 7.1083e-05 - val_activation_2_loss: 1.7190e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2948e-04 - activation_1_loss: 3.7242e-05 - activation_2_loss: 3.9224e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3653e-04 - val_activation_1_loss: 1.3920e-05 - val_activation_2_loss: 2.2261e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7424e-04 - activation_1_loss: 9.6293e-06 - activation_2_loss: 1.6461e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.6211e-05 - val_activation_1_loss: 1.1988e-05 - val_activation_2_loss: 6.4223e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7908e-04 - activation_1_loss: 4.2675e-05 - activation_2_loss: 2.3641e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4610e-04 - val_activation_1_loss: 4.1563e-05 - val_activation_2_loss: 3.0454e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2071e-04 - activation_1_loss: 2.0848e-05 - activation_2_loss: 2.9986e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3640e-04 - val_activation_1_loss: 1.3554e-05 - val_activation_2_loss: 2.2285e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4832e-04 - activation_1_loss: 1.4174e-05 - activation_2_loss: 2.3415e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7277e-04 - val_activation_1_loss: 1.3078e-05 - val_activation_2_loss: 1.5969e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0021 - activation_1_loss: 0.0011 - activation_2_loss: 9.4265e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 6.5970e-04 - val_activation_1_loss: 1.5074e-04 - val_activation_2_loss: 5.0897e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8473e-04 - activation_1_loss: 2.7346e-05 - activation_2_loss: 2.5739e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1601e-04 - val_activation_1_loss: 4.7766e-05 - val_activation_2_loss: 2.6825e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3029e-04 - activation_1_loss: 1.5933e-04 - activation_2_loss: 1.7096e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9114e-04 - val_activation_1_loss: 6.5467e-05 - val_activation_2_loss: 1.2567e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0632e-04 - activation_1_loss: 9.8872e-06 - activation_2_loss: 1.9643e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4543e-05 - val_activation_1_loss: 7.5423e-06 - val_activation_2_loss: 3.7000e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.5505e-05 - activation_1_loss: 7.4579e-06 - activation_2_loss: 7.8047e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6600e-04 - val_activation_1_loss: 1.1712e-05 - val_activation_2_loss: 4.5429e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7821e-04 - activation_1_loss: 7.8889e-06 - activation_2_loss: 1.7032e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8251e-04 - val_activation_1_loss: 1.9542e-05 - val_activation_2_loss: 1.6297e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5470e-04 - activation_1_loss: 6.3386e-06 - activation_2_loss: 1.4837e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.2937e-05 - val_activation_1_loss: 1.4750e-05 - val_activation_2_loss: 3.8187e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2066e-05 - activation_1_loss: 5.1261e-06 - activation_2_loss: 4.6940e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6336e-04 - val_activation_1_loss: 3.2682e-06 - val_activation_2_loss: 2.6010e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8816e-05 - activation_1_loss: 7.8941e-06 - activation_2_loss: 6.0922e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4899e-05 - val_activation_1_loss: 6.6014e-06 - val_activation_2_loss: 2.8297e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7214e-04 - activation_1_loss: 2.4219e-05 - activation_2_loss: 1.4792e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6740e-04 - val_activation_1_loss: 2.6089e-05 - val_activation_2_loss: 1.4131e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5309e-04 - activation_1_loss: 1.3677e-05 - activation_2_loss: 1.3941e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.9341e-04 - val_activation_1_loss: 1.6010e-05 - val_activation_2_loss: 6.7740e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.3392e-04 - activation_1_loss: 1.8085e-05 - activation_2_loss: 3.1583e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4529e-04 - val_activation_1_loss: 3.0187e-05 - val_activation_2_loss: 4.1510e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.4335e-04 - activation_1_loss: 4.4173e-05 - activation_2_loss: 3.9917e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3289e-04 - val_activation_1_loss: 8.6806e-06 - val_activation_2_loss: 2.2421e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.4825e-04 - activation_1_loss: 1.9386e-05 - activation_2_loss: 2.2887e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8433e-04 - val_activation_1_loss: 7.1131e-06 - val_activation_2_loss: 2.7722e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3170e-04 - activation_1_loss: 8.4241e-06 - activation_2_loss: 1.2328e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3395e-04 - val_activation_1_loss: 4.9437e-06 - val_activation_2_loss: 1.2900e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5840e-04 - activation_1_loss: 9.8676e-06 - activation_2_loss: 1.4853e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4306e-04 - val_activation_1_loss: 5.2710e-06 - val_activation_2_loss: 4.3779e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.8420e-05 - activation_1_loss: 4.5677e-06 - activation_2_loss: 9.3852e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5380e-05 - val_activation_1_loss: 3.8218e-06 - val_activation_2_loss: 3.1558e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.3693e-05 - activation_1_loss: 5.4260e-06 - activation_2_loss: 5.8267e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.6629e-05 - val_activation_1_loss: 1.2765e-05 - val_activation_2_loss: 7.3865e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.5628e-04 - activation_1_loss: 6.3482e-06 - activation_2_loss: 3.4993e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6123e-04 - val_activation_1_loss: 6.6563e-05 - val_activation_2_loss: 1.9466e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4988e-04 - activation_1_loss: 3.1993e-05 - activation_2_loss: 1.1789e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4338e-04 - val_activation_1_loss: 7.2787e-06 - val_activation_2_loss: 1.3610e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.8944e-05 - activation_1_loss: 2.4871e-05 - activation_2_loss: 4.4074e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5223e-05 - val_activation_1_loss: 1.0105e-05 - val_activation_2_loss: 2.5119e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.2583e-05 - activation_1_loss: 7.5532e-06 - activation_2_loss: 3.5030e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.7441e-05 - val_activation_1_loss: 4.4637e-06 - val_activation_2_loss: 8.2977e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.8357e-05 - activation_1_loss: 4.6734e-06 - activation_2_loss: 8.3683e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8160e-05 - val_activation_1_loss: 4.3633e-06 - val_activation_2_loss: 4.3797e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 8.2548e-05 - activation_1_loss: 4.1322e-06 - activation_2_loss: 7.8415e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9623e-04 - val_activation_1_loss: 4.0129e-05 - val_activation_2_loss: 1.5610e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.1586e-05 - activation_1_loss: 8.5724e-06 - activation_2_loss: 8.3013e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0013 - val_activation_1_loss: 5.8543e-04 - val_activation_2_loss: 7.2401e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0013 - activation_1_loss: 5.4709e-04 - activation_2_loss: 7.4859e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 8.0444e-04 - val_activation_1_loss: 3.8419e-04 - val_activation_2_loss: 4.2025e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.9501e-04 - activation_1_loss: 6.2157e-05 - activation_2_loss: 3.3285e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0040e-04 - val_activation_1_loss: 1.6728e-05 - val_activation_2_loss: 1.8368e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.6222e-04 - activation_1_loss: 1.7360e-05 - activation_2_loss: 3.4486e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8158e-04 - val_activation_1_loss: 9.5738e-06 - val_activation_2_loss: 1.7201e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.0663e-04 - activation_1_loss: 1.8921e-05 - activation_2_loss: 1.8770e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2240e-04 - val_activation_1_loss: 1.0620e-05 - val_activation_2_loss: 1.1178e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.1707e-05 - activation_1_loss: 8.1706e-06 - activation_2_loss: 5.3536e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6332e-04 - val_activation_1_loss: 2.1266e-05 - val_activation_2_loss: 1.4205e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2332e-04 - activation_1_loss: 1.3817e-05 - activation_2_loss: 2.0951e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3330e-04 - val_activation_1_loss: 6.9812e-06 - val_activation_2_loss: 2.2632e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.7638e-05 - activation_1_loss: 1.0102e-05 - activation_2_loss: 5.7536e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7259e-05 - val_activation_1_loss: 7.8532e-06 - val_activation_2_loss: 5.9406e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2836e-04 - activation_1_loss: 1.6421e-05 - activation_2_loss: 3.1194e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.8405e-05 - val_activation_1_loss: 7.4536e-06 - val_activation_2_loss: 5.0951e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2637e-04 - activation_1_loss: 1.5553e-05 - activation_2_loss: 1.1082e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.5814e-05 - val_activation_1_loss: 4.1807e-06 - val_activation_2_loss: 5.1633e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8202e-04 - activation_1_loss: 8.2643e-06 - activation_2_loss: 1.7375e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0452e-04 - val_activation_1_loss: 1.3461e-05 - val_activation_2_loss: 3.9106e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.5400e-05 - activation_1_loss: 4.7846e-06 - activation_2_loss: 4.0615e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8893e-05 - val_activation_1_loss: 3.3624e-06 - val_activation_2_loss: 2.5530e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2601e-04 - activation_1_loss: 4.6672e-06 - activation_2_loss: 1.2135e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7830e-05 - val_activation_1_loss: 3.1349e-06 - val_activation_2_loss: 6.4696e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5741e-04 - activation_1_loss: 3.5022e-06 - activation_2_loss: 1.5390e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8740e-04 - val_activation_1_loss: 5.0971e-06 - val_activation_2_loss: 2.8230e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.9996e-04 - activation_1_loss: 1.1973e-05 - activation_2_loss: 1.8799e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5201e-04 - val_activation_1_loss: 9.4596e-06 - val_activation_2_loss: 3.4255e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.2139e-04 - activation_1_loss: 2.9341e-05 - activation_2_loss: 2.9205e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2553e-04 - val_activation_1_loss: 3.7631e-05 - val_activation_2_loss: 8.7904e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.8973e-04 - activation_1_loss: 3.9028e-05 - activation_2_loss: 2.5070e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.9207e-04 - val_activation_1_loss: 4.5851e-04 - val_activation_2_loss: 3.3356e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7273e-04 - activation_1_loss: 1.8776e-05 - activation_2_loss: 1.5396e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5659e-04 - val_activation_1_loss: 9.9905e-06 - val_activation_2_loss: 1.4660e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0012 - activation_1_loss: 5.7028e-04 - activation_2_loss: 5.9476e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 5.6669e-04 - val_activation_1_loss: 1.1751e-04 - val_activation_2_loss: 4.4918e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.8552e-04 - activation_1_loss: 4.0936e-05 - activation_2_loss: 3.4458e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3357e-04 - val_activation_1_loss: 1.1008e-05 - val_activation_2_loss: 1.2256e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.7254e-04 - activation_1_loss: 1.1613e-04 - activation_2_loss: 3.5641e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4592e-04 - val_activation_1_loss: 2.0718e-05 - val_activation_2_loss: 4.2520e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2538e-04 - activation_1_loss: 2.0229e-05 - activation_2_loss: 2.0515e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4691e-04 - val_activation_1_loss: 9.0075e-06 - val_activation_2_loss: 2.3791e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.0141e-04 - activation_1_loss: 2.7529e-05 - activation_2_loss: 2.7388e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1074e-04 - val_activation_1_loss: 2.5552e-05 - val_activation_2_loss: 2.8519e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1236e-04 - activation_1_loss: 1.6109e-05 - activation_2_loss: 9.6252e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9176e-05 - val_activation_1_loss: 1.1801e-05 - val_activation_2_loss: 7.7375e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5848e-04 - activation_1_loss: 1.4000e-04 - activation_2_loss: 1.1847e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7877e-04 - val_activation_1_loss: 2.4607e-05 - val_activation_2_loss: 1.5417e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.7150e-05 - activation_1_loss: 1.0976e-05 - activation_2_loss: 4.6174e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1392e-04 - val_activation_1_loss: 5.6870e-06 - val_activation_2_loss: 1.0823e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4249e-04 - activation_1_loss: 1.1013e-05 - activation_2_loss: 1.3148e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8586e-04 - val_activation_1_loss: 1.0961e-05 - val_activation_2_loss: 4.7490e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5184e-04 - activation_1_loss: 8.6877e-06 - activation_2_loss: 1.4315e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3688e-05 - val_activation_1_loss: 9.2322e-06 - val_activation_2_loss: 4.4456e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.1092e-04 - activation_1_loss: 5.8646e-06 - activation_2_loss: 2.0505e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.3118e-05 - val_activation_1_loss: 6.8351e-06 - val_activation_2_loss: 7.6283e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.5941e-04 - activation_1_loss: 1.2462e-05 - activation_2_loss: 1.4695e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1277e-04 - val_activation_1_loss: 6.1976e-06 - val_activation_2_loss: 2.0657e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4079e-04 - activation_1_loss: 7.6612e-06 - activation_2_loss: 1.3313e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6218e-05 - val_activation_1_loss: 2.7961e-06 - val_activation_2_loss: 3.3422e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2054e-04 - activation_1_loss: 1.1485e-05 - activation_2_loss: 1.0905e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7009e-04 - val_activation_1_loss: 1.0422e-05 - val_activation_2_loss: 2.5967e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1329e-04 - activation_1_loss: 1.3031e-05 - activation_2_loss: 1.0026e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4713e-04 - val_activation_1_loss: 5.8637e-06 - val_activation_2_loss: 2.4126e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0670e-04 - activation_1_loss: 8.3364e-06 - activation_2_loss: 9.8362e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7429e-04 - val_activation_1_loss: 1.6408e-05 - val_activation_2_loss: 1.5789e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3880e-04 - activation_1_loss: 1.4879e-05 - activation_2_loss: 1.2393e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4099e-04 - val_activation_1_loss: 8.8425e-06 - val_activation_2_loss: 3.3215e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.6144e-04 - activation_1_loss: 1.0246e-04 - activation_2_loss: 4.5897e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.8027e-04 - val_activation_1_loss: 2.3908e-05 - val_activation_2_loss: 7.5636e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 3.7220e-04 - activation_1_loss: 2.6148e-05 - activation_2_loss: 3.4606e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0030 - val_activation_1_loss: 0.0017 - val_activation_2_loss: 0.0013 - val_activation_1_acc: 0.9997 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 6.9020e-04 - activation_1_loss: 3.7251e-04 - activation_2_loss: 3.1769e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6754e-04 - val_activation_1_loss: 2.1114e-05 - val_activation_2_loss: 1.4642e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.9119e-04 - activation_1_loss: 9.8232e-05 - activation_2_loss: 1.9296e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6838e-04 - val_activation_1_loss: 7.7997e-06 - val_activation_2_loss: 2.6058e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7560e-04 - activation_1_loss: 2.0979e-05 - activation_2_loss: 2.5462e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5343e-04 - val_activation_1_loss: 2.2337e-05 - val_activation_2_loss: 1.3109e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8592e-04 - activation_1_loss: 1.6110e-05 - activation_2_loss: 1.6981e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.9816e-05 - val_activation_1_loss: 2.3453e-05 - val_activation_2_loss: 4.6363e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.2986e-04 - activation_1_loss: 1.6380e-05 - activation_2_loss: 2.1348e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4917e-04 - val_activation_1_loss: 1.5260e-05 - val_activation_2_loss: 1.3391e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0010 - activation_1_loss: 4.3204e-04 - activation_2_loss: 5.8098e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 6.9110e-04 - val_activation_1_loss: 2.1944e-04 - val_activation_2_loss: 4.7166e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.1214e-04 - activation_1_loss: 1.7883e-04 - activation_2_loss: 3.3331e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7177e-04 - val_activation_1_loss: 2.3267e-05 - val_activation_2_loss: 3.4851e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8547e-04 - activation_1_loss: 3.1091e-05 - activation_2_loss: 1.5438e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.5808e-04 - val_activation_1_loss: 2.0546e-04 - val_activation_2_loss: 5.5262e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7504e-04 - activation_1_loss: 3.3890e-05 - activation_2_loss: 1.4115e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9359e-04 - val_activation_1_loss: 3.5800e-05 - val_activation_2_loss: 1.5779e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 9.0881e-05 - activation_1_loss: 1.0469e-05 - activation_2_loss: 8.0413e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2552e-05 - val_activation_1_loss: 4.3815e-06 - val_activation_2_loss: 2.8170e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2008e-04 - activation_1_loss: 5.2353e-06 - activation_2_loss: 1.1484e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.2824e-05 - val_activation_1_loss: 4.5554e-06 - val_activation_2_loss: 6.8269e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2761e-04 - activation_1_loss: 4.3540e-05 - activation_2_loss: 8.4072e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0412e-04 - val_activation_1_loss: 1.9589e-05 - val_activation_2_loss: 8.4534e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3847e-04 - activation_1_loss: 3.1249e-05 - activation_2_loss: 1.0722e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.7259e-05 - val_activation_1_loss: 8.1280e-06 - val_activation_2_loss: 8.9131e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1308e-04 - activation_1_loss: 6.6590e-06 - activation_2_loss: 1.0642e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.5550e-05 - val_activation_1_loss: 7.2507e-06 - val_activation_2_loss: 8.8299e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4587e-04 - activation_1_loss: 1.0828e-05 - activation_2_loss: 1.3505e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1103e-04 - val_activation_1_loss: 3.9951e-06 - val_activation_2_loss: 1.0704e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.7595e-04 - activation_1_loss: 3.3691e-06 - activation_2_loss: 1.7258e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7405e-04 - val_activation_1_loss: 4.3682e-06 - val_activation_2_loss: 5.6968e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.9233e-04 - activation_1_loss: 1.4166e-04 - activation_2_loss: 3.5067e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.6591e-04 - val_activation_1_loss: 6.4320e-05 - val_activation_2_loss: 4.0159e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.1069e-04 - activation_1_loss: 1.2923e-05 - activation_2_loss: 9.7771e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5500e-04 - val_activation_1_loss: 4.1783e-06 - val_activation_2_loss: 1.5082e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.4637e-04 - activation_1_loss: 1.7697e-04 - activation_2_loss: 3.6940e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.2641e-04 - val_activation_1_loss: 3.0904e-04 - val_activation_2_loss: 4.1737e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.0011 - activation_1_loss: 4.1873e-04 - activation_2_loss: 7.1360e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1682e-04 - val_activation_1_loss: 5.4558e-05 - val_activation_2_loss: 1.6226e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7988e-04 - activation_1_loss: 4.6328e-05 - activation_2_loss: 2.3355e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1229e-04 - val_activation_1_loss: 4.1214e-05 - val_activation_2_loss: 1.7108e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3357e-04 - activation_1_loss: 1.7531e-05 - activation_2_loss: 1.1604e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4776e-04 - val_activation_1_loss: 6.1955e-06 - val_activation_2_loss: 1.4157e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.3357e-04 - activation_1_loss: 5.5833e-05 - activation_2_loss: 1.7773e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9193e-05 - val_activation_1_loss: 1.1712e-05 - val_activation_2_loss: 2.7480e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.4939e-04 - activation_1_loss: 1.7314e-05 - activation_2_loss: 1.3208e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3879e-04 - val_activation_1_loss: 4.8320e-06 - val_activation_2_loss: 1.3395e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.3383e-04 - activation_1_loss: 6.8799e-06 - activation_2_loss: 1.2695e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.5238e-05 - val_activation_1_loss: 4.1759e-06 - val_activation_2_loss: 9.1062e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.8086e-04 - activation_1_loss: 3.3060e-06 - activation_2_loss: 1.7756e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8361e-04 - val_activation_1_loss: 1.1819e-05 - val_activation_2_loss: 3.7180e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.7395e-04 - activation_1_loss: 1.2927e-05 - activation_2_loss: 2.6103e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0489e-05 - val_activation_1_loss: 7.7674e-06 - val_activation_2_loss: 4.2721e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2052e-04 - activation_1_loss: 1.0699e-05 - activation_2_loss: 1.0982e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0416e-04 - val_activation_1_loss: 2.9325e-05 - val_activation_2_loss: 2.7484e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 4.1774e-04 - activation_1_loss: 2.4866e-04 - activation_2_loss: 1.6908e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1407e-04 - val_activation_1_loss: 6.1797e-06 - val_activation_2_loss: 1.0789e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.0091e-04 - activation_1_loss: 1.0465e-05 - activation_2_loss: 9.0448e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.8357e-05 - val_activation_1_loss: 3.0240e-06 - val_activation_2_loss: 8.5333e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 2.5136e-04 - activation_1_loss: 1.4673e-05 - activation_2_loss: 2.3668e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7510e-04 - val_activation_1_loss: 5.6012e-06 - val_activation_2_loss: 1.6949e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0505e-04 - activation_1_loss: 1.0026e-05 - activation_2_loss: 9.5021e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6199e-04 - val_activation_1_loss: 3.0537e-05 - val_activation_2_loss: 1.3146e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 27s 3ms/step - loss: 2.6692e-05 - activation_1_loss: 6.3637e-06 - activation_2_loss: 2.0328e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1194e-05 - val_activation_1_loss: 3.4134e-06 - val_activation_2_loss: 1.7781e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4495e-04 - activation_1_loss: 6.7666e-06 - activation_2_loss: 2.3818e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.2697e-04 - val_activation_1_loss: 3.4651e-06 - val_activation_2_loss: 4.2350e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2082e-04 - activation_1_loss: 1.0494e-05 - activation_2_loss: 1.1033e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0461e-05 - val_activation_1_loss: 3.2015e-06 - val_activation_2_loss: 3.7260e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2904e-04 - activation_1_loss: 9.6008e-06 - activation_2_loss: 1.1944e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1190e-05 - val_activation_1_loss: 6.2231e-06 - val_activation_2_loss: 4.4967e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2819e-04 - activation_1_loss: 1.0073e-05 - activation_2_loss: 1.1811e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1190e-04 - val_activation_1_loss: 2.1516e-05 - val_activation_2_loss: 2.9038e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8018e-04 - activation_1_loss: 3.5963e-04 - activation_2_loss: 1.2055e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8963e-04 - val_activation_1_loss: 2.6553e-04 - val_activation_2_loss: 5.2411e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.3649e-04 - activation_1_loss: 2.5396e-04 - activation_2_loss: 4.8253e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 5.9282e-04 - val_activation_1_loss: 6.6227e-05 - val_activation_2_loss: 5.2659e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0458e-04 - activation_1_loss: 6.8657e-05 - activation_2_loss: 2.3592e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8552e-04 - val_activation_1_loss: 2.3687e-05 - val_activation_2_loss: 2.6183e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8959e-04 - activation_1_loss: 3.7242e-05 - activation_2_loss: 2.5235e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0987e-04 - val_activation_1_loss: 9.2613e-06 - val_activation_2_loss: 5.0061e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8387e-04 - activation_1_loss: 3.3227e-05 - activation_2_loss: 2.5064e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6178e-04 - val_activation_1_loss: 1.0102e-05 - val_activation_2_loss: 1.5167e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8839e-04 - activation_1_loss: 2.3748e-05 - activation_2_loss: 2.6464e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2568e-04 - val_activation_1_loss: 1.4921e-05 - val_activation_2_loss: 2.1076e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5744e-04 - activation_1_loss: 8.9178e-06 - activation_2_loss: 1.4853e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2935e-05 - val_activation_1_loss: 5.9905e-06 - val_activation_2_loss: 5.6945e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1090e-04 - activation_1_loss: 1.3199e-05 - activation_2_loss: 9.7701e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0167e-04 - val_activation_1_loss: 8.1924e-06 - val_activation_2_loss: 9.3477e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1129e-04 - activation_1_loss: 4.2712e-06 - activation_2_loss: 1.0701e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9630e-05 - val_activation_1_loss: 4.8512e-06 - val_activation_2_loss: 5.4778e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3137e-04 - activation_1_loss: 4.5498e-06 - activation_2_loss: 1.2683e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7812e-04 - val_activation_1_loss: 8.9367e-06 - val_activation_2_loss: 2.6918e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2504e-04 - activation_1_loss: 8.2506e-05 - activation_2_loss: 1.4254e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5030e-05 - val_activation_1_loss: 6.7960e-06 - val_activation_2_loss: 3.8234e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5582e-05 - activation_1_loss: 4.3739e-06 - activation_2_loss: 6.1208e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5731e-05 - val_activation_1_loss: 4.0417e-06 - val_activation_2_loss: 3.1689e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6018e-04 - activation_1_loss: 5.6584e-06 - activation_2_loss: 1.5452e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.9815e-05 - val_activation_1_loss: 4.5563e-06 - val_activation_2_loss: 7.5259e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.7816e-05 - activation_1_loss: 7.5889e-06 - activation_2_loss: 7.0227e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3004e-05 - val_activation_1_loss: 9.2591e-06 - val_activation_2_loss: 4.3745e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6856e-04 - activation_1_loss: 3.7940e-04 - activation_2_loss: 2.8915e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2971e-04 - val_activation_1_loss: 7.2159e-05 - val_activation_2_loss: 1.5755e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5481e-04 - activation_1_loss: 2.2400e-04 - activation_2_loss: 2.3081e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9067e-04 - val_activation_1_loss: 1.9928e-05 - val_activation_2_loss: 5.7074e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5702e-04 - activation_1_loss: 2.5314e-05 - activation_2_loss: 1.3170e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4266e-04 - val_activation_1_loss: 1.4188e-05 - val_activation_2_loss: 1.2848e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2059e-04 - activation_1_loss: 1.2355e-05 - activation_2_loss: 2.0824e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8322e-04 - val_activation_1_loss: 3.0258e-05 - val_activation_2_loss: 2.5296e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.6801e-04 - activation_1_loss: 1.7168e-04 - activation_2_loss: 3.9633e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6563e-04 - val_activation_1_loss: 9.2504e-06 - val_activation_2_loss: 3.5638e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1589e-04 - activation_1_loss: 2.3342e-05 - activation_2_loss: 9.2552e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9273e-05 - val_activation_1_loss: 5.3188e-06 - val_activation_2_loss: 1.3954e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2119e-04 - activation_1_loss: 8.0026e-06 - activation_2_loss: 1.1319e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.4799e-05 - val_activation_1_loss: 2.0831e-05 - val_activation_2_loss: 6.3968e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9819e-04 - activation_1_loss: 5.9961e-06 - activation_2_loss: 1.9219e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7173e-04 - val_activation_1_loss: 5.0060e-06 - val_activation_2_loss: 2.6673e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.9612e-05 - activation_1_loss: 1.9382e-05 - activation_2_loss: 6.0230e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2848e-05 - val_activation_1_loss: 6.7483e-06 - val_activation_2_loss: 1.6099e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9060e-05 - activation_1_loss: 6.1850e-06 - activation_2_loss: 4.2875e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0680e-04 - val_activation_1_loss: 1.1692e-05 - val_activation_2_loss: 9.5109e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0481e-04 - activation_1_loss: 3.6037e-06 - activation_2_loss: 2.0121e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0688e-04 - val_activation_1_loss: 3.4441e-06 - val_activation_2_loss: 1.0343e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2588e-04 - activation_1_loss: 1.2953e-05 - activation_2_loss: 2.1293e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.7985e-04 - val_activation_1_loss: 4.4699e-05 - val_activation_2_loss: 4.3515e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4154e-04 - activation_1_loss: 9.0374e-05 - activation_2_loss: 1.5116e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.5692e-05 - val_activation_1_loss: 7.4445e-06 - val_activation_2_loss: 5.8248e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3427e-04 - activation_1_loss: 1.9842e-04 - activation_2_loss: 2.3585e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5544e-04 - val_activation_1_loss: 2.8351e-05 - val_activation_2_loss: 2.2709e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2260e-04 - activation_1_loss: 1.1409e-05 - activation_2_loss: 3.1120e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1690e-04 - val_activation_1_loss: 1.1400e-05 - val_activation_2_loss: 2.0550e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1852e-04 - activation_1_loss: 6.1655e-05 - activation_2_loss: 2.5686e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7548e-04 - val_activation_1_loss: 3.9155e-05 - val_activation_2_loss: 3.3633e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0585e-04 - activation_1_loss: 2.1096e-05 - activation_2_loss: 2.8476e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4180e-04 - val_activation_1_loss: 1.8928e-05 - val_activation_2_loss: 1.2287e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3546e-04 - activation_1_loss: 1.8281e-05 - activation_2_loss: 4.1718e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3642e-04 - val_activation_1_loss: 1.5877e-05 - val_activation_2_loss: 2.2054e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8931e-04 - activation_1_loss: 1.6702e-05 - activation_2_loss: 1.7261e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2896e-04 - val_activation_1_loss: 2.9794e-05 - val_activation_2_loss: 1.9917e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3481e-04 - activation_1_loss: 1.2275e-05 - activation_2_loss: 1.2254e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3057e-05 - val_activation_1_loss: 2.9994e-05 - val_activation_2_loss: 4.3063e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6212e-04 - activation_1_loss: 7.0816e-05 - activation_2_loss: 9.1301e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9830e-05 - val_activation_1_loss: 9.5969e-06 - val_activation_2_loss: 5.0233e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4110e-04 - activation_1_loss: 1.2321e-05 - activation_2_loss: 1.2878e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9204e-04 - val_activation_1_loss: 2.6438e-05 - val_activation_2_loss: 8.6560e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5512e-05 - activation_1_loss: 9.4974e-06 - activation_2_loss: 8.6014e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8603e-04 - val_activation_1_loss: 8.6614e-06 - val_activation_2_loss: 2.7737e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5082e-04 - activation_1_loss: 4.2884e-05 - activation_2_loss: 1.0794e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1638e-04 - val_activation_1_loss: 4.2324e-05 - val_activation_2_loss: 7.4059e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1244e-04 - activation_1_loss: 2.5690e-05 - activation_2_loss: 8.6749e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7912e-04 - val_activation_1_loss: 3.8036e-05 - val_activation_2_loss: 5.4108e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6523e-04 - activation_1_loss: 6.3586e-06 - activation_2_loss: 1.5887e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0011 - val_activation_1_loss: 6.3665e-06 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2119e-04 - activation_1_loss: 9.8623e-06 - activation_2_loss: 1.1133e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2367e-04 - val_activation_1_loss: 1.0129e-05 - val_activation_2_loss: 2.1354e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2700e-04 - activation_1_loss: 2.9311e-05 - activation_2_loss: 9.7687e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6603e-04 - val_activation_1_loss: 8.1578e-06 - val_activation_2_loss: 2.5787e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7396e-04 - activation_1_loss: 3.5218e-05 - activation_2_loss: 2.3874e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4933e-04 - val_activation_1_loss: 6.0232e-05 - val_activation_2_loss: 2.8910e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4932e-04 - activation_1_loss: 2.6205e-05 - activation_2_loss: 3.2311e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0671e-04 - val_activation_1_loss: 8.7671e-06 - val_activation_2_loss: 9.7942e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4991e-04 - activation_1_loss: 2.1959e-05 - activation_2_loss: 2.2795e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6586e-04 - val_activation_1_loss: 1.2229e-05 - val_activation_2_loss: 1.5363e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3569e-04 - activation_1_loss: 1.2817e-05 - activation_2_loss: 2.2287e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9246e-04 - val_activation_1_loss: 1.3059e-05 - val_activation_2_loss: 1.7940e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.9740e-05 - activation_1_loss: 8.1757e-06 - activation_2_loss: 7.1564e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7747e-04 - val_activation_1_loss: 1.0183e-05 - val_activation_2_loss: 3.6729e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4891e-04 - activation_1_loss: 3.7382e-05 - activation_2_loss: 3.1153e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6887e-04 - val_activation_1_loss: 2.9647e-05 - val_activation_2_loss: 2.3922e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1245e-04 - activation_1_loss: 5.6782e-05 - activation_2_loss: 2.5567e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7664e-04 - val_activation_1_loss: 1.6160e-05 - val_activation_2_loss: 1.6048e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2691e-04 - activation_1_loss: 1.7798e-05 - activation_2_loss: 2.0911e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5093e-04 - val_activation_1_loss: 1.5349e-05 - val_activation_2_loss: 1.3558e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4057e-05 - activation_1_loss: 1.8610e-05 - activation_2_loss: 6.5447e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.7304e-05 - val_activation_1_loss: 5.3239e-06 - val_activation_2_loss: 8.1980e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.4803e-05 - activation_1_loss: 3.9743e-06 - activation_2_loss: 7.0829e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4174e-05 - val_activation_1_loss: 3.5237e-06 - val_activation_2_loss: 4.0651e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1717e-05 - activation_1_loss: 2.0705e-05 - activation_2_loss: 2.1012e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0885e-05 - val_activation_1_loss: 2.5360e-06 - val_activation_2_loss: 2.8349e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3113e-05 - activation_1_loss: 7.4571e-06 - activation_2_loss: 2.5655e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4197e-05 - val_activation_1_loss: 2.8743e-06 - val_activation_2_loss: 1.1323e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.9569e-05 - activation_1_loss: 4.8390e-06 - activation_2_loss: 7.4730e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2344e-05 - val_activation_1_loss: 6.5275e-06 - val_activation_2_loss: 5.5816e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4015e-05 - activation_1_loss: 1.6030e-05 - activation_2_loss: 3.7985e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4806e-05 - val_activation_1_loss: 5.5536e-06 - val_activation_2_loss: 1.9252e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0655e-04 - activation_1_loss: 7.7398e-06 - activation_2_loss: 1.9881e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5790e-04 - val_activation_1_loss: 1.5262e-05 - val_activation_2_loss: 3.4264e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4238e-04 - activation_1_loss: 2.7788e-05 - activation_2_loss: 2.1460e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3557e-04 - val_activation_1_loss: 2.1753e-05 - val_activation_2_loss: 1.1381e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1043e-04 - activation_1_loss: 1.0525e-05 - activation_2_loss: 2.9990e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7089e-04 - val_activation_1_loss: 3.5771e-05 - val_activation_2_loss: 2.3512e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3214e-04 - activation_1_loss: 3.7168e-05 - activation_2_loss: 1.9497e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.6500e-05 - val_activation_1_loss: 7.5657e-06 - val_activation_2_loss: 5.8934e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.7015e-05 - activation_1_loss: 9.4488e-06 - activation_2_loss: 8.7567e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6013e-04 - val_activation_1_loss: 1.3181e-05 - val_activation_2_loss: 1.4695e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 7.7130e-05 - activation_1_loss: 7.6825e-06 - activation_2_loss: 6.9447e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1703e-05 - val_activation_1_loss: 6.9373e-06 - val_activation_2_loss: 4.4766e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1205e-04 - activation_1_loss: 5.3526e-06 - activation_2_loss: 1.0669e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5204e-04 - val_activation_1_loss: 7.2731e-06 - val_activation_2_loss: 1.4476e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4760e-04 - activation_1_loss: 4.8643e-06 - activation_2_loss: 1.4273e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0762e-04 - val_activation_1_loss: 1.0784e-05 - val_activation_2_loss: 2.9684e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5412e-04 - activation_1_loss: 1.0948e-05 - activation_2_loss: 1.4318e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.5555e-05 - val_activation_1_loss: 2.9340e-05 - val_activation_2_loss: 6.6215e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8025e-04 - activation_1_loss: 1.5566e-04 - activation_2_loss: 1.2459e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3248e-04 - val_activation_1_loss: 2.3433e-05 - val_activation_2_loss: 4.0905e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0014 - activation_1_loss: 4.9776e-04 - activation_2_loss: 8.9196e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9998 - val_loss: 6.5532e-04 - val_activation_1_loss: 1.8466e-04 - val_activation_2_loss: 4.7066e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2453e-04 - activation_1_loss: 1.1866e-04 - activation_2_loss: 4.0587e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.2002e-05 - val_activation_1_loss: 1.9836e-05 - val_activation_2_loss: 5.2167e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1491e-04 - activation_1_loss: 2.1618e-05 - activation_2_loss: 9.3290e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2530e-04 - val_activation_1_loss: 2.4440e-05 - val_activation_2_loss: 2.0086e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4319e-04 - activation_1_loss: 1.0342e-05 - activation_2_loss: 1.3285e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7445e-04 - val_activation_1_loss: 2.9498e-06 - val_activation_2_loss: 1.7150e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.0067e-05 - activation_1_loss: 9.7612e-06 - activation_2_loss: 6.0306e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0042e-04 - val_activation_1_loss: 1.0525e-05 - val_activation_2_loss: 8.9892e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5155e-04 - activation_1_loss: 7.2629e-06 - activation_2_loss: 1.4429e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8940e-05 - val_activation_1_loss: 3.2878e-06 - val_activation_2_loss: 1.5652e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1005e-04 - activation_1_loss: 4.8096e-06 - activation_2_loss: 1.0525e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3877e-04 - val_activation_1_loss: 5.9942e-06 - val_activation_2_loss: 4.3277e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8297e-04 - activation_1_loss: 1.3429e-05 - activation_2_loss: 1.6954e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9384e-05 - val_activation_1_loss: 6.2416e-06 - val_activation_2_loss: 2.3142e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3625e-04 - activation_1_loss: 6.1152e-06 - activation_2_loss: 1.3013e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8307e-04 - val_activation_1_loss: 2.6713e-06 - val_activation_2_loss: 2.8040e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0051e-05 - activation_1_loss: 3.3785e-06 - activation_2_loss: 4.6673e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0510e-04 - val_activation_1_loss: 7.8428e-06 - val_activation_2_loss: 3.9726e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5025e-05 - activation_1_loss: 4.4635e-06 - activation_2_loss: 9.0561e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5800e-04 - val_activation_1_loss: 1.0264e-04 - val_activation_2_loss: 5.5357e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7872e-05 - activation_1_loss: 5.3080e-06 - activation_2_loss: 3.2564e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0777e-05 - val_activation_1_loss: 3.3335e-06 - val_activation_2_loss: 3.7444e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7553e-05 - activation_1_loss: 5.4271e-06 - activation_2_loss: 8.2126e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4190e-05 - val_activation_1_loss: 3.7877e-06 - val_activation_2_loss: 9.0402e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.9703e-04 - activation_1_loss: 3.5868e-05 - activation_2_loss: 5.6116e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9787e-04 - val_activation_1_loss: 2.8182e-05 - val_activation_2_loss: 2.6969e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.0062e-04 - activation_1_loss: 2.2016e-05 - activation_2_loss: 3.7861e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9913e-04 - val_activation_1_loss: 4.8938e-06 - val_activation_2_loss: 1.9424e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6303e-04 - activation_1_loss: 1.3117e-05 - activation_2_loss: 1.4992e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1883e-04 - val_activation_1_loss: 8.0092e-06 - val_activation_2_loss: 2.1082e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2103e-04 - activation_1_loss: 8.9889e-05 - activation_2_loss: 3.3114e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2288e-04 - val_activation_1_loss: 7.9049e-06 - val_activation_2_loss: 1.1498e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9865e-04 - activation_1_loss: 2.0280e-05 - activation_2_loss: 1.7837e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2121e-05 - val_activation_1_loss: 7.7534e-06 - val_activation_2_loss: 1.4368e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.2641e-05 - activation_1_loss: 5.4359e-06 - activation_2_loss: 8.7205e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.1925e-05 - val_activation_1_loss: 4.3222e-06 - val_activation_2_loss: 5.7603e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6376e-04 - activation_1_loss: 2.1152e-05 - activation_2_loss: 1.4261e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6998e-05 - val_activation_1_loss: 3.8173e-06 - val_activation_2_loss: 2.3181e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0992e-04 - activation_1_loss: 1.6831e-05 - activation_2_loss: 1.9309e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9497e-05 - val_activation_1_loss: 1.4494e-05 - val_activation_2_loss: 7.5003e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8269e-04 - activation_1_loss: 8.0042e-06 - activation_2_loss: 1.7469e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6952e-05 - val_activation_1_loss: 5.2800e-06 - val_activation_2_loss: 4.1672e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4623e-04 - activation_1_loss: 1.5598e-05 - activation_2_loss: 2.3063e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.9604e-05 - val_activation_1_loss: 1.2684e-05 - val_activation_2_loss: 8.6920e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4015e-04 - activation_1_loss: 2.1300e-05 - activation_2_loss: 2.1885e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.4973e-05 - val_activation_1_loss: 5.7414e-06 - val_activation_2_loss: 7.9232e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2416e-04 - activation_1_loss: 8.0559e-06 - activation_2_loss: 1.1610e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8451e-04 - val_activation_1_loss: 6.9761e-06 - val_activation_2_loss: 1.7753e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6440e-04 - activation_1_loss: 4.3357e-05 - activation_2_loss: 1.2105e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0614e-04 - val_activation_1_loss: 1.0811e-05 - val_activation_2_loss: 2.9533e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4500e-04 - activation_1_loss: 8.8527e-05 - activation_2_loss: 4.5647e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0094e-04 - val_activation_1_loss: 4.4213e-05 - val_activation_2_loss: 3.5673e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.0625e-04 - activation_1_loss: 4.1163e-04 - activation_2_loss: 4.9462e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 2.9972e-04 - val_activation_1_loss: 5.2717e-05 - val_activation_2_loss: 2.4700e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8409e-04 - activation_1_loss: 4.3604e-05 - activation_2_loss: 1.4048e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1892e-04 - val_activation_1_loss: 2.8254e-05 - val_activation_2_loss: 9.0662e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0797e-04 - activation_1_loss: 7.0722e-05 - activation_2_loss: 2.3725e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.2562e-04 - val_activation_1_loss: 7.2153e-06 - val_activation_2_loss: 5.1840e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2829e-04 - activation_1_loss: 1.5334e-05 - activation_2_loss: 2.1295e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1794e-04 - val_activation_1_loss: 4.6695e-05 - val_activation_2_loss: 2.7124e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2895e-04 - activation_1_loss: 5.9684e-06 - activation_2_loss: 1.2298e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5270e-04 - val_activation_1_loss: 3.7378e-06 - val_activation_2_loss: 1.4897e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0697e-04 - activation_1_loss: 6.8578e-06 - activation_2_loss: 1.0011e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1619e-04 - val_activation_1_loss: 3.8520e-06 - val_activation_2_loss: 1.1234e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.8414e-05 - activation_1_loss: 6.2756e-06 - activation_2_loss: 8.2139e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7491e-04 - val_activation_1_loss: 3.2812e-06 - val_activation_2_loss: 3.7163e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4304e-05 - activation_1_loss: 4.7253e-06 - activation_2_loss: 3.9579e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.5494e-05 - val_activation_1_loss: 4.4157e-06 - val_activation_2_loss: 7.1079e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0301e-04 - activation_1_loss: 6.5545e-06 - activation_2_loss: 1.9646e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8484e-04 - val_activation_1_loss: 6.3221e-05 - val_activation_2_loss: 3.2162e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2193e-04 - activation_1_loss: 7.3977e-06 - activation_2_loss: 2.1453e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9383e-05 - val_activation_1_loss: 4.8472e-06 - val_activation_2_loss: 9.4536e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0243e-04 - activation_1_loss: 6.5691e-06 - activation_2_loss: 9.5866e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4619e-04 - val_activation_1_loss: 4.9649e-06 - val_activation_2_loss: 1.4123e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9017e-05 - activation_1_loss: 4.0925e-06 - activation_2_loss: 2.4924e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8951e-05 - val_activation_1_loss: 1.8786e-05 - val_activation_2_loss: 6.0165e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2880e-04 - activation_1_loss: 4.2611e-06 - activation_2_loss: 1.2454e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7181e-05 - val_activation_1_loss: 6.9553e-06 - val_activation_2_loss: 6.0226e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4162e-04 - activation_1_loss: 2.3304e-05 - activation_2_loss: 1.1832e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4236e-05 - val_activation_1_loss: 1.4510e-05 - val_activation_2_loss: 1.9726e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2137e-04 - activation_1_loss: 5.7199e-06 - activation_2_loss: 1.1565e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2831e-04 - val_activation_1_loss: 2.0482e-06 - val_activation_2_loss: 2.2626e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0015 - activation_1_loss: 6.7714e-04 - activation_2_loss: 7.8353e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 2.0941e-04 - val_activation_1_loss: 8.6302e-05 - val_activation_2_loss: 1.2311e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1923e-04 - activation_1_loss: 2.4009e-05 - activation_2_loss: 2.9522e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8511e-04 - val_activation_1_loss: 2.8496e-04 - val_activation_2_loss: 1.0015e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2622e-04 - activation_1_loss: 1.5969e-04 - activation_2_loss: 2.6653e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5308e-04 - val_activation_1_loss: 6.5720e-05 - val_activation_2_loss: 8.7356e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0216e-04 - activation_1_loss: 1.7679e-05 - activation_2_loss: 8.4482e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6951e-04 - val_activation_1_loss: 5.8316e-05 - val_activation_2_loss: 1.1120e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2457e-04 - activation_1_loss: 6.8175e-06 - activation_2_loss: 1.1776e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.1606e-05 - val_activation_1_loss: 4.5357e-05 - val_activation_2_loss: 4.6248e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0094e-04 - activation_1_loss: 2.8123e-04 - activation_2_loss: 5.1971e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3236e-04 - val_activation_1_loss: 4.3355e-05 - val_activation_2_loss: 8.9005e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3186e-04 - activation_1_loss: 9.3245e-05 - activation_2_loss: 3.3862e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9330e-04 - val_activation_1_loss: 4.7003e-05 - val_activation_2_loss: 1.4630e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3398e-04 - activation_1_loss: 1.7580e-05 - activation_2_loss: 1.1640e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3424e-05 - val_activation_1_loss: 9.5067e-06 - val_activation_2_loss: 3.3917e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6566e-05 - activation_1_loss: 1.5180e-05 - activation_2_loss: 5.1386e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2537e-05 - val_activation_1_loss: 7.0786e-06 - val_activation_2_loss: 2.5458e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.1795e-05 - activation_1_loss: 2.1048e-05 - activation_2_loss: 5.0748e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4114e-04 - val_activation_1_loss: 4.4632e-06 - val_activation_2_loss: 2.3668e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7767e-04 - activation_1_loss: 4.8207e-06 - activation_2_loss: 1.7285e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0433e-04 - val_activation_1_loss: 1.5072e-05 - val_activation_2_loss: 2.8926e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3725e-04 - activation_1_loss: 3.8949e-06 - activation_2_loss: 1.3336e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5912e-05 - val_activation_1_loss: 1.8628e-05 - val_activation_2_loss: 1.7284e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8743e-05 - activation_1_loss: 1.0650e-05 - activation_2_loss: 6.8093e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2228e-04 - val_activation_1_loss: 5.2598e-06 - val_activation_2_loss: 1.1702e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8450e-04 - activation_1_loss: 9.7822e-06 - activation_2_loss: 2.7472e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.8578e-04 - val_activation_1_loss: 1.0840e-05 - val_activation_2_loss: 6.7494e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3039e-04 - activation_1_loss: 6.4507e-06 - activation_2_loss: 1.2394e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4640e-05 - val_activation_1_loss: 3.4783e-05 - val_activation_2_loss: 2.9857e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6881e-04 - activation_1_loss: 3.2889e-05 - activation_2_loss: 1.3592e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2130e-05 - val_activation_1_loss: 1.3068e-05 - val_activation_2_loss: 1.9062e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5335e-05 - activation_1_loss: 2.1231e-05 - activation_2_loss: 4.4105e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2732e-05 - val_activation_1_loss: 1.0466e-05 - val_activation_2_loss: 4.2266e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3727e-04 - activation_1_loss: 1.8837e-05 - activation_2_loss: 1.1844e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3552e-05 - val_activation_1_loss: 2.2151e-06 - val_activation_2_loss: 1.1337e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.8474e-05 - activation_1_loss: 4.8746e-06 - activation_2_loss: 5.3599e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0672e-05 - val_activation_1_loss: 2.5310e-06 - val_activation_2_loss: 5.8141e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2602e-04 - activation_1_loss: 2.5787e-05 - activation_2_loss: 3.0024e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.8508e-04 - val_activation_1_loss: 1.3598e-05 - val_activation_2_loss: 5.7148e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9385e-04 - activation_1_loss: 8.6989e-06 - activation_2_loss: 3.8515e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.0332e-05 - val_activation_1_loss: 7.5677e-06 - val_activation_2_loss: 6.2764e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2448e-04 - activation_1_loss: 1.6163e-05 - activation_2_loss: 1.0831e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9526e-04 - val_activation_1_loss: 2.2538e-05 - val_activation_2_loss: 1.7272e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5152e-05 - activation_1_loss: 6.0558e-06 - activation_2_loss: 5.9096e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4324e-04 - val_activation_1_loss: 2.6796e-06 - val_activation_2_loss: 1.4056e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4761e-04 - activation_1_loss: 1.6600e-05 - activation_2_loss: 1.3101e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.7381e-05 - val_activation_1_loss: 5.5038e-06 - val_activation_2_loss: 4.1877e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1273e-04 - activation_1_loss: 2.3844e-05 - activation_2_loss: 8.8888e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9751e-05 - val_activation_1_loss: 1.5374e-05 - val_activation_2_loss: 4.4377e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6897e-05 - activation_1_loss: 3.4734e-06 - activation_2_loss: 2.3424e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0663e-04 - val_activation_1_loss: 9.4012e-06 - val_activation_2_loss: 9.7233e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0461e-04 - activation_1_loss: 3.9597e-06 - activation_2_loss: 1.0066e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1449e-04 - val_activation_1_loss: 4.6549e-06 - val_activation_2_loss: 5.0984e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.8694e-05 - activation_1_loss: 1.4297e-05 - activation_2_loss: 7.4398e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4339e-05 - val_activation_1_loss: 3.3638e-06 - val_activation_2_loss: 3.0976e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0723e-04 - activation_1_loss: 1.9015e-04 - activation_2_loss: 1.1707e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.4457e-05 - val_activation_1_loss: 1.6724e-05 - val_activation_2_loss: 5.7733e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0695e-04 - activation_1_loss: 4.1232e-05 - activation_2_loss: 6.5718e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7451e-04 - val_activation_1_loss: 2.2732e-04 - val_activation_2_loss: 1.4719e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3858e-04 - activation_1_loss: 5.4674e-05 - activation_2_loss: 1.8390e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.2195e-05 - val_activation_1_loss: 1.4480e-05 - val_activation_2_loss: 5.7715e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9953e-04 - activation_1_loss: 2.6012e-04 - activation_2_loss: 4.3941e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 1.2742e-04 - val_activation_1_loss: 1.5115e-05 - val_activation_2_loss: 1.1231e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4655e-04 - activation_1_loss: 1.2239e-05 - activation_2_loss: 2.3431e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1619e-04 - val_activation_1_loss: 1.8509e-05 - val_activation_2_loss: 1.9768e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.4174e-04 - activation_1_loss: 2.8972e-04 - activation_2_loss: 4.5202e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.4252e-04 - val_activation_1_loss: 7.7446e-05 - val_activation_2_loss: 4.6507e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5789e-04 - activation_1_loss: 3.8092e-04 - activation_2_loss: 2.7697e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.3951e-05 - val_activation_1_loss: 5.6963e-05 - val_activation_2_loss: 3.6988e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7948e-04 - activation_1_loss: 1.0800e-04 - activation_2_loss: 1.7148e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.1423e-05 - val_activation_1_loss: 7.9718e-06 - val_activation_2_loss: 8.3451e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3727e-04 - activation_1_loss: 6.1578e-05 - activation_2_loss: 7.5690e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3690e-05 - val_activation_1_loss: 2.4037e-05 - val_activation_2_loss: 4.9653e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1490e-04 - activation_1_loss: 2.2709e-05 - activation_2_loss: 1.9219e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.7620e-05 - val_activation_1_loss: 3.5442e-05 - val_activation_2_loss: 4.2178e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9571e-05 - activation_1_loss: 1.1072e-05 - activation_2_loss: 7.8499e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2463e-04 - val_activation_1_loss: 3.7625e-06 - val_activation_2_loss: 1.2087e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9862e-05 - activation_1_loss: 1.1957e-05 - activation_2_loss: 2.7904e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9769e-05 - val_activation_1_loss: 3.9890e-05 - val_activation_2_loss: 5.9879e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0003e-04 - activation_1_loss: 9.0509e-06 - activation_2_loss: 1.9098e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0098e-04 - val_activation_1_loss: 2.8088e-06 - val_activation_2_loss: 9.8170e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.6081e-05 - activation_1_loss: 5.0198e-06 - activation_2_loss: 5.1061e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7451e-04 - val_activation_1_loss: 2.1762e-05 - val_activation_2_loss: 3.5275e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5023e-04 - activation_1_loss: 7.6728e-05 - activation_2_loss: 7.3504e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1610e-05 - val_activation_1_loss: 8.2586e-06 - val_activation_2_loss: 6.3351e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7158e-05 - activation_1_loss: 5.5834e-06 - activation_2_loss: 6.1575e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0508e-04 - val_activation_1_loss: 2.7514e-06 - val_activation_2_loss: 1.0233e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6161e-04 - activation_1_loss: 1.4179e-05 - activation_2_loss: 2.4743e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.5719e-04 - val_activation_1_loss: 3.7626e-06 - val_activation_2_loss: 6.5342e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1712e-04 - activation_1_loss: 5.4289e-06 - activation_2_loss: 1.1169e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4732e-04 - val_activation_1_loss: 2.3970e-05 - val_activation_2_loss: 2.2335e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4434e-04 - activation_1_loss: 1.0821e-05 - activation_2_loss: 1.3352e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8972e-05 - val_activation_1_loss: 2.5777e-06 - val_activation_2_loss: 2.6394e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.7181e-04 - activation_1_loss: 1.1649e-04 - activation_2_loss: 3.5532e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3258e-04 - val_activation_1_loss: 4.5364e-05 - val_activation_2_loss: 8.7212e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3668e-04 - activation_1_loss: 2.9883e-05 - activation_2_loss: 1.0679e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4429e-04 - val_activation_1_loss: 6.3809e-05 - val_activation_2_loss: 2.8049e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2205e-04 - activation_1_loss: 1.1353e-04 - activation_2_loss: 4.0851e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9851e-04 - val_activation_1_loss: 4.5430e-05 - val_activation_2_loss: 1.5308e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2706e-04 - activation_1_loss: 1.2610e-04 - activation_2_loss: 2.0097e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6349e-04 - val_activation_1_loss: 1.1989e-05 - val_activation_2_loss: 1.5150e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5884e-04 - activation_1_loss: 2.6595e-05 - activation_2_loss: 1.3224e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1936e-04 - val_activation_1_loss: 2.8119e-05 - val_activation_2_loss: 2.9124e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0419e-04 - activation_1_loss: 6.3071e-06 - activation_2_loss: 1.9788e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.4592e-05 - val_activation_1_loss: 4.1455e-06 - val_activation_2_loss: 6.0447e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1550e-04 - activation_1_loss: 1.0731e-05 - activation_2_loss: 1.0477e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7171e-04 - val_activation_1_loss: 1.3380e-05 - val_activation_2_loss: 3.5833e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0117e-04 - activation_1_loss: 1.3910e-05 - activation_2_loss: 8.7265e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8741e-04 - val_activation_1_loss: 1.3934e-05 - val_activation_2_loss: 1.7347e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2543e-05 - activation_1_loss: 3.4125e-06 - activation_2_loss: 4.9131e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9736e-05 - val_activation_1_loss: 4.2554e-06 - val_activation_2_loss: 5.5480e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5394e-05 - activation_1_loss: 6.8067e-06 - activation_2_loss: 2.8587e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9995e-05 - val_activation_1_loss: 4.2713e-06 - val_activation_2_loss: 7.5724e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1837e-04 - activation_1_loss: 8.6001e-06 - activation_2_loss: 1.0977e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4012e-04 - val_activation_1_loss: 6.7962e-05 - val_activation_2_loss: 1.7216e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0087e-04 - activation_1_loss: 1.1295e-05 - activation_2_loss: 1.8958e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.4970e-04 - val_activation_1_loss: 4.5228e-06 - val_activation_2_loss: 5.4518e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2965e-04 - activation_1_loss: 1.0322e-05 - activation_2_loss: 2.1932e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3500e-04 - val_activation_1_loss: 4.0264e-06 - val_activation_2_loss: 1.3097e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5121e-04 - activation_1_loss: 1.6508e-05 - activation_2_loss: 1.3470e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2935e-04 - val_activation_1_loss: 4.9248e-06 - val_activation_2_loss: 1.2442e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4296e-05 - activation_1_loss: 6.6473e-06 - activation_2_loss: 7.7648e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.5837e-05 - val_activation_1_loss: 1.0510e-05 - val_activation_2_loss: 4.5327e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0407e-04 - activation_1_loss: 2.4828e-05 - activation_2_loss: 2.7924e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.3467e-04 - val_activation_1_loss: 1.1110e-05 - val_activation_2_loss: 2.2356e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4778e-04 - activation_1_loss: 1.4837e-05 - activation_2_loss: 2.3294e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4295e-04 - val_activation_1_loss: 4.9597e-06 - val_activation_2_loss: 1.3799e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4639e-04 - activation_1_loss: 9.8795e-06 - activation_2_loss: 1.3651e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.2292e-05 - val_activation_1_loss: 5.1403e-06 - val_activation_2_loss: 6.7152e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2555e-05 - activation_1_loss: 4.2496e-06 - activation_2_loss: 4.8305e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3399e-05 - val_activation_1_loss: 4.5876e-06 - val_activation_2_loss: 1.8811e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.5322e-05 - activation_1_loss: 5.0021e-06 - activation_2_loss: 5.0320e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1921e-05 - val_activation_1_loss: 2.1601e-06 - val_activation_2_loss: 6.9761e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5332e-05 - activation_1_loss: 5.6954e-06 - activation_2_loss: 7.9636e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4298e-04 - val_activation_1_loss: 4.8799e-06 - val_activation_2_loss: 2.3810e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.0979e-05 - activation_1_loss: 7.0255e-06 - activation_2_loss: 8.3953e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1793e-04 - val_activation_1_loss: 3.5735e-06 - val_activation_2_loss: 1.1436e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.9037e-05 - activation_1_loss: 8.5605e-06 - activation_2_loss: 9.0476e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.3999e-04 - val_activation_1_loss: 2.7157e-06 - val_activation_2_loss: 6.3728e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1437e-04 - activation_1_loss: 1.6264e-05 - activation_2_loss: 9.8105e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7369e-04 - val_activation_1_loss: 3.2471e-05 - val_activation_2_loss: 1.4122e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5445e-04 - activation_1_loss: 5.0741e-05 - activation_2_loss: 1.0371e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1306e-04 - val_activation_1_loss: 9.7029e-06 - val_activation_2_loss: 1.0335e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4022e-04 - activation_1_loss: 9.0522e-06 - activation_2_loss: 1.3116e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.2374e-04 - val_activation_1_loss: 5.9177e-06 - val_activation_2_loss: 7.1782e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2413e-05 - activation_1_loss: 4.2041e-06 - activation_2_loss: 4.8209e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8834e-05 - val_activation_1_loss: 2.2222e-06 - val_activation_2_loss: 4.6611e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3294e-04 - activation_1_loss: 5.8179e-05 - activation_2_loss: 2.7476e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9129e-04 - val_activation_1_loss: 5.8154e-06 - val_activation_2_loss: 2.8547e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4874e-04 - activation_1_loss: 9.0866e-06 - activation_2_loss: 1.3966e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.5062e-05 - val_activation_1_loss: 1.6412e-05 - val_activation_2_loss: 7.8650e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6787e-04 - activation_1_loss: 1.6472e-05 - activation_2_loss: 2.5140e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7491e-04 - val_activation_1_loss: 6.8142e-06 - val_activation_2_loss: 1.6809e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5183e-04 - activation_1_loss: 1.2713e-05 - activation_2_loss: 1.3912e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.8467e-05 - val_activation_1_loss: 5.7189e-06 - val_activation_2_loss: 3.2748e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5103e-04 - activation_1_loss: 1.6363e-04 - activation_2_loss: 8.7395e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4005e-04 - val_activation_1_loss: 1.7262e-05 - val_activation_2_loss: 3.2279e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4762e-04 - activation_1_loss: 1.1232e-04 - activation_2_loss: 1.3530e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3347e-04 - val_activation_1_loss: 1.2084e-05 - val_activation_2_loss: 1.2138e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6863e-04 - activation_1_loss: 1.5500e-05 - activation_2_loss: 1.5313e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9711e-05 - val_activation_1_loss: 8.4942e-06 - val_activation_2_loss: 7.1216e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7361e-04 - activation_1_loss: 6.4516e-05 - activation_2_loss: 2.0909e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9861e-05 - val_activation_1_loss: 9.0596e-06 - val_activation_2_loss: 7.0802e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.9618e-05 - activation_1_loss: 1.3114e-05 - activation_2_loss: 8.6505e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2341e-05 - val_activation_1_loss: 5.3319e-06 - val_activation_2_loss: 2.7009e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8172e-04 - activation_1_loss: 5.1339e-06 - activation_2_loss: 2.7659e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6748e-05 - val_activation_1_loss: 5.6786e-06 - val_activation_2_loss: 3.1069e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8163e-04 - activation_1_loss: 3.2434e-05 - activation_2_loss: 1.4919e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1984e-05 - val_activation_1_loss: 2.3756e-05 - val_activation_2_loss: 2.8228e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6191e-04 - activation_1_loss: 7.2543e-06 - activation_2_loss: 1.5466e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.5494e-05 - val_activation_1_loss: 4.3204e-06 - val_activation_2_loss: 6.1174e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3034e-04 - activation_1_loss: 2.6941e-05 - activation_2_loss: 1.0339e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.6258e-05 - val_activation_1_loss: 2.6333e-06 - val_activation_2_loss: 9.3625e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5355e-04 - activation_1_loss: 7.0934e-06 - activation_2_loss: 1.4646e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0603e-05 - val_activation_1_loss: 8.9938e-06 - val_activation_2_loss: 3.1609e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2797e-04 - activation_1_loss: 3.3462e-06 - activation_2_loss: 1.2463e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5051e-05 - val_activation_1_loss: 3.6835e-06 - val_activation_2_loss: 2.1368e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4359e-05 - activation_1_loss: 2.8351e-06 - activation_2_loss: 6.1524e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3748e-04 - val_activation_1_loss: 9.8483e-06 - val_activation_2_loss: 1.2763e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8557e-05 - activation_1_loss: 3.3000e-06 - activation_2_loss: 7.5257e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6664e-04 - val_activation_1_loss: 2.3515e-06 - val_activation_2_loss: 1.6429e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4614e-04 - activation_1_loss: 1.3045e-05 - activation_2_loss: 1.3310e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3552e-04 - val_activation_1_loss: 1.0244e-05 - val_activation_2_loss: 4.2527e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2008e-04 - activation_1_loss: 2.6954e-05 - activation_2_loss: 3.9313e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6081e-04 - val_activation_1_loss: 4.7520e-06 - val_activation_2_loss: 1.5606e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0478e-04 - activation_1_loss: 2.5033e-05 - activation_2_loss: 1.7975e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5435e-04 - val_activation_1_loss: 1.7590e-05 - val_activation_2_loss: 1.3676e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0819e-04 - activation_1_loss: 4.9477e-05 - activation_2_loss: 1.5872e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9074e-04 - val_activation_1_loss: 5.6889e-05 - val_activation_2_loss: 1.3385e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2911e-04 - activation_1_loss: 2.4343e-05 - activation_2_loss: 3.0476e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.1439e-05 - val_activation_1_loss: 1.2987e-05 - val_activation_2_loss: 6.8452e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1087e-04 - activation_1_loss: 4.6948e-05 - activation_2_loss: 6.3922e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.5886e-05 - val_activation_1_loss: 3.2617e-06 - val_activation_2_loss: 9.2624e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5251e-05 - activation_1_loss: 4.0902e-06 - activation_2_loss: 1.1161e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.6883e-05 - val_activation_1_loss: 2.2410e-06 - val_activation_2_loss: 6.4642e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5351e-04 - activation_1_loss: 8.2573e-06 - activation_2_loss: 1.4525e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3100e-05 - val_activation_1_loss: 7.1377e-06 - val_activation_2_loss: 2.5962e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.2237e-05 - activation_1_loss: 5.6424e-06 - activation_2_loss: 5.6595e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1985e-05 - val_activation_1_loss: 3.3100e-06 - val_activation_2_loss: 4.8675e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1458e-04 - activation_1_loss: 5.3786e-06 - activation_2_loss: 1.0920e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1803e-04 - val_activation_1_loss: 6.8772e-06 - val_activation_2_loss: 1.1115e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9040e-05 - activation_1_loss: 5.2465e-06 - activation_2_loss: 8.3793e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9212e-05 - val_activation_1_loss: 3.0135e-05 - val_activation_2_loss: 6.9077e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.0131e-05 - activation_1_loss: 3.8955e-06 - activation_2_loss: 6.6236e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1372e-05 - val_activation_1_loss: 2.4744e-06 - val_activation_2_loss: 8.8974e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4654e-05 - activation_1_loss: 3.1655e-06 - activation_2_loss: 6.1488e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.2145e-05 - val_activation_1_loss: 5.2331e-06 - val_activation_2_loss: 7.6912e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1148e-05 - activation_1_loss: 2.9835e-06 - activation_2_loss: 1.8164e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8222e-04 - val_activation_1_loss: 2.0891e-06 - val_activation_2_loss: 2.8013e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8377e-04 - activation_1_loss: 3.3533e-05 - activation_2_loss: 1.5024e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3431e-04 - val_activation_1_loss: 9.8052e-06 - val_activation_2_loss: 1.2451e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1360e-04 - activation_1_loss: 4.6642e-06 - activation_2_loss: 2.0893e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1223e-04 - val_activation_1_loss: 3.6933e-05 - val_activation_2_loss: 1.7530e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0422e-04 - activation_1_loss: 6.9500e-06 - activation_2_loss: 2.9727e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.9177e-04 - val_activation_1_loss: 4.0268e-04 - val_activation_2_loss: 1.8908e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6455e-04 - activation_1_loss: 2.0114e-05 - activation_2_loss: 3.4443e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.8936e-05 - val_activation_1_loss: 5.9250e-06 - val_activation_2_loss: 7.3011e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8985e-04 - activation_1_loss: 2.6354e-05 - activation_2_loss: 1.6349e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.0651e-05 - val_activation_1_loss: 9.3144e-06 - val_activation_2_loss: 7.1337e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0011 - activation_1_loss: 5.7866e-04 - activation_2_loss: 5.1707e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 9.4303e-04 - val_activation_1_loss: 1.3863e-04 - val_activation_2_loss: 8.0440e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2871e-04 - activation_1_loss: 8.2360e-05 - activation_2_loss: 3.4635e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.6434e-05 - val_activation_1_loss: 1.0524e-05 - val_activation_2_loss: 7.5910e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2862e-04 - activation_1_loss: 1.1190e-05 - activation_2_loss: 1.1743e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5387e-04 - val_activation_1_loss: 4.7766e-06 - val_activation_2_loss: 3.4909e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7376e-05 - activation_1_loss: 6.7871e-06 - activation_2_loss: 6.0589e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0416e-04 - val_activation_1_loss: 1.3718e-05 - val_activation_2_loss: 3.9044e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.1726e-05 - activation_1_loss: 4.6455e-06 - activation_2_loss: 4.7081e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0482e-05 - val_activation_1_loss: 9.8261e-06 - val_activation_2_loss: 3.0656e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0691e-04 - activation_1_loss: 7.8541e-06 - activation_2_loss: 9.9059e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4556e-04 - val_activation_1_loss: 2.0070e-06 - val_activation_2_loss: 1.4355e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1648e-04 - activation_1_loss: 5.9372e-06 - activation_2_loss: 1.1054e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7509e-04 - val_activation_1_loss: 1.3101e-05 - val_activation_2_loss: 2.6199e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1184e-04 - activation_1_loss: 1.8101e-04 - activation_2_loss: 1.3083e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8599e-04 - val_activation_1_loss: 2.9272e-05 - val_activation_2_loss: 1.5672e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5364e-04 - activation_1_loss: 1.2452e-05 - activation_2_loss: 2.4119e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7769e-04 - val_activation_1_loss: 5.8253e-05 - val_activation_2_loss: 1.1943e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0364e-04 - activation_1_loss: 5.0322e-05 - activation_2_loss: 2.5331e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5587e-04 - val_activation_1_loss: 7.0591e-05 - val_activation_2_loss: 1.8528e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1797e-04 - activation_1_loss: 6.8087e-06 - activation_2_loss: 1.1116e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3669e-04 - val_activation_1_loss: 2.5542e-04 - val_activation_2_loss: 8.1265e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3101e-04 - activation_1_loss: 3.2616e-05 - activation_2_loss: 9.8397e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4840e-04 - val_activation_1_loss: 3.5645e-06 - val_activation_2_loss: 1.4484e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8135e-04 - activation_1_loss: 3.2549e-05 - activation_2_loss: 1.4880e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2938e-04 - val_activation_1_loss: 2.6064e-06 - val_activation_2_loss: 1.2677e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.0602e-04 - activation_1_loss: 2.7512e-04 - activation_2_loss: 3.3090e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7428e-04 - val_activation_1_loss: 2.6140e-05 - val_activation_2_loss: 1.4814e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7759e-04 - activation_1_loss: 1.8270e-05 - activation_2_loss: 1.5932e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8230e-04 - val_activation_1_loss: 2.4364e-05 - val_activation_2_loss: 3.5794e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2823e-04 - activation_1_loss: 5.2310e-06 - activation_2_loss: 1.2300e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9977e-04 - val_activation_1_loss: 5.7849e-04 - val_activation_2_loss: 2.1279e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8550e-04 - activation_1_loss: 6.4340e-06 - activation_2_loss: 1.7907e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7807e-04 - val_activation_1_loss: 9.3333e-06 - val_activation_2_loss: 1.6874e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5192e-05 - activation_1_loss: 4.6649e-06 - activation_2_loss: 8.0527e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.9505e-05 - val_activation_1_loss: 2.0825e-05 - val_activation_2_loss: 4.8680e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5166e-04 - activation_1_loss: 7.7423e-06 - activation_2_loss: 1.4392e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0032e-05 - val_activation_1_loss: 1.7105e-06 - val_activation_2_loss: 2.8321e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9236e-04 - activation_1_loss: 3.6323e-06 - activation_2_loss: 1.8873e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7227e-04 - val_activation_1_loss: 2.0988e-06 - val_activation_2_loss: 1.7017e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1551e-04 - activation_1_loss: 6.5947e-06 - activation_2_loss: 2.0892e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.6764e-05 - val_activation_1_loss: 2.6148e-06 - val_activation_2_loss: 4.4149e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0455e-04 - activation_1_loss: 4.1164e-06 - activation_2_loss: 1.0043e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1379e-04 - val_activation_1_loss: 8.2185e-06 - val_activation_2_loss: 2.0557e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7198e-05 - activation_1_loss: 6.0973e-06 - activation_2_loss: 6.1100e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4023e-05 - val_activation_1_loss: 1.9119e-06 - val_activation_2_loss: 1.2112e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5837e-05 - activation_1_loss: 3.6148e-06 - activation_2_loss: 9.2222e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0597e-05 - val_activation_1_loss: 3.4193e-06 - val_activation_2_loss: 1.7178e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7983e-04 - activation_1_loss: 1.8804e-05 - activation_2_loss: 1.6102e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1187e-04 - val_activation_1_loss: 5.9829e-06 - val_activation_2_loss: 1.0589e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2455e-04 - activation_1_loss: 6.0115e-06 - activation_2_loss: 1.1854e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.8798e-05 - val_activation_1_loss: 9.5167e-06 - val_activation_2_loss: 4.9281e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1402e-04 - activation_1_loss: 6.0609e-05 - activation_2_loss: 1.5341e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1284e-04 - val_activation_1_loss: 1.3423e-04 - val_activation_2_loss: 1.7861e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.7394e-04 - activation_1_loss: 1.3655e-04 - activation_2_loss: 3.3739e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7948e-04 - val_activation_1_loss: 4.8287e-05 - val_activation_2_loss: 1.3120e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8828e-04 - activation_1_loss: 1.7023e-05 - activation_2_loss: 1.7126e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1344e-04 - val_activation_1_loss: 8.6396e-06 - val_activation_2_loss: 1.0480e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7716e-05 - activation_1_loss: 1.2102e-05 - activation_2_loss: 5.5614e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9136e-05 - val_activation_1_loss: 2.9792e-06 - val_activation_2_loss: 1.6157e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3583e-04 - activation_1_loss: 2.5762e-05 - activation_2_loss: 1.1007e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0792e-05 - val_activation_1_loss: 6.3594e-06 - val_activation_2_loss: 2.4432e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6008e-04 - activation_1_loss: 1.5475e-05 - activation_2_loss: 1.4460e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9381e-05 - val_activation_1_loss: 1.1051e-05 - val_activation_2_loss: 4.8331e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7791e-05 - activation_1_loss: 3.8120e-06 - activation_2_loss: 2.3979e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.0932e-05 - val_activation_1_loss: 3.6514e-06 - val_activation_2_loss: 4.7281e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4072e-04 - activation_1_loss: 2.7723e-05 - activation_2_loss: 1.1299e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.8358e-05 - val_activation_1_loss: 1.1620e-05 - val_activation_2_loss: 8.6737e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9366e-05 - activation_1_loss: 2.1822e-06 - activation_2_loss: 8.7184e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7750e-05 - val_activation_1_loss: 3.1161e-06 - val_activation_2_loss: 1.4634e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9738e-04 - activation_1_loss: 6.1298e-06 - activation_2_loss: 1.9125e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3150e-04 - val_activation_1_loss: 1.9796e-05 - val_activation_2_loss: 2.1171e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.7860e-04 - activation_1_loss: 2.1885e-04 - activation_2_loss: 2.5975e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.8022e-05 - val_activation_1_loss: 5.7580e-06 - val_activation_2_loss: 4.2264e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0177e-04 - activation_1_loss: 2.0244e-05 - activation_2_loss: 8.1528e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.1542e-04 - val_activation_1_loss: 4.8520e-05 - val_activation_2_loss: 5.6689e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6564e-04 - activation_1_loss: 7.2764e-06 - activation_2_loss: 1.5836e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2155e-04 - val_activation_1_loss: 1.9544e-05 - val_activation_2_loss: 1.0201e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0864e-05 - activation_1_loss: 1.0101e-05 - activation_2_loss: 4.0763e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.8379e-05 - val_activation_1_loss: 1.6760e-05 - val_activation_2_loss: 7.1619e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1969e-04 - activation_1_loss: 3.9428e-06 - activation_2_loss: 1.1575e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4893e-05 - val_activation_1_loss: 3.0457e-06 - val_activation_2_loss: 9.1848e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0747e-04 - activation_1_loss: 2.8714e-06 - activation_2_loss: 1.0460e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1534e-04 - val_activation_1_loss: 8.4661e-06 - val_activation_2_loss: 4.0687e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 1.2758e-04 - activation_1_loss: 3.1874e-05 - activation_2_loss: 9.5711e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4652e-05 - val_activation_1_loss: 2.7351e-06 - val_activation_2_loss: 6.1917e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5752e-04 - activation_1_loss: 9.3109e-06 - activation_2_loss: 1.4821e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8015e-04 - val_activation_1_loss: 2.0851e-06 - val_activation_2_loss: 1.7807e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8145e-05 - activation_1_loss: 2.2467e-06 - activation_2_loss: 4.5898e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4060e-04 - val_activation_1_loss: 1.0156e-05 - val_activation_2_loss: 4.3045e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8092e-05 - activation_1_loss: 2.9142e-06 - activation_2_loss: 3.5178e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3255e-05 - val_activation_1_loss: 4.5054e-06 - val_activation_2_loss: 8.7493e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9460e-05 - activation_1_loss: 2.0861e-05 - activation_2_loss: 4.8600e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8408e-05 - val_activation_1_loss: 2.7949e-06 - val_activation_2_loss: 4.5613e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4713e-05 - activation_1_loss: 4.1525e-06 - activation_2_loss: 6.0560e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3619e-04 - val_activation_1_loss: 9.0046e-06 - val_activation_2_loss: 2.2719e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4068e-04 - activation_1_loss: 6.7245e-06 - activation_2_loss: 2.3396e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.2182e-04 - val_activation_1_loss: 1.4805e-04 - val_activation_2_loss: 5.7377e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2819e-04 - activation_1_loss: 8.2151e-05 - activation_2_loss: 1.4604e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1550e-04 - val_activation_1_loss: 1.2393e-05 - val_activation_2_loss: 7.0311e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4037e-04 - activation_1_loss: 3.0583e-05 - activation_2_loss: 3.0979e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0499e-04 - val_activation_1_loss: 4.6776e-05 - val_activation_2_loss: 4.5821e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0771e-04 - activation_1_loss: 1.1746e-04 - activation_2_loss: 3.9025e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.5771e-04 - val_activation_1_loss: 1.0916e-05 - val_activation_2_loss: 4.4679e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9044e-04 - activation_1_loss: 1.7371e-05 - activation_2_loss: 2.7307e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.7674e-04 - val_activation_1_loss: 4.2388e-05 - val_activation_2_loss: 4.3435e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4831e-04 - activation_1_loss: 1.5282e-05 - activation_2_loss: 1.3303e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0465e-04 - val_activation_1_loss: 2.2703e-05 - val_activation_2_loss: 8.1943e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.6775e-04 - activation_1_loss: 1.0989e-04 - activation_2_loss: 3.5786e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.5574e-05 - val_activation_1_loss: 1.0411e-05 - val_activation_2_loss: 8.5163e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0571e-04 - activation_1_loss: 1.8024e-05 - activation_2_loss: 8.7689e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4665e-04 - val_activation_1_loss: 5.5299e-06 - val_activation_2_loss: 1.4112e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1256e-04 - activation_1_loss: 1.0788e-05 - activation_2_loss: 1.0177e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3113e-04 - val_activation_1_loss: 3.2239e-06 - val_activation_2_loss: 1.2791e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3901e-05 - activation_1_loss: 4.6031e-06 - activation_2_loss: 3.9298e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6447e-04 - val_activation_1_loss: 1.3517e-05 - val_activation_2_loss: 1.5095e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1386e-04 - activation_1_loss: 1.5806e-05 - activation_2_loss: 9.8056e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7586e-05 - val_activation_1_loss: 2.3170e-06 - val_activation_2_loss: 1.5269e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1586e-05 - activation_1_loss: 5.8248e-06 - activation_2_loss: 5.5762e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9842e-05 - val_activation_1_loss: 4.3762e-06 - val_activation_2_loss: 2.5466e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2166e-04 - activation_1_loss: 9.8752e-06 - activation_2_loss: 1.1178e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2382e-05 - val_activation_1_loss: 1.5715e-05 - val_activation_2_loss: 3.6667e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4659e-04 - activation_1_loss: 1.7115e-04 - activation_2_loss: 7.5441e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.0317e-05 - val_activation_1_loss: 1.9498e-05 - val_activation_2_loss: 7.0820e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2679e-04 - activation_1_loss: 7.5966e-05 - activation_2_loss: 1.5082e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3200e-04 - val_activation_1_loss: 1.3980e-04 - val_activation_2_loss: 2.9221e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3658e-04 - activation_1_loss: 2.0798e-04 - activation_2_loss: 3.2860e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0749e-04 - val_activation_1_loss: 3.4178e-05 - val_activation_2_loss: 7.3313e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2602e-04 - activation_1_loss: 1.2145e-05 - activation_2_loss: 1.1388e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4655e-05 - val_activation_1_loss: 2.9801e-06 - val_activation_2_loss: 5.1675e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.9075e-05 - activation_1_loss: 1.1112e-05 - activation_2_loss: 4.7963e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3577e-04 - val_activation_1_loss: 3.5512e-06 - val_activation_2_loss: 2.3222e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4680e-04 - activation_1_loss: 4.8252e-06 - activation_2_loss: 1.4198e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6343e-05 - val_activation_1_loss: 5.0178e-06 - val_activation_2_loss: 2.1326e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0585e-04 - activation_1_loss: 6.9044e-06 - activation_2_loss: 9.8948e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6981e-04 - val_activation_1_loss: 4.0975e-05 - val_activation_2_loss: 1.2883e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2338e-04 - activation_1_loss: 9.1205e-06 - activation_2_loss: 2.1426e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4091e-05 - val_activation_1_loss: 7.8731e-06 - val_activation_2_loss: 2.6218e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8652e-04 - activation_1_loss: 2.2455e-05 - activation_2_loss: 1.6406e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8878e-04 - val_activation_1_loss: 4.2531e-06 - val_activation_2_loss: 4.8453e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1422e-04 - activation_1_loss: 9.5472e-05 - activation_2_loss: 1.1875e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1520e-04 - val_activation_1_loss: 6.7653e-05 - val_activation_2_loss: 2.4755e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8671e-05 - activation_1_loss: 9.9554e-06 - activation_2_loss: 5.8716e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6323e-05 - val_activation_1_loss: 2.7017e-06 - val_activation_2_loss: 3.3621e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3441e-04 - activation_1_loss: 7.1421e-06 - activation_2_loss: 1.2727e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6992e-05 - val_activation_1_loss: 7.6538e-06 - val_activation_2_loss: 9.3385e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.9543e-05 - activation_1_loss: 5.2170e-06 - activation_2_loss: 9.4326e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2344e-04 - val_activation_1_loss: 4.0080e-04 - val_activation_2_loss: 2.2633e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1846e-05 - activation_1_loss: 2.2942e-05 - activation_2_loss: 3.8905e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0353e-04 - val_activation_1_loss: 9.8435e-06 - val_activation_2_loss: 1.9369e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4657e-05 - activation_1_loss: 5.6778e-06 - activation_2_loss: 1.8979e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.3070e-06 - val_activation_1_loss: 3.3867e-06 - val_activation_2_loss: 2.9204e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2879e-04 - activation_1_loss: 1.0962e-05 - activation_2_loss: 3.1783e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.3054e-04 - val_activation_1_loss: 2.1814e-04 - val_activation_2_loss: 2.1240e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3407e-04 - activation_1_loss: 2.1509e-05 - activation_2_loss: 3.1256e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5233e-04 - val_activation_1_loss: 1.6226e-05 - val_activation_2_loss: 2.3610e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7265e-05 - activation_1_loss: 1.6995e-05 - activation_2_loss: 7.0271e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.4081e-05 - val_activation_1_loss: 5.2360e-06 - val_activation_2_loss: 7.8845e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9057e-04 - activation_1_loss: 1.7327e-05 - activation_2_loss: 1.7325e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7135e-04 - val_activation_1_loss: 5.3177e-06 - val_activation_2_loss: 1.6603e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8423e-05 - activation_1_loss: 1.4809e-05 - activation_2_loss: 5.3614e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5273e-04 - val_activation_1_loss: 2.5670e-04 - val_activation_2_loss: 9.6029e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6575e-04 - activation_1_loss: 6.5346e-05 - activation_2_loss: 2.0041e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8706e-04 - val_activation_1_loss: 2.1075e-04 - val_activation_2_loss: 2.7631e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5596e-04 - activation_1_loss: 1.4179e-04 - activation_2_loss: 3.1417e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.4373e-05 - val_activation_1_loss: 4.7584e-06 - val_activation_2_loss: 6.9614e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4002e-04 - activation_1_loss: 1.3417e-05 - activation_2_loss: 1.2661e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.0362e-05 - val_activation_1_loss: 4.0357e-06 - val_activation_2_loss: 6.6327e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7948e-04 - activation_1_loss: 4.3262e-06 - activation_2_loss: 1.7516e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1746e-05 - val_activation_1_loss: 2.5975e-05 - val_activation_2_loss: 4.5771e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0318e-05 - activation_1_loss: 1.1266e-05 - activation_2_loss: 6.9052e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1232e-05 - val_activation_1_loss: 3.9280e-06 - val_activation_2_loss: 4.7304e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6904e-05 - activation_1_loss: 2.1455e-05 - activation_2_loss: 1.5449e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0459e-05 - val_activation_1_loss: 4.4455e-06 - val_activation_2_loss: 2.6014e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.6398e-05 - activation_1_loss: 8.5890e-06 - activation_2_loss: 3.7809e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4002e-05 - val_activation_1_loss: 3.1541e-06 - val_activation_2_loss: 5.0848e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4916e-05 - activation_1_loss: 5.5846e-06 - activation_2_loss: 4.9331e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9654e-06 - val_activation_1_loss: 2.5277e-06 - val_activation_2_loss: 6.4378e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9947e-04 - activation_1_loss: 4.4278e-06 - activation_2_loss: 1.9504e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.5881e-05 - val_activation_1_loss: 3.2201e-06 - val_activation_2_loss: 5.2661e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2027e-04 - activation_1_loss: 6.5360e-06 - activation_2_loss: 1.1374e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3688e-04 - val_activation_1_loss: 2.7097e-05 - val_activation_2_loss: 3.0978e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9565e-04 - activation_1_loss: 1.0435e-05 - activation_2_loss: 1.8521e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.6990e-05 - val_activation_1_loss: 4.9162e-06 - val_activation_2_loss: 9.2073e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9056e-04 - activation_1_loss: 1.5514e-05 - activation_2_loss: 1.7504e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.3427e-05 - val_activation_1_loss: 3.2682e-06 - val_activation_2_loss: 8.0159e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0696e-04 - activation_1_loss: 2.0243e-05 - activation_2_loss: 8.6721e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3935e-04 - val_activation_1_loss: 7.0109e-05 - val_activation_2_loss: 6.9241e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8816e-05 - activation_1_loss: 2.6644e-06 - activation_2_loss: 2.6151e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2962e-04 - val_activation_1_loss: 1.9883e-06 - val_activation_2_loss: 1.2763e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0010e-04 - activation_1_loss: 2.0822e-06 - activation_2_loss: 9.8017e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3155e-04 - val_activation_1_loss: 3.3097e-06 - val_activation_2_loss: 1.2824e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.0861e-04 - activation_1_loss: 3.2228e-04 - activation_2_loss: 8.6323e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2313e-04 - val_activation_1_loss: 5.7292e-05 - val_activation_2_loss: 6.5837e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0492e-04 - activation_1_loss: 1.2156e-04 - activation_2_loss: 1.8336e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4531e-04 - val_activation_1_loss: 3.0969e-05 - val_activation_2_loss: 3.1434e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.8395e-05 - activation_1_loss: 2.4398e-05 - activation_2_loss: 7.3997e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5535e-05 - val_activation_1_loss: 1.8086e-05 - val_activation_2_loss: 2.7448e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3862e-04 - activation_1_loss: 8.0082e-06 - activation_2_loss: 1.3061e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7266e-05 - val_activation_1_loss: 7.5528e-06 - val_activation_2_loss: 5.9713e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.2076e-05 - activation_1_loss: 3.0504e-05 - activation_2_loss: 6.1572e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6334e-05 - val_activation_1_loss: 2.9374e-06 - val_activation_2_loss: 3.3396e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2891e-04 - activation_1_loss: 1.1275e-05 - activation_2_loss: 1.1763e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2752e-04 - val_activation_1_loss: 8.9459e-06 - val_activation_2_loss: 1.1858e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3053e-04 - activation_1_loss: 3.6365e-05 - activation_2_loss: 1.9416e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.5386e-04 - val_activation_1_loss: 6.1296e-05 - val_activation_2_loss: 1.9256e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1638e-04 - activation_1_loss: 4.1391e-06 - activation_2_loss: 1.1224e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.5734e-05 - val_activation_1_loss: 5.4418e-06 - val_activation_2_loss: 5.0292e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.6622e-05 - activation_1_loss: 8.9900e-06 - activation_2_loss: 6.7632e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4857e-05 - val_activation_1_loss: 5.8862e-06 - val_activation_2_loss: 4.8970e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8380e-05 - activation_1_loss: 4.6485e-06 - activation_2_loss: 4.3731e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.7686e-05 - val_activation_1_loss: 1.5455e-05 - val_activation_2_loss: 3.2231e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4678e-04 - activation_1_loss: 2.7337e-06 - activation_2_loss: 1.4404e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9448e-05 - val_activation_1_loss: 1.8662e-05 - val_activation_2_loss: 4.0786e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3120e-04 - activation_1_loss: 6.4823e-06 - activation_2_loss: 1.2472e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1180e-04 - val_activation_1_loss: 1.4162e-05 - val_activation_2_loss: 3.9764e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1797e-04 - activation_1_loss: 1.2081e-05 - activation_2_loss: 1.0589e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8183e-04 - val_activation_1_loss: 7.6714e-05 - val_activation_2_loss: 1.0512e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5362e-05 - activation_1_loss: 1.6571e-05 - activation_2_loss: 7.8790e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4920e-05 - val_activation_1_loss: 1.1376e-05 - val_activation_2_loss: 5.3544e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6638e-04 - activation_1_loss: 5.0965e-05 - activation_2_loss: 1.1542e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8918e-05 - val_activation_1_loss: 4.4544e-06 - val_activation_2_loss: 7.4464e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.4024e-05 - activation_1_loss: 1.5033e-05 - activation_2_loss: 7.8992e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1554e-05 - val_activation_1_loss: 6.3783e-06 - val_activation_2_loss: 3.5176e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2312e-05 - activation_1_loss: 8.4946e-06 - activation_2_loss: 6.3818e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8799e-05 - val_activation_1_loss: 2.2297e-06 - val_activation_2_loss: 7.6570e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2525e-04 - activation_1_loss: 3.2720e-05 - activation_2_loss: 1.9253e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5903e-04 - val_activation_1_loss: 1.4272e-04 - val_activation_2_loss: 2.1631e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2713e-04 - activation_1_loss: 4.4528e-06 - activation_2_loss: 1.2268e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8839e-04 - val_activation_1_loss: 3.7157e-06 - val_activation_2_loss: 2.8468e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3080e-04 - activation_1_loss: 8.2806e-06 - activation_2_loss: 2.2252e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9093e-05 - val_activation_1_loss: 2.1813e-06 - val_activation_2_loss: 2.6912e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8088e-04 - activation_1_loss: 2.4380e-05 - activation_2_loss: 2.5650e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7405e-04 - val_activation_1_loss: 5.0368e-06 - val_activation_2_loss: 1.6902e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6056e-04 - activation_1_loss: 1.0542e-05 - activation_2_loss: 1.5002e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5897e-05 - val_activation_1_loss: 3.6366e-06 - val_activation_2_loss: 3.2261e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7003e-04 - activation_1_loss: 8.5643e-06 - activation_2_loss: 1.6147e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4176e-04 - val_activation_1_loss: 5.3098e-05 - val_activation_2_loss: 3.8866e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6484e-05 - activation_1_loss: 1.1199e-05 - activation_2_loss: 5.5285e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3122e-04 - val_activation_1_loss: 3.3214e-06 - val_activation_2_loss: 3.2789e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.3839e-05 - activation_1_loss: 1.5193e-05 - activation_2_loss: 6.8646e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1370e-05 - val_activation_1_loss: 1.8945e-06 - val_activation_2_loss: 9.4753e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.4165e-05 - activation_1_loss: 3.1560e-06 - activation_2_loss: 7.1009e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7243e-05 - val_activation_1_loss: 2.8969e-06 - val_activation_2_loss: 6.4346e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.7611e-05 - activation_1_loss: 2.4335e-06 - activation_2_loss: 4.5178e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6147e-05 - val_activation_1_loss: 4.0216e-06 - val_activation_2_loss: 1.2126e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.7120e-05 - activation_1_loss: 6.6010e-06 - activation_2_loss: 5.0519e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7435e-05 - val_activation_1_loss: 3.0419e-06 - val_activation_2_loss: 5.4393e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8490e-05 - activation_1_loss: 5.8559e-06 - activation_2_loss: 3.2634e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1860e-05 - val_activation_1_loss: 2.1299e-06 - val_activation_2_loss: 2.9730e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5399e-04 - activation_1_loss: 6.3552e-05 - activation_2_loss: 1.9043e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3070e-04 - val_activation_1_loss: 5.2146e-04 - val_activation_2_loss: 2.0924e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4227e-04 - activation_1_loss: 2.3006e-04 - activation_2_loss: 4.1220e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6013e-04 - val_activation_1_loss: 3.0076e-06 - val_activation_2_loss: 2.5712e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3102e-04 - activation_1_loss: 2.2526e-05 - activation_2_loss: 1.0850e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4934e-05 - val_activation_1_loss: 3.1920e-06 - val_activation_2_loss: 6.1742e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0034e-04 - activation_1_loss: 1.4980e-05 - activation_2_loss: 1.8536e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4495e-04 - val_activation_1_loss: 3.8946e-06 - val_activation_2_loss: 1.4106e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2164e-04 - activation_1_loss: 3.6166e-06 - activation_2_loss: 1.1803e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3779e-04 - val_activation_1_loss: 9.4001e-05 - val_activation_2_loss: 4.3792e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2023e-04 - activation_1_loss: 2.6355e-06 - activation_2_loss: 1.1760e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2014e-04 - val_activation_1_loss: 1.4141e-04 - val_activation_2_loss: 3.7874e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5000e-05 - activation_1_loss: 2.9008e-06 - activation_2_loss: 4.2099e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3189e-04 - val_activation_1_loss: 4.8788e-06 - val_activation_2_loss: 1.2701e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3296e-04 - activation_1_loss: 6.6473e-06 - activation_2_loss: 1.2631e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8685e-05 - val_activation_1_loss: 3.0948e-06 - val_activation_2_loss: 1.5590e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0994e-04 - activation_1_loss: 3.8214e-06 - activation_2_loss: 1.0611e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7212e-05 - val_activation_1_loss: 1.9866e-06 - val_activation_2_loss: 1.5226e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.6423e-05 - activation_1_loss: 3.8718e-06 - activation_2_loss: 9.2551e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.0312e-05 - val_activation_1_loss: 1.6021e-06 - val_activation_2_loss: 6.8710e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3077e-05 - activation_1_loss: 5.5383e-06 - activation_2_loss: 1.7538e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6871e-05 - val_activation_1_loss: 2.9890e-06 - val_activation_2_loss: 1.3882e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2496e-05 - activation_1_loss: 2.0305e-06 - activation_2_loss: 1.0466e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6063e-05 - val_activation_1_loss: 1.1710e-06 - val_activation_2_loss: 3.4892e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1622e-04 - activation_1_loss: 3.9697e-06 - activation_2_loss: 1.1225e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4383e-04 - val_activation_1_loss: 2.8506e-05 - val_activation_2_loss: 9.1532e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8207e-04 - activation_1_loss: 1.3270e-05 - activation_2_loss: 1.6880e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1548e-04 - val_activation_1_loss: 1.3995e-05 - val_activation_2_loss: 2.0148e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2731e-04 - activation_1_loss: 1.5861e-05 - activation_2_loss: 1.1145e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4806e-04 - val_activation_1_loss: 2.2024e-05 - val_activation_2_loss: 2.2603e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7127e-04 - activation_1_loss: 7.4387e-05 - activation_2_loss: 1.9688e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.3007e-04 - val_activation_1_loss: 2.6515e-04 - val_activation_2_loss: 1.6492e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7325e-04 - activation_1_loss: 3.5371e-05 - activation_2_loss: 1.3788e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1547e-05 - val_activation_1_loss: 8.6825e-06 - val_activation_2_loss: 2.2864e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6780e-05 - activation_1_loss: 1.9226e-05 - activation_2_loss: 4.7554e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.6055e-05 - val_activation_1_loss: 2.3275e-06 - val_activation_2_loss: 6.3727e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.1109e-05 - activation_1_loss: 3.2854e-06 - activation_2_loss: 4.7823e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2133e-05 - val_activation_1_loss: 2.5995e-06 - val_activation_2_loss: 9.5332e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3845e-04 - activation_1_loss: 2.0694e-05 - activation_2_loss: 1.1776e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3899e-04 - val_activation_1_loss: 2.6620e-06 - val_activation_2_loss: 4.3633e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9778e-04 - activation_1_loss: 6.3638e-06 - activation_2_loss: 1.9141e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7684e-04 - val_activation_1_loss: 2.1081e-05 - val_activation_2_loss: 1.5576e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7634e-04 - activation_1_loss: 4.9718e-05 - activation_2_loss: 1.2662e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.8734e-05 - val_activation_1_loss: 3.4363e-06 - val_activation_2_loss: 3.5298e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.3799e-05 - activation_1_loss: 7.5276e-06 - activation_2_loss: 5.6271e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4278e-04 - val_activation_1_loss: 4.0128e-05 - val_activation_2_loss: 2.0265e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.1848e-05 - activation_1_loss: 1.0987e-05 - activation_2_loss: 7.0861e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7646e-04 - val_activation_1_loss: 5.1498e-06 - val_activation_2_loss: 1.7131e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8138e-04 - activation_1_loss: 5.6885e-06 - activation_2_loss: 1.7569e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.9761e-04 - val_activation_1_loss: 3.0576e-04 - val_activation_2_loss: 1.9185e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6333e-04 - activation_1_loss: 1.4040e-05 - activation_2_loss: 2.4929e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.1666e-05 - val_activation_1_loss: 1.2261e-05 - val_activation_2_loss: 2.9405e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9055e-04 - activation_1_loss: 3.8450e-05 - activation_2_loss: 2.5210e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1262e-04 - val_activation_1_loss: 3.4513e-05 - val_activation_2_loss: 7.8108e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.7464e-05 - activation_1_loss: 3.7419e-06 - activation_2_loss: 7.3723e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7785e-05 - val_activation_1_loss: 7.6184e-06 - val_activation_2_loss: 2.0167e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3506e-04 - activation_1_loss: 2.2614e-04 - activation_2_loss: 2.0893e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2097e-04 - val_activation_1_loss: 2.2884e-05 - val_activation_2_loss: 9.8084e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0813e-04 - activation_1_loss: 1.0118e-04 - activation_2_loss: 1.0696e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7676e-04 - val_activation_1_loss: 1.2023e-05 - val_activation_2_loss: 3.6473e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9744e-04 - activation_1_loss: 3.6064e-05 - activation_2_loss: 1.6138e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7437e-04 - val_activation_1_loss: 1.0826e-04 - val_activation_2_loss: 6.6117e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.1709e-05 - activation_1_loss: 7.5808e-06 - activation_2_loss: 6.4128e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9639e-05 - val_activation_1_loss: 4.0647e-06 - val_activation_2_loss: 2.5574e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2334e-04 - activation_1_loss: 1.6315e-04 - activation_2_loss: 3.6019e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.0289e-05 - val_activation_1_loss: 3.4200e-05 - val_activation_2_loss: 2.6089e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2121e-04 - activation_1_loss: 2.2010e-05 - activation_2_loss: 9.9196e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3903e-05 - val_activation_1_loss: 7.1607e-06 - val_activation_2_loss: 6.6742e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1087e-04 - activation_1_loss: 5.7174e-04 - activation_2_loss: 3.9133e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2527e-05 - val_activation_1_loss: 8.3057e-06 - val_activation_2_loss: 3.4221e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0522e-04 - activation_1_loss: 1.2238e-05 - activation_2_loss: 9.2978e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3998e-04 - val_activation_1_loss: 3.8945e-06 - val_activation_2_loss: 7.3608e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0792e-04 - activation_1_loss: 1.8773e-04 - activation_2_loss: 3.2019e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0015 - val_activation_1_loss: 2.7135e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9997\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3446e-04 - activation_1_loss: 8.5103e-06 - activation_2_loss: 1.2595e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3704e-04 - val_activation_1_loss: 4.0609e-05 - val_activation_2_loss: 2.9643e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0156e-04 - activation_1_loss: 1.6182e-05 - activation_2_loss: 8.5380e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2927e-05 - val_activation_1_loss: 7.5679e-06 - val_activation_2_loss: 1.5359e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1173e-04 - activation_1_loss: 1.2837e-05 - activation_2_loss: 9.8892e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.7727e-05 - val_activation_1_loss: 4.0372e-06 - val_activation_2_loss: 7.3690e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4493e-04 - activation_1_loss: 6.0765e-06 - activation_2_loss: 1.3885e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.0660e-05 - val_activation_1_loss: 2.0040e-05 - val_activation_2_loss: 3.0620e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.2848e-05 - activation_1_loss: 1.2371e-05 - activation_2_loss: 7.0477e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4678e-05 - val_activation_1_loss: 2.3457e-06 - val_activation_2_loss: 1.2332e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1216e-04 - activation_1_loss: 3.3741e-06 - activation_2_loss: 1.0878e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.3423e-05 - val_activation_1_loss: 3.0323e-06 - val_activation_2_loss: 8.0391e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.1903e-05 - activation_1_loss: 3.7130e-06 - activation_2_loss: 8.8190e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8784e-05 - val_activation_1_loss: 6.1135e-06 - val_activation_2_loss: 1.2670e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5521e-05 - activation_1_loss: 4.8458e-06 - activation_2_loss: 3.0676e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8005e-05 - val_activation_1_loss: 2.7848e-06 - val_activation_2_loss: 2.5220e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.7554e-05 - activation_1_loss: 4.3954e-06 - activation_2_loss: 5.3159e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6360e-05 - val_activation_1_loss: 2.6352e-06 - val_activation_2_loss: 2.3725e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4366e-05 - activation_1_loss: 1.0446e-05 - activation_2_loss: 7.3920e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0989e-04 - val_activation_1_loss: 8.9037e-05 - val_activation_2_loss: 2.0857e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1467e-05 - activation_1_loss: 4.7904e-06 - activation_2_loss: 6.6762e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7214e-05 - val_activation_1_loss: 3.1516e-06 - val_activation_2_loss: 1.4062e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.5386e-05 - activation_1_loss: 2.3453e-06 - activation_2_loss: 7.3041e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7148e-05 - val_activation_1_loss: 2.0473e-05 - val_activation_2_loss: 6.6742e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8136e-05 - activation_1_loss: 2.3463e-06 - activation_2_loss: 1.5790e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4891e-05 - val_activation_1_loss: 2.5681e-06 - val_activation_2_loss: 2.2322e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6841e-05 - activation_1_loss: 8.0222e-06 - activation_2_loss: 2.8818e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1024e-05 - val_activation_1_loss: 1.7517e-06 - val_activation_2_loss: 9.2726e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.4460e-05 - activation_1_loss: 3.0116e-05 - activation_2_loss: 6.4344e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6438e-04 - val_activation_1_loss: 1.1983e-05 - val_activation_2_loss: 3.5240e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2119e-04 - activation_1_loss: 4.3157e-05 - activation_2_loss: 2.7803e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.8361e-04 - val_activation_1_loss: 3.1383e-06 - val_activation_2_loss: 5.8048e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2821e-04 - activation_1_loss: 2.9433e-05 - activation_2_loss: 1.9877e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.1964e-05 - val_activation_1_loss: 6.0774e-06 - val_activation_2_loss: 6.5887e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.6188e-05 - activation_1_loss: 2.8816e-06 - activation_2_loss: 9.3306e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5533e-04 - val_activation_1_loss: 4.3035e-06 - val_activation_2_loss: 1.5103e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3423e-05 - activation_1_loss: 1.7023e-05 - activation_2_loss: 3.6399e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9763e-04 - val_activation_1_loss: 5.0265e-06 - val_activation_2_loss: 1.9260e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4160e-04 - activation_1_loss: 2.0716e-04 - activation_2_loss: 2.3443e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1956e-04 - val_activation_1_loss: 4.5266e-05 - val_activation_2_loss: 2.7429e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9517e-04 - activation_1_loss: 9.4498e-06 - activation_2_loss: 2.8572e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1019e-04 - val_activation_1_loss: 1.2000e-05 - val_activation_2_loss: 9.8190e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3507e-04 - activation_1_loss: 8.4427e-06 - activation_2_loss: 1.2662e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.5344e-04 - val_activation_1_loss: 6.6832e-04 - val_activation_2_loss: 2.8512e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1787e-04 - activation_1_loss: 9.7414e-06 - activation_2_loss: 1.0812e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1134e-04 - val_activation_1_loss: 7.4080e-05 - val_activation_2_loss: 3.7256e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9452e-05 - activation_1_loss: 2.1107e-05 - activation_2_loss: 4.8345e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2482e-05 - val_activation_1_loss: 1.0017e-05 - val_activation_2_loss: 1.2465e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.3813e-05 - activation_1_loss: 3.7908e-06 - activation_2_loss: 6.0022e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2467e-05 - val_activation_1_loss: 3.2951e-06 - val_activation_2_loss: 4.9171e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7581e-04 - activation_1_loss: 1.7211e-05 - activation_2_loss: 1.5860e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3586e-05 - val_activation_1_loss: 6.1741e-06 - val_activation_2_loss: 2.7412e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7472e-05 - activation_1_loss: 6.8928e-05 - activation_2_loss: 1.8544e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4391e-04 - val_activation_1_loss: 6.2250e-04 - val_activation_2_loss: 3.2141e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4077e-04 - activation_1_loss: 1.7021e-04 - activation_2_loss: 1.7056e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.2540e-05 - val_activation_1_loss: 1.9602e-05 - val_activation_2_loss: 6.2938e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4146e-05 - activation_1_loss: 1.1854e-05 - activation_2_loss: 7.2291e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5099e-04 - val_activation_1_loss: 1.8038e-05 - val_activation_2_loss: 1.3295e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.1955e-05 - activation_1_loss: 7.6083e-06 - activation_2_loss: 4.4347e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2254e-05 - val_activation_1_loss: 1.1813e-05 - val_activation_2_loss: 3.0441e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0603e-05 - activation_1_loss: 7.8829e-06 - activation_2_loss: 7.2721e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7103e-05 - val_activation_1_loss: 5.6331e-06 - val_activation_2_loss: 5.1470e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1339e-04 - activation_1_loss: 5.7176e-06 - activation_2_loss: 1.0767e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1636e-04 - val_activation_1_loss: 2.4918e-06 - val_activation_2_loss: 1.1386e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9145e-05 - activation_1_loss: 2.9398e-05 - activation_2_loss: 5.9747e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7251e-04 - val_activation_1_loss: 4.6652e-06 - val_activation_2_loss: 6.6784e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9958e-04 - activation_1_loss: 4.9131e-04 - activation_2_loss: 4.0827e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 2.3301e-04 - val_activation_1_loss: 2.3354e-05 - val_activation_2_loss: 2.0966e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4040e-04 - activation_1_loss: 5.9717e-05 - activation_2_loss: 1.8068e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.4060e-04 - val_activation_1_loss: 1.3105e-05 - val_activation_2_loss: 2.2749e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4219e-04 - activation_1_loss: 1.0232e-05 - activation_2_loss: 1.3196e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7668e-05 - val_activation_1_loss: 3.0625e-06 - val_activation_2_loss: 6.4606e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7251e-04 - activation_1_loss: 1.2657e-05 - activation_2_loss: 2.5985e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.3458e-05 - val_activation_1_loss: 1.9600e-06 - val_activation_2_loss: 5.1498e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3226e-04 - activation_1_loss: 1.6899e-05 - activation_2_loss: 1.1536e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1286e-04 - val_activation_1_loss: 4.4238e-06 - val_activation_2_loss: 1.0844e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5263e-05 - activation_1_loss: 4.3348e-06 - activation_2_loss: 3.0928e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0529e-04 - val_activation_1_loss: 4.2309e-05 - val_activation_2_loss: 6.2982e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3012e-04 - activation_1_loss: 4.6932e-05 - activation_2_loss: 8.3185e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0626e-04 - val_activation_1_loss: 2.2963e-06 - val_activation_2_loss: 1.0396e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0968e-04 - activation_1_loss: 6.2173e-06 - activation_2_loss: 1.0347e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8296e-05 - val_activation_1_loss: 2.2733e-06 - val_activation_2_loss: 2.6023e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7461e-05 - activation_1_loss: 8.9830e-06 - activation_2_loss: 2.8478e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3616e-05 - val_activation_1_loss: 5.3932e-06 - val_activation_2_loss: 4.8223e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7910e-05 - activation_1_loss: 6.1458e-06 - activation_2_loss: 1.1764e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0185e-05 - val_activation_1_loss: 3.0822e-06 - val_activation_2_loss: 7.1029e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3010e-05 - activation_1_loss: 1.5875e-05 - activation_2_loss: 3.7134e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.1202e-05 - val_activation_1_loss: 6.8133e-06 - val_activation_2_loss: 5.4389e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.8797e-05 - activation_1_loss: 4.8304e-06 - activation_2_loss: 9.3966e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2640e-05 - val_activation_1_loss: 8.1340e-06 - val_activation_2_loss: 4.5063e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4814e-05 - activation_1_loss: 1.3103e-05 - activation_2_loss: 5.1711e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2749e-05 - val_activation_1_loss: 2.5714e-06 - val_activation_2_loss: 2.0178e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0965e-04 - activation_1_loss: 9.5548e-06 - activation_2_loss: 1.0010e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9692e-05 - val_activation_1_loss: 1.6284e-06 - val_activation_2_loss: 3.8063e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3437e-04 - activation_1_loss: 2.4505e-05 - activation_2_loss: 1.0986e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9629e-05 - val_activation_1_loss: 5.4292e-06 - val_activation_2_loss: 1.4200e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8306e-05 - activation_1_loss: 2.0374e-06 - activation_2_loss: 6.6268e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7013e-05 - val_activation_1_loss: 6.4091e-06 - val_activation_2_loss: 6.0603e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1199e-04 - activation_1_loss: 2.2123e-06 - activation_2_loss: 1.0978e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3752e-04 - val_activation_1_loss: 2.4765e-06 - val_activation_2_loss: 1.3505e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6439e-05 - activation_1_loss: 1.6063e-05 - activation_2_loss: 5.0376e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.3730e-05 - val_activation_1_loss: 2.5905e-05 - val_activation_2_loss: 6.7826e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6429e-04 - activation_1_loss: 8.7618e-05 - activation_2_loss: 2.7667e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.4002e-04 - val_activation_1_loss: 4.7016e-06 - val_activation_2_loss: 4.3532e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.6167e-05 - activation_1_loss: 8.5071e-06 - activation_2_loss: 4.7660e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0191e-04 - val_activation_1_loss: 2.3521e-06 - val_activation_2_loss: 9.9555e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.9393e-05 - activation_1_loss: 4.3807e-06 - activation_2_loss: 9.5012e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1297e-04 - val_activation_1_loss: 2.5578e-06 - val_activation_2_loss: 1.1041e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5634e-05 - activation_1_loss: 4.7271e-06 - activation_2_loss: 6.0907e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5728e-05 - val_activation_1_loss: 2.3239e-06 - val_activation_2_loss: 1.3404e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5955e-05 - activation_1_loss: 2.8824e-06 - activation_2_loss: 6.3072e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3882e-04 - val_activation_1_loss: 3.8963e-06 - val_activation_2_loss: 1.3493e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2054e-05 - activation_1_loss: 2.5011e-06 - activation_2_loss: 6.9553e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3437e-04 - val_activation_1_loss: 4.7295e-06 - val_activation_2_loss: 2.2964e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4392e-05 - activation_1_loss: 6.5126e-06 - activation_2_loss: 3.7879e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.0108e-05 - val_activation_1_loss: 6.2396e-06 - val_activation_2_loss: 4.3868e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5094e-04 - activation_1_loss: 8.0702e-06 - activation_2_loss: 1.4287e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6494e-05 - val_activation_1_loss: 5.2790e-06 - val_activation_2_loss: 4.1215e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0391e-04 - activation_1_loss: 3.2047e-06 - activation_2_loss: 2.0070e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1889e-05 - val_activation_1_loss: 5.3558e-06 - val_activation_2_loss: 2.6533e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.6634e-04 - activation_1_loss: 1.2651e-04 - activation_2_loss: 3.3982e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.7701e-05 - val_activation_1_loss: 8.8161e-06 - val_activation_2_loss: 4.8885e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7767e-04 - activation_1_loss: 6.8169e-05 - activation_2_loss: 2.0950e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2405e-05 - val_activation_1_loss: 4.7306e-05 - val_activation_2_loss: 1.5098e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4305e-04 - activation_1_loss: 4.0483e-05 - activation_2_loss: 2.0257e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4023e-04 - val_activation_1_loss: 6.0984e-05 - val_activation_2_loss: 7.9241e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6952e-04 - activation_1_loss: 1.3026e-04 - activation_2_loss: 2.3926e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1343e-04 - val_activation_1_loss: 8.3335e-06 - val_activation_2_loss: 1.0509e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7975e-04 - activation_1_loss: 4.6021e-05 - activation_2_loss: 1.3373e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.7117e-05 - val_activation_1_loss: 5.6586e-06 - val_activation_2_loss: 7.1458e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3721e-04 - activation_1_loss: 6.3608e-05 - activation_2_loss: 7.3600e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0555e-05 - val_activation_1_loss: 2.3497e-05 - val_activation_2_loss: 1.7057e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2410e-04 - activation_1_loss: 7.5355e-06 - activation_2_loss: 1.1657e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0927e-04 - val_activation_1_loss: 7.1492e-06 - val_activation_2_loss: 3.0212e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.0218e-05 - activation_1_loss: 5.1703e-06 - activation_2_loss: 5.5047e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4387e-05 - val_activation_1_loss: 6.8361e-06 - val_activation_2_loss: 1.7551e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.3823e-05 - activation_1_loss: 1.3702e-05 - activation_2_loss: 7.0121e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4695e-04 - val_activation_1_loss: 3.7192e-06 - val_activation_2_loss: 2.4323e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6948e-05 - activation_1_loss: 4.8229e-06 - activation_2_loss: 6.2125e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.3493e-05 - val_activation_1_loss: 2.7757e-06 - val_activation_2_loss: 9.0717e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.7694e-05 - activation_1_loss: 2.9376e-06 - activation_2_loss: 4.4757e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1227e-05 - val_activation_1_loss: 2.8660e-06 - val_activation_2_loss: 3.8361e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5361e-05 - activation_1_loss: 1.6136e-05 - activation_2_loss: 6.9224e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3762e-04 - val_activation_1_loss: 3.1843e-05 - val_activation_2_loss: 3.0577e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3377e-04 - activation_1_loss: 1.9528e-04 - activation_2_loss: 1.3849e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9403e-04 - val_activation_1_loss: 2.1453e-05 - val_activation_2_loss: 1.7258e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4400e-04 - activation_1_loss: 1.3851e-04 - activation_2_loss: 2.0549e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9272e-04 - val_activation_1_loss: 5.7739e-04 - val_activation_2_loss: 1.5325e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.3149e-05 - activation_1_loss: 8.9333e-06 - activation_2_loss: 8.4216e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6582e-05 - val_activation_1_loss: 5.4982e-06 - val_activation_2_loss: 3.1084e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3334e-04 - activation_1_loss: 1.1630e-05 - activation_2_loss: 4.2171e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.5755e-05 - val_activation_1_loss: 6.0230e-06 - val_activation_2_loss: 5.9732e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1038e-04 - activation_1_loss: 1.4302e-05 - activation_2_loss: 9.6082e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0313e-04 - val_activation_1_loss: 2.8966e-06 - val_activation_2_loss: 1.0023e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3848e-04 - activation_1_loss: 7.7885e-06 - activation_2_loss: 1.3069e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.9953e-05 - val_activation_1_loss: 5.9290e-06 - val_activation_2_loss: 6.4024e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6194e-04 - activation_1_loss: 2.0456e-05 - activation_2_loss: 1.4148e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6276e-04 - val_activation_1_loss: 1.5011e-05 - val_activation_2_loss: 1.4775e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8449e-04 - activation_1_loss: 1.1435e-04 - activation_2_loss: 1.7014e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.1767e-05 - val_activation_1_loss: 5.3268e-06 - val_activation_2_loss: 4.6440e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4582e-04 - activation_1_loss: 1.7188e-04 - activation_2_loss: 1.7393e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.0604e-05 - val_activation_1_loss: 1.5572e-05 - val_activation_2_loss: 5.5032e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0985e-04 - activation_1_loss: 1.5690e-05 - activation_2_loss: 9.4164e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4421e-04 - val_activation_1_loss: 5.1819e-05 - val_activation_2_loss: 1.9239e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1983e-04 - activation_1_loss: 5.5518e-06 - activation_2_loss: 1.1428e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1803e-04 - val_activation_1_loss: 7.4758e-05 - val_activation_2_loss: 1.4327e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1412e-05 - activation_1_loss: 4.6035e-06 - activation_2_loss: 1.6809e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2885e-05 - val_activation_1_loss: 1.9277e-05 - val_activation_2_loss: 4.3609e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.8018e-05 - activation_1_loss: 5.8220e-06 - activation_2_loss: 8.2196e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1531e-05 - val_activation_1_loss: 1.6009e-05 - val_activation_2_loss: 1.5522e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.3386e-05 - activation_1_loss: 1.2311e-05 - activation_2_loss: 8.1075e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.7265e-05 - val_activation_1_loss: 1.0336e-05 - val_activation_2_loss: 8.6929e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1994e-04 - activation_1_loss: 8.4293e-05 - activation_2_loss: 1.3564e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3064e-04 - val_activation_1_loss: 1.3919e-05 - val_activation_2_loss: 1.1672e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0090e-04 - activation_1_loss: 2.7747e-05 - activation_2_loss: 1.7315e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6211e-04 - val_activation_1_loss: 1.4541e-05 - val_activation_2_loss: 1.4756e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6207e-04 - activation_1_loss: 3.3447e-04 - activation_2_loss: 3.2760e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 0.0010 - val_activation_1_loss: 6.1057e-05 - val_activation_2_loss: 9.7596e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2899e-04 - activation_1_loss: 3.2477e-05 - activation_2_loss: 9.6518e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2052e-04 - val_activation_1_loss: 2.0701e-05 - val_activation_2_loss: 9.9822e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0142e-04 - activation_1_loss: 1.5067e-05 - activation_2_loss: 1.8635e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9516e-04 - val_activation_1_loss: 5.1074e-06 - val_activation_2_loss: 2.9005e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1874e-04 - activation_1_loss: 6.6883e-06 - activation_2_loss: 1.1205e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3753e-04 - val_activation_1_loss: 1.6524e-05 - val_activation_2_loss: 1.2101e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5724e-04 - activation_1_loss: 1.5196e-05 - activation_2_loss: 2.4204e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8255e-04 - val_activation_1_loss: 5.7445e-06 - val_activation_2_loss: 2.7681e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7640e-05 - activation_1_loss: 5.5791e-06 - activation_2_loss: 8.2061e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0670e-05 - val_activation_1_loss: 1.3817e-05 - val_activation_2_loss: 1.6853e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3159e-04 - activation_1_loss: 4.9878e-06 - activation_2_loss: 1.2660e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0812e-04 - val_activation_1_loss: 9.3503e-06 - val_activation_2_loss: 9.8769e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0339e-05 - activation_1_loss: 5.3710e-06 - activation_2_loss: 7.4968e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6064e-05 - val_activation_1_loss: 1.1231e-05 - val_activation_2_loss: 1.4833e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5768e-04 - activation_1_loss: 2.5073e-06 - activation_2_loss: 1.5517e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9918e-05 - val_activation_1_loss: 4.7530e-06 - val_activation_2_loss: 1.5165e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6509e-05 - activation_1_loss: 3.7551e-06 - activation_2_loss: 6.2754e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8108e-05 - val_activation_1_loss: 3.5394e-06 - val_activation_2_loss: 7.4569e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5397e-05 - activation_1_loss: 3.3660e-06 - activation_2_loss: 8.2031e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3319e-05 - val_activation_1_loss: 1.0440e-05 - val_activation_2_loss: 6.2880e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3077e-05 - activation_1_loss: 3.3876e-06 - activation_2_loss: 1.9689e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0017 - val_activation_1_loss: 0.0017 - val_activation_2_loss: 5.1436e-06 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2528e-05 - activation_1_loss: 3.0763e-06 - activation_2_loss: 3.9451e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7890e-05 - val_activation_1_loss: 2.5096e-06 - val_activation_2_loss: 5.5380e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6540e-04 - activation_1_loss: 4.4642e-06 - activation_2_loss: 1.6094e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2120e-05 - val_activation_1_loss: 3.0631e-06 - val_activation_2_loss: 9.0568e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7430e-04 - activation_1_loss: 2.7631e-06 - activation_2_loss: 1.7153e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2528e-04 - val_activation_1_loss: 3.1525e-05 - val_activation_2_loss: 9.3751e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4638e-04 - activation_1_loss: 6.9188e-06 - activation_2_loss: 2.3946e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0324e-04 - val_activation_1_loss: 3.0380e-05 - val_activation_2_loss: 7.2857e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8838e-04 - activation_1_loss: 2.0101e-04 - activation_2_loss: 2.8737e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.5249e-05 - val_activation_1_loss: 5.4609e-06 - val_activation_2_loss: 3.9789e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8619e-04 - activation_1_loss: 1.0307e-05 - activation_2_loss: 1.7588e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.3354e-04 - val_activation_1_loss: 8.6575e-06 - val_activation_2_loss: 3.2488e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9006e-05 - activation_1_loss: 2.6329e-06 - activation_2_loss: 8.6373e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.0028e-05 - val_activation_1_loss: 2.3145e-05 - val_activation_2_loss: 2.6882e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.0871e-05 - activation_1_loss: 2.8657e-06 - activation_2_loss: 3.8005e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3468e-04 - val_activation_1_loss: 2.2800e-04 - val_activation_2_loss: 6.6805e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8543e-05 - activation_1_loss: 2.9000e-05 - activation_2_loss: 4.9543e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5324e-04 - val_activation_1_loss: 1.7276e-06 - val_activation_2_loss: 1.5151e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8715e-04 - activation_1_loss: 1.2358e-05 - activation_2_loss: 1.7479e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.4186e-05 - val_activation_1_loss: 6.5568e-06 - val_activation_2_loss: 4.7629e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.0863e-05 - activation_1_loss: 5.2504e-06 - activation_2_loss: 8.5612e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9202e-05 - val_activation_1_loss: 3.9072e-06 - val_activation_2_loss: 7.5294e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1514e-05 - activation_1_loss: 2.2901e-05 - activation_2_loss: 3.8614e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9706e-04 - val_activation_1_loss: 1.4477e-05 - val_activation_2_loss: 1.8258e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3819e-05 - activation_1_loss: 4.3103e-06 - activation_2_loss: 3.9508e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3264e-05 - val_activation_1_loss: 1.2424e-05 - val_activation_2_loss: 1.0840e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.7736e-05 - activation_1_loss: 1.2622e-05 - activation_2_loss: 4.5114e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7955e-04 - val_activation_1_loss: 1.9637e-05 - val_activation_2_loss: 1.5991e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7206e-05 - activation_1_loss: 8.3693e-06 - activation_2_loss: 7.8837e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3546e-05 - val_activation_1_loss: 2.2257e-06 - val_activation_2_loss: 5.1321e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3678e-05 - activation_1_loss: 7.8634e-06 - activation_2_loss: 3.5815e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5455e-04 - val_activation_1_loss: 2.0371e-06 - val_activation_2_loss: 1.5251e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3701e-05 - activation_1_loss: 5.0917e-06 - activation_2_loss: 3.8609e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6900e-05 - val_activation_1_loss: 5.7778e-06 - val_activation_2_loss: 1.1122e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2258e-05 - activation_1_loss: 2.8320e-06 - activation_2_loss: 9.4258e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5912e-05 - val_activation_1_loss: 2.0932e-06 - val_activation_2_loss: 3.3819e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3232e-04 - activation_1_loss: 1.3142e-05 - activation_2_loss: 2.1918e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4470e-04 - val_activation_1_loss: 1.6552e-05 - val_activation_2_loss: 1.2815e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2081e-04 - activation_1_loss: 1.5670e-04 - activation_2_loss: 2.6411e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.5117e-04 - val_activation_1_loss: 4.9519e-04 - val_activation_2_loss: 3.5598e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8874e-04 - activation_1_loss: 1.5947e-04 - activation_2_loss: 2.2926e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6046e-04 - val_activation_1_loss: 9.3197e-06 - val_activation_2_loss: 1.5114e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6030e-04 - activation_1_loss: 1.7375e-04 - activation_2_loss: 1.8655e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8133e-04 - val_activation_1_loss: 1.1861e-05 - val_activation_2_loss: 3.6947e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3864e-04 - activation_1_loss: 4.3568e-05 - activation_2_loss: 1.9507e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.2348e-04 - val_activation_1_loss: 7.8304e-06 - val_activation_2_loss: 2.1565e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0453e-04 - activation_1_loss: 2.3337e-05 - activation_2_loss: 8.1194e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4854e-04 - val_activation_1_loss: 1.5703e-05 - val_activation_2_loss: 1.3284e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4465e-05 - activation_1_loss: 1.0583e-05 - activation_2_loss: 3.3883e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7498e-05 - val_activation_1_loss: 3.6404e-06 - val_activation_2_loss: 1.3858e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.2345e-05 - activation_1_loss: 2.5903e-06 - activation_2_loss: 8.9755e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7829e-05 - val_activation_1_loss: 4.0381e-06 - val_activation_2_loss: 1.3791e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7065e-05 - activation_1_loss: 3.6061e-06 - activation_2_loss: 2.3459e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2062e-05 - val_activation_1_loss: 1.8571e-06 - val_activation_2_loss: 1.0205e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4310e-05 - activation_1_loss: 4.1858e-06 - activation_2_loss: 3.0124e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7682e-05 - val_activation_1_loss: 2.1590e-06 - val_activation_2_loss: 3.5523e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7083e-05 - activation_1_loss: 5.8304e-06 - activation_2_loss: 2.1252e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2893e-05 - val_activation_1_loss: 2.5749e-06 - val_activation_2_loss: 5.0318e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0567e-05 - activation_1_loss: 3.3441e-06 - activation_2_loss: 1.7223e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3524e-05 - val_activation_1_loss: 3.4647e-06 - val_activation_2_loss: 2.0059e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5179e-05 - activation_1_loss: 2.2526e-05 - activation_2_loss: 6.2653e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.7685e-04 - val_activation_1_loss: 1.4250e-06 - val_activation_2_loss: 8.7543e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8090e-04 - activation_1_loss: 1.0939e-05 - activation_2_loss: 1.6996e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.7296e-05 - val_activation_1_loss: 4.2902e-06 - val_activation_2_loss: 7.3006e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8647e-04 - activation_1_loss: 5.0149e-05 - activation_2_loss: 3.3632e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5300e-04 - val_activation_1_loss: 2.0808e-05 - val_activation_2_loss: 1.3219e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9392e-04 - activation_1_loss: 5.2985e-05 - activation_2_loss: 2.4094e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4292e-04 - val_activation_1_loss: 2.0042e-06 - val_activation_2_loss: 1.4091e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4641e-04 - activation_1_loss: 2.9261e-04 - activation_2_loss: 3.5380e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1600e-04 - val_activation_1_loss: 6.4251e-06 - val_activation_2_loss: 1.0957e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3087e-05 - activation_1_loss: 3.7486e-06 - activation_2_loss: 2.9339e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1442e-04 - val_activation_1_loss: 4.0646e-06 - val_activation_2_loss: 1.1036e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2176e-04 - activation_1_loss: 1.5793e-05 - activation_2_loss: 1.0597e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.5487e-05 - val_activation_1_loss: 3.4478e-06 - val_activation_2_loss: 8.2039e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4365e-04 - activation_1_loss: 1.7781e-04 - activation_2_loss: 6.5837e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1440e-05 - val_activation_1_loss: 7.7012e-06 - val_activation_2_loss: 4.3739e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7950e-04 - activation_1_loss: 4.0037e-05 - activation_2_loss: 1.3947e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0092e-04 - val_activation_1_loss: 3.6017e-05 - val_activation_2_loss: 6.4899e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2405e-04 - activation_1_loss: 8.9286e-06 - activation_2_loss: 1.1512e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9448e-04 - val_activation_1_loss: 1.0366e-05 - val_activation_2_loss: 1.8411e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0448e-04 - activation_1_loss: 1.1126e-05 - activation_2_loss: 1.9336e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8724e-04 - val_activation_1_loss: 6.7774e-06 - val_activation_2_loss: 1.8046e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4754e-04 - activation_1_loss: 7.9429e-05 - activation_2_loss: 2.6812e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.4312e-04 - val_activation_1_loss: 5.7657e-05 - val_activation_2_loss: 4.8546e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2113e-04 - activation_1_loss: 1.6245e-05 - activation_2_loss: 3.0488e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4988e-04 - val_activation_1_loss: 2.2612e-06 - val_activation_2_loss: 1.4762e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0117e-04 - activation_1_loss: 9.8496e-06 - activation_2_loss: 9.1316e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6812e-05 - val_activation_1_loss: 1.3780e-05 - val_activation_2_loss: 2.3032e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.8612e-05 - activation_1_loss: 1.0807e-05 - activation_2_loss: 4.7805e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2770e-05 - val_activation_1_loss: 1.5459e-06 - val_activation_2_loss: 3.1224e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7932e-05 - activation_1_loss: 8.5764e-06 - activation_2_loss: 2.9355e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3987e-04 - val_activation_1_loss: 5.9663e-06 - val_activation_2_loss: 1.3390e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1316e-04 - activation_1_loss: 5.1532e-06 - activation_2_loss: 1.0801e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9226e-05 - val_activation_1_loss: 4.2056e-06 - val_activation_2_loss: 4.5021e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7715e-05 - activation_1_loss: 3.3749e-06 - activation_2_loss: 3.4340e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0083e-04 - val_activation_1_loss: 2.3402e-06 - val_activation_2_loss: 9.8488e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.3119e-05 - activation_1_loss: 1.3359e-05 - activation_2_loss: 5.9760e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.1993e-05 - val_activation_1_loss: 4.1545e-06 - val_activation_2_loss: 8.7839e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0988e-04 - activation_1_loss: 4.5731e-06 - activation_2_loss: 2.0531e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6003e-04 - val_activation_1_loss: 8.8682e-05 - val_activation_2_loss: 1.7135e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2049e-04 - activation_1_loss: 9.5662e-06 - activation_2_loss: 1.1092e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4390e-04 - val_activation_1_loss: 9.6723e-06 - val_activation_2_loss: 1.3423e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.1391e-05 - activation_1_loss: 3.8306e-06 - activation_2_loss: 6.7560e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2905e-04 - val_activation_1_loss: 1.4415e-06 - val_activation_2_loss: 1.2761e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3869e-04 - activation_1_loss: 4.3294e-06 - activation_2_loss: 1.3436e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.5465e-05 - val_activation_1_loss: 2.4648e-06 - val_activation_2_loss: 9.3001e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.8419e-05 - activation_1_loss: 1.3156e-05 - activation_2_loss: 7.5263e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.8909e-05 - val_activation_1_loss: 1.1413e-05 - val_activation_2_loss: 7.7496e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6630e-04 - activation_1_loss: 3.6714e-05 - activation_2_loss: 1.2959e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.2964e-05 - val_activation_1_loss: 8.1031e-06 - val_activation_2_loss: 8.4861e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1264e-05 - activation_1_loss: 1.0071e-05 - activation_2_loss: 2.1192e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4154e-05 - val_activation_1_loss: 2.4959e-06 - val_activation_2_loss: 1.1658e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1453e-05 - activation_1_loss: 2.3497e-06 - activation_2_loss: 5.9103e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.1682e-05 - val_activation_1_loss: 3.3160e-06 - val_activation_2_loss: 8.8366e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.4987e-05 - activation_1_loss: 2.6697e-06 - activation_2_loss: 9.2317e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6171e-06 - val_activation_1_loss: 2.0479e-06 - val_activation_2_loss: 2.5691e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9803e-05 - activation_1_loss: 6.5076e-06 - activation_2_loss: 4.3295e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9801e-05 - val_activation_1_loss: 1.3794e-06 - val_activation_2_loss: 2.8422e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3496e-04 - activation_1_loss: 4.9398e-06 - activation_2_loss: 1.3002e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6051e-05 - val_activation_1_loss: 1.2367e-06 - val_activation_2_loss: 2.4814e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3305e-05 - activation_1_loss: 6.7880e-06 - activation_2_loss: 4.6517e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4728e-05 - val_activation_1_loss: 2.2559e-06 - val_activation_2_loss: 4.2472e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2955e-04 - activation_1_loss: 3.0709e-06 - activation_2_loss: 1.2648e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.3997e-05 - val_activation_1_loss: 2.9310e-06 - val_activation_2_loss: 9.1066e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0509e-05 - activation_1_loss: 2.7971e-06 - activation_2_loss: 1.7712e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.8684e-05 - val_activation_1_loss: 2.4159e-06 - val_activation_2_loss: 3.6268e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5320e-04 - activation_1_loss: 1.6299e-06 - activation_2_loss: 2.5157e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6592e-05 - val_activation_1_loss: 2.5963e-06 - val_activation_2_loss: 2.3996e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5903e-04 - activation_1_loss: 9.1206e-05 - activation_2_loss: 6.7828e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.6679e-05 - val_activation_1_loss: 4.0919e-06 - val_activation_2_loss: 5.2587e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4572e-04 - activation_1_loss: 2.5392e-05 - activation_2_loss: 1.2032e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6890e-05 - val_activation_1_loss: 2.3228e-06 - val_activation_2_loss: 2.4567e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8199e-05 - activation_1_loss: 3.8795e-06 - activation_2_loss: 6.4320e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5121e-04 - val_activation_1_loss: 1.0271e-04 - val_activation_2_loss: 3.4851e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7211e-04 - activation_1_loss: 1.2107e-04 - activation_2_loss: 2.5104e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0421e-05 - val_activation_1_loss: 8.8272e-06 - val_activation_2_loss: 3.1594e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8909e-05 - activation_1_loss: 1.5667e-05 - activation_2_loss: 5.3242e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2415e-04 - val_activation_1_loss: 1.0269e-04 - val_activation_2_loss: 2.1458e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7774e-04 - activation_1_loss: 1.3598e-04 - activation_2_loss: 1.4176e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5628e-04 - val_activation_1_loss: 1.0551e-05 - val_activation_2_loss: 1.4573e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9343e-04 - activation_1_loss: 2.1546e-05 - activation_2_loss: 1.7189e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.1822e-05 - val_activation_1_loss: 1.1562e-05 - val_activation_2_loss: 8.0260e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5686e-04 - activation_1_loss: 2.1480e-05 - activation_2_loss: 2.3538e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7831e-05 - val_activation_1_loss: 2.3906e-06 - val_activation_2_loss: 2.5441e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8541e-04 - activation_1_loss: 4.2464e-05 - activation_2_loss: 1.4295e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4665e-04 - val_activation_1_loss: 1.6606e-04 - val_activation_2_loss: 3.8059e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1517e-04 - activation_1_loss: 3.3537e-06 - activation_2_loss: 1.1182e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2671e-05 - val_activation_1_loss: 4.7436e-06 - val_activation_2_loss: 3.7928e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7581e-05 - activation_1_loss: 4.3598e-06 - activation_2_loss: 2.3221e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8666e-05 - val_activation_1_loss: 3.3386e-06 - val_activation_2_loss: 1.5328e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.0178e-05 - activation_1_loss: 2.1902e-05 - activation_2_loss: 3.8276e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5133e-05 - val_activation_1_loss: 3.2520e-06 - val_activation_2_loss: 3.1881e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6118e-05 - activation_1_loss: 2.1445e-06 - activation_2_loss: 1.3973e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9856e-06 - val_activation_1_loss: 1.1485e-06 - val_activation_2_loss: 7.8371e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0217e-04 - activation_1_loss: 4.4344e-06 - activation_2_loss: 9.7733e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6125e-04 - val_activation_1_loss: 3.3394e-06 - val_activation_2_loss: 1.5791e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.0224e-05 - activation_1_loss: 6.1277e-06 - activation_2_loss: 5.4096e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2462e-05 - val_activation_1_loss: 9.2891e-06 - val_activation_2_loss: 3.1730e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1042e-05 - activation_1_loss: 5.0632e-06 - activation_2_loss: 5.9786e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9000e-06 - val_activation_1_loss: 2.3479e-06 - val_activation_2_loss: 2.5521e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1860e-04 - activation_1_loss: 2.0269e-05 - activation_2_loss: 1.9833e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6962e-04 - val_activation_1_loss: 2.3910e-06 - val_activation_2_loss: 1.6723e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6743e-04 - activation_1_loss: 3.0837e-05 - activation_2_loss: 1.3660e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2112e-05 - val_activation_1_loss: 8.1686e-06 - val_activation_2_loss: 5.3943e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5401e-04 - activation_1_loss: 6.8259e-06 - activation_2_loss: 1.4718e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.3320e-04 - val_activation_1_loss: 4.8086e-06 - val_activation_2_loss: 1.2839e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4867e-04 - activation_1_loss: 1.3147e-04 - activation_2_loss: 2.1719e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.0664e-04 - val_activation_1_loss: 2.6991e-05 - val_activation_2_loss: 3.7965e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5980e-04 - activation_1_loss: 1.4043e-05 - activation_2_loss: 1.4575e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7829e-04 - val_activation_1_loss: 6.4921e-06 - val_activation_2_loss: 1.7180e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1362e-04 - activation_1_loss: 1.1845e-04 - activation_2_loss: 1.9517e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.8402e-05 - val_activation_1_loss: 4.7225e-06 - val_activation_2_loss: 6.3679e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1812e-04 - activation_1_loss: 4.5046e-05 - activation_2_loss: 3.7307e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.0558e-05 - val_activation_1_loss: 3.8957e-06 - val_activation_2_loss: 4.6662e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3362e-04 - activation_1_loss: 5.0850e-05 - activation_2_loss: 8.2769e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3627e-04 - val_activation_1_loss: 2.2281e-05 - val_activation_2_loss: 1.1399e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1072e-04 - activation_1_loss: 5.0514e-05 - activation_2_loss: 6.0205e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9013e-05 - val_activation_1_loss: 2.6623e-06 - val_activation_2_loss: 3.6351e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2153e-04 - activation_1_loss: 8.9672e-05 - activation_2_loss: 3.1855e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0045e-04 - val_activation_1_loss: 3.5273e-04 - val_activation_2_loss: 4.7723e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.3423e-05 - activation_1_loss: 3.3117e-05 - activation_2_loss: 3.0305e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.4244e-05 - val_activation_1_loss: 7.6618e-06 - val_activation_2_loss: 7.6582e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4134e-04 - activation_1_loss: 4.8673e-05 - activation_2_loss: 1.9267e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0011 - val_activation_1_loss: 0.0011 - val_activation_2_loss: 1.0729e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2344e-04 - activation_1_loss: 3.9925e-05 - activation_2_loss: 8.3520e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4852e-04 - val_activation_1_loss: 6.8572e-06 - val_activation_2_loss: 2.4166e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9109e-05 - activation_1_loss: 1.8676e-05 - activation_2_loss: 2.0433e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2523e-05 - val_activation_1_loss: 1.9984e-06 - val_activation_2_loss: 2.0525e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.3392e-05 - activation_1_loss: 4.0596e-06 - activation_2_loss: 6.9332e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5785e-04 - val_activation_1_loss: 6.8537e-05 - val_activation_2_loss: 8.9310e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.7447e-05 - activation_1_loss: 7.6887e-06 - activation_2_loss: 6.9758e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2138e-05 - val_activation_1_loss: 2.1889e-06 - val_activation_2_loss: 4.9949e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.1886e-05 - activation_1_loss: 1.0818e-05 - activation_2_loss: 8.1069e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3933e-05 - val_activation_1_loss: 1.9310e-06 - val_activation_2_loss: 2.2002e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0012 - activation_1_loss: 5.8576e-04 - activation_2_loss: 6.0043e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 1.7939e-04 - val_activation_1_loss: 6.8251e-06 - val_activation_2_loss: 1.7257e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9313e-05 - activation_1_loss: 4.9015e-06 - activation_2_loss: 6.4412e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7171e-05 - val_activation_1_loss: 1.8991e-05 - val_activation_2_loss: 8.1798e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.8085e-05 - activation_1_loss: 4.3327e-06 - activation_2_loss: 8.3753e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1153e-04 - val_activation_1_loss: 2.3499e-06 - val_activation_2_loss: 1.0918e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4325e-05 - activation_1_loss: 2.9866e-06 - activation_2_loss: 8.1338e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4298e-04 - val_activation_1_loss: 2.5894e-06 - val_activation_2_loss: 1.4039e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7552e-05 - activation_1_loss: 1.0582e-05 - activation_2_loss: 5.6970e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9422e-04 - val_activation_1_loss: 1.0595e-05 - val_activation_2_loss: 1.8363e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7311e-04 - activation_1_loss: 7.9885e-06 - activation_2_loss: 2.6512e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.2901e-04 - val_activation_1_loss: 5.5573e-04 - val_activation_2_loss: 7.3282e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4435e-04 - activation_1_loss: 1.4000e-04 - activation_2_loss: 3.0435e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.0922e-05 - val_activation_1_loss: 1.3299e-06 - val_activation_2_loss: 8.9592e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1434e-04 - activation_1_loss: 9.1363e-06 - activation_2_loss: 1.0521e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9799e-05 - val_activation_1_loss: 2.1528e-06 - val_activation_2_loss: 1.7646e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0983e-05 - activation_1_loss: 3.2993e-06 - activation_2_loss: 2.7684e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7974e-05 - val_activation_1_loss: 1.6662e-05 - val_activation_2_loss: 1.1311e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4426e-04 - activation_1_loss: 1.0699e-05 - activation_2_loss: 1.3356e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1853e-04 - val_activation_1_loss: 4.7360e-06 - val_activation_2_loss: 2.1380e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.6905e-05 - activation_1_loss: 1.6971e-06 - activation_2_loss: 7.5208e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9228e-04 - val_activation_1_loss: 3.0112e-06 - val_activation_2_loss: 4.8927e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1155e-05 - activation_1_loss: 2.4009e-06 - activation_2_loss: 3.8754e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4104e-04 - val_activation_1_loss: 1.6124e-06 - val_activation_2_loss: 1.3943e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6277e-05 - activation_1_loss: 3.9427e-06 - activation_2_loss: 6.2335e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6480e-05 - val_activation_1_loss: 1.3462e-06 - val_activation_2_loss: 1.5134e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9632e-05 - activation_1_loss: 3.6406e-06 - activation_2_loss: 2.5991e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4947e-04 - val_activation_1_loss: 3.8220e-06 - val_activation_2_loss: 1.4565e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5529e-05 - activation_1_loss: 1.6704e-06 - activation_2_loss: 3.3859e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7316e-05 - val_activation_1_loss: 9.0280e-07 - val_activation_2_loss: 1.6413e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1679e-05 - activation_1_loss: 5.7158e-06 - activation_2_loss: 5.9631e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7580e-06 - val_activation_1_loss: 3.5425e-06 - val_activation_2_loss: 2.2156e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.9829e-04 - activation_1_loss: 3.4920e-04 - activation_2_loss: 4.4909e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.6833e-05 - val_activation_1_loss: 5.1430e-06 - val_activation_2_loss: 5.1690e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0077e-04 - activation_1_loss: 1.4198e-05 - activation_2_loss: 8.6570e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.0859e-05 - val_activation_1_loss: 1.3188e-05 - val_activation_2_loss: 6.7671e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5952e-04 - activation_1_loss: 1.0575e-05 - activation_2_loss: 1.4895e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7254e-04 - val_activation_1_loss: 7.3521e-06 - val_activation_2_loss: 3.6519e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0240e-04 - activation_1_loss: 2.6690e-06 - activation_2_loss: 9.9734e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.2672e-05 - val_activation_1_loss: 2.9710e-06 - val_activation_2_loss: 7.9701e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4286e-05 - activation_1_loss: 1.2107e-05 - activation_2_loss: 7.2179e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5754e-04 - val_activation_1_loss: 2.1632e-06 - val_activation_2_loss: 2.5538e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3718e-05 - activation_1_loss: 7.3705e-06 - activation_2_loss: 4.6347e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0329e-05 - val_activation_1_loss: 2.2200e-06 - val_activation_2_loss: 1.8109e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5903e-05 - activation_1_loss: 3.3641e-06 - activation_2_loss: 3.2539e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1850e-05 - val_activation_1_loss: 1.8394e-06 - val_activation_2_loss: 7.0011e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6899e-04 - activation_1_loss: 2.2733e-06 - activation_2_loss: 1.6671e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6372e-04 - val_activation_1_loss: 1.1187e-06 - val_activation_2_loss: 1.6260e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.1592e-05 - activation_1_loss: 2.5434e-06 - activation_2_loss: 7.9048e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1338e-04 - val_activation_1_loss: 2.4654e-06 - val_activation_2_loss: 3.1092e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5598e-05 - activation_1_loss: 1.9873e-05 - activation_2_loss: 4.5725e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5878e-04 - val_activation_1_loss: 1.8298e-06 - val_activation_2_loss: 3.5695e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1377e-04 - activation_1_loss: 2.5761e-04 - activation_2_loss: 5.6160e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4587e-05 - val_activation_1_loss: 2.3823e-06 - val_activation_2_loss: 1.2204e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5224e-04 - activation_1_loss: 1.0304e-04 - activation_2_loss: 2.4920e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2452e-04 - val_activation_1_loss: 4.5829e-05 - val_activation_2_loss: 7.8689e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7672e-04 - activation_1_loss: 1.9226e-04 - activation_2_loss: 8.4456e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.6404e-04 - val_activation_1_loss: 3.3582e-04 - val_activation_2_loss: 2.2822e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.9974e-05 - activation_1_loss: 6.5477e-06 - activation_2_loss: 5.3426e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4484e-05 - val_activation_1_loss: 2.5190e-06 - val_activation_2_loss: 4.1965e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9938e-04 - activation_1_loss: 3.4098e-06 - activation_2_loss: 1.9597e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.9484e-05 - val_activation_1_loss: 4.7526e-06 - val_activation_2_loss: 3.4731e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8559e-04 - activation_1_loss: 6.3802e-06 - activation_2_loss: 1.7921e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 5.3718e-05 - val_activation_1_loss: 2.1523e-06 - val_activation_2_loss: 5.1566e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4206e-05 - activation_1_loss: 7.8177e-06 - activation_2_loss: 5.6388e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5801e-04 - val_activation_1_loss: 1.7297e-06 - val_activation_2_loss: 1.5628e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2490e-05 - activation_1_loss: 1.1172e-05 - activation_2_loss: 6.1318e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.9522e-06 - val_activation_1_loss: 2.9942e-06 - val_activation_2_loss: 3.9580e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8239e-05 - activation_1_loss: 9.8476e-06 - activation_2_loss: 8.3915e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4093e-06 - val_activation_1_loss: 2.1178e-06 - val_activation_2_loss: 2.2916e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1107e-05 - activation_1_loss: 2.6152e-06 - activation_2_loss: 5.8492e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6521e-05 - val_activation_1_loss: 3.7502e-06 - val_activation_2_loss: 1.2771e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0799e-05 - activation_1_loss: 1.5742e-06 - activation_2_loss: 2.9225e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5779e-05 - val_activation_1_loss: 2.5592e-06 - val_activation_2_loss: 2.3220e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0504e-05 - activation_1_loss: 5.6574e-06 - activation_2_loss: 2.4846e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1505e-05 - val_activation_1_loss: 6.1533e-06 - val_activation_2_loss: 5.3517e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0752e-04 - activation_1_loss: 8.3945e-06 - activation_2_loss: 9.9127e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8043e-05 - val_activation_1_loss: 2.9912e-06 - val_activation_2_loss: 7.5052e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8118e-04 - activation_1_loss: 1.3244e-04 - activation_2_loss: 4.8748e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6280e-04 - val_activation_1_loss: 1.0058e-04 - val_activation_2_loss: 6.2220e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4885e-04 - activation_1_loss: 4.8076e-05 - activation_2_loss: 1.0077e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3335e-04 - val_activation_1_loss: 9.7964e-05 - val_activation_2_loss: 1.3539e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5504e-04 - activation_1_loss: 1.5635e-05 - activation_2_loss: 1.3940e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3191e-04 - val_activation_1_loss: 6.8928e-06 - val_activation_2_loss: 2.2502e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8367e-04 - activation_1_loss: 1.2996e-04 - activation_2_loss: 2.5372e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6062e-04 - val_activation_1_loss: 6.6893e-06 - val_activation_2_loss: 2.5393e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8146e-04 - activation_1_loss: 2.4436e-04 - activation_2_loss: 1.3710e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0023 - val_activation_1_loss: 0.0020 - val_activation_2_loss: 2.6835e-04 - val_activation_1_acc: 0.9998 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7311e-04 - activation_1_loss: 1.2298e-04 - activation_2_loss: 1.5012e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4363e-05 - val_activation_1_loss: 6.7972e-06 - val_activation_2_loss: 2.7566e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6889e-04 - activation_1_loss: 1.8861e-05 - activation_2_loss: 1.5003e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5608e-04 - val_activation_1_loss: 1.0283e-05 - val_activation_2_loss: 2.4580e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3408e-04 - activation_1_loss: 3.0740e-05 - activation_2_loss: 3.0334e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.7760e-05 - val_activation_1_loss: 3.1279e-06 - val_activation_2_loss: 3.4632e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.4426e-05 - activation_1_loss: 5.1090e-06 - activation_2_loss: 6.9317e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2413e-05 - val_activation_1_loss: 1.3445e-06 - val_activation_2_loss: 2.1069e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.5086e-05 - activation_1_loss: 8.6966e-06 - activation_2_loss: 6.6389e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0415e-05 - val_activation_1_loss: 2.7346e-05 - val_activation_2_loss: 1.3070e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7913e-05 - activation_1_loss: 1.7874e-06 - activation_2_loss: 2.6125e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.5375e-05 - val_activation_1_loss: 1.8843e-06 - val_activation_2_loss: 9.3491e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.5162e-05 - activation_1_loss: 1.7920e-06 - activation_2_loss: 5.3370e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9500e-04 - val_activation_1_loss: 1.8542e-06 - val_activation_2_loss: 1.9315e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5282e-05 - activation_1_loss: 1.7332e-06 - activation_2_loss: 2.3549e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.0466e-05 - val_activation_1_loss: 2.8083e-06 - val_activation_2_loss: 7.7658e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0723e-05 - activation_1_loss: 1.8077e-06 - activation_2_loss: 1.8915e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3373e-04 - val_activation_1_loss: 1.7668e-06 - val_activation_2_loss: 1.3196e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3404e-04 - activation_1_loss: 9.7809e-06 - activation_2_loss: 1.2426e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5292e-05 - val_activation_1_loss: 2.3037e-06 - val_activation_2_loss: 4.2988e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2741e-04 - activation_1_loss: 5.1252e-06 - activation_2_loss: 1.2228e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7870e-05 - val_activation_1_loss: 4.7220e-06 - val_activation_2_loss: 2.3148e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.8490e-05 - activation_1_loss: 7.4783e-06 - activation_2_loss: 9.1012e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4251e-05 - val_activation_1_loss: 6.0186e-06 - val_activation_2_loss: 8.2329e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4828e-05 - activation_1_loss: 4.8350e-06 - activation_2_loss: 2.9993e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.6579e-04 - val_activation_1_loss: 5.5973e-04 - val_activation_2_loss: 6.0597e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0241e-04 - activation_1_loss: 2.0976e-06 - activation_2_loss: 1.0032e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0682e-04 - val_activation_1_loss: 1.3284e-04 - val_activation_2_loss: 4.7398e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0014 - activation_1_loss: 9.3078e-04 - activation_2_loss: 4.9889e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 7.7687e-05 - val_activation_1_loss: 1.2494e-05 - val_activation_2_loss: 6.5193e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1958e-04 - activation_1_loss: 1.2777e-04 - activation_2_loss: 2.9181e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0024 - val_activation_1_loss: 9.9693e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2538e-05 - activation_1_loss: 8.9892e-06 - activation_2_loss: 6.3548e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3952e-05 - val_activation_1_loss: 3.7531e-06 - val_activation_2_loss: 5.0199e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0403e-04 - activation_1_loss: 3.8424e-06 - activation_2_loss: 1.0018e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1968e-04 - val_activation_1_loss: 5.2704e-06 - val_activation_2_loss: 2.1441e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8815e-04 - activation_1_loss: 1.7154e-05 - activation_2_loss: 1.7099e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0779e-04 - val_activation_1_loss: 2.6619e-06 - val_activation_2_loss: 1.0513e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1952e-04 - activation_1_loss: 3.5794e-05 - activation_2_loss: 8.3723e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8803e-04 - val_activation_1_loss: 5.7045e-05 - val_activation_2_loss: 1.3099e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3973e-04 - activation_1_loss: 7.3544e-06 - activation_2_loss: 1.3238e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0665e-05 - val_activation_1_loss: 6.6737e-06 - val_activation_2_loss: 1.3991e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8507e-05 - activation_1_loss: 5.8008e-06 - activation_2_loss: 6.2707e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3919e-04 - val_activation_1_loss: 5.1866e-06 - val_activation_2_loss: 2.3401e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9279e-05 - activation_1_loss: 4.5216e-06 - activation_2_loss: 1.4758e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.5056e-05 - val_activation_1_loss: 1.4821e-05 - val_activation_2_loss: 6.0236e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6161e-04 - activation_1_loss: 9.4456e-06 - activation_2_loss: 1.5216e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.7021e-05 - val_activation_1_loss: 4.0266e-05 - val_activation_2_loss: 3.6755e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.6968e-05 - activation_1_loss: 3.0949e-06 - activation_2_loss: 8.3873e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2622e-04 - val_activation_1_loss: 2.5939e-06 - val_activation_2_loss: 1.2363e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1220e-05 - activation_1_loss: 3.0683e-06 - activation_2_loss: 3.8151e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.6547e-05 - val_activation_1_loss: 4.1128e-06 - val_activation_2_loss: 7.2434e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3420e-04 - activation_1_loss: 9.7755e-05 - activation_2_loss: 3.6443e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1069e-04 - val_activation_1_loss: 2.0308e-04 - val_activation_2_loss: 7.6122e-06 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9366e-05 - activation_1_loss: 2.9758e-05 - activation_2_loss: 9.6085e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1655e-04 - val_activation_1_loss: 1.6371e-05 - val_activation_2_loss: 1.0017e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2224e-04 - activation_1_loss: 7.8599e-05 - activation_2_loss: 1.4364e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7740e-05 - val_activation_1_loss: 2.7834e-06 - val_activation_2_loss: 5.4957e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9055e-04 - activation_1_loss: 2.4912e-04 - activation_2_loss: 1.4143e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0689e-05 - val_activation_1_loss: 3.8952e-06 - val_activation_2_loss: 6.7939e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9563e-05 - activation_1_loss: 5.8225e-06 - activation_2_loss: 4.3741e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5973e-05 - val_activation_1_loss: 3.0899e-06 - val_activation_2_loss: 3.2883e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0859e-04 - activation_1_loss: 2.1484e-05 - activation_2_loss: 1.8710e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0011 - val_activation_1_loss: 2.7339e-04 - val_activation_2_loss: 8.3558e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.0596e-05 - activation_1_loss: 7.5149e-06 - activation_2_loss: 6.3081e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6480e-05 - val_activation_1_loss: 2.7253e-05 - val_activation_2_loss: 9.2271e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3799e-04 - activation_1_loss: 4.1615e-05 - activation_2_loss: 1.9637e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.8958e-04 - val_activation_1_loss: 2.1933e-05 - val_activation_2_loss: 3.6765e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0263e-04 - activation_1_loss: 7.0461e-06 - activation_2_loss: 9.5588e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4175e-05 - val_activation_1_loss: 4.2719e-06 - val_activation_2_loss: 3.9903e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.6486e-05 - activation_1_loss: 5.0352e-06 - activation_2_loss: 8.1451e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3192e-04 - val_activation_1_loss: 3.1420e-06 - val_activation_2_loss: 2.2878e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1357e-04 - activation_1_loss: 2.6303e-06 - activation_2_loss: 1.1094e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0007e-04 - val_activation_1_loss: 1.1636e-06 - val_activation_2_loss: 9.8903e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4480e-04 - activation_1_loss: 4.3269e-05 - activation_2_loss: 1.0153e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2295e-04 - val_activation_1_loss: 8.3290e-05 - val_activation_2_loss: 3.9657e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6681e-05 - activation_1_loss: 1.9980e-05 - activation_2_loss: 1.6701e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.6844e-04 - val_activation_1_loss: 1.5035e-06 - val_activation_2_loss: 3.6694e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9336e-04 - activation_1_loss: 2.2055e-05 - activation_2_loss: 1.7131e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0033 - val_activation_1_loss: 0.0016 - val_activation_2_loss: 0.0017 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.7524e-04 - activation_1_loss: 2.2451e-04 - activation_2_loss: 3.5073e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.6757e-04 - val_activation_1_loss: 3.3895e-05 - val_activation_2_loss: 3.3368e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0013 - activation_1_loss: 8.3673e-04 - activation_2_loss: 4.2820e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 3.6137e-04 - val_activation_1_loss: 3.0286e-05 - val_activation_2_loss: 3.3109e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5808e-04 - activation_1_loss: 7.5124e-05 - activation_2_loss: 1.8295e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.4238e-04 - val_activation_1_loss: 1.5496e-04 - val_activation_2_loss: 1.8742e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1291e-04 - activation_1_loss: 1.3273e-04 - activation_2_loss: 8.0177e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4174e-05 - val_activation_1_loss: 1.9902e-05 - val_activation_2_loss: 3.4272e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0378e-04 - activation_1_loss: 2.5305e-05 - activation_2_loss: 1.7847e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1547e-04 - val_activation_1_loss: 1.5766e-05 - val_activation_2_loss: 2.9970e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2013e-04 - activation_1_loss: 1.7795e-05 - activation_2_loss: 1.0234e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7701e-05 - val_activation_1_loss: 6.6407e-06 - val_activation_2_loss: 1.1060e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4354e-04 - activation_1_loss: 1.7517e-05 - activation_2_loss: 1.2602e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3417e-05 - val_activation_1_loss: 4.4866e-06 - val_activation_2_loss: 1.8930e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1276e-04 - activation_1_loss: 1.8426e-05 - activation_2_loss: 9.4336e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7493e-05 - val_activation_1_loss: 3.8967e-06 - val_activation_2_loss: 6.3597e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9067e-05 - activation_1_loss: 1.1780e-05 - activation_2_loss: 2.7287e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.5526e-05 - val_activation_1_loss: 3.8379e-06 - val_activation_2_loss: 5.1688e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2030e-05 - activation_1_loss: 4.2530e-06 - activation_2_loss: 4.7777e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9231e-05 - val_activation_1_loss: 2.7623e-06 - val_activation_2_loss: 7.6469e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.0768e-05 - activation_1_loss: 5.3528e-06 - activation_2_loss: 3.5415e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7000e-05 - val_activation_1_loss: 3.3610e-06 - val_activation_2_loss: 1.3639e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2798e-05 - activation_1_loss: 4.1249e-06 - activation_2_loss: 8.6731e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.2555e-05 - val_activation_1_loss: 2.7981e-06 - val_activation_2_loss: 8.9757e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.8408e-06 - activation_1_loss: 2.2442e-06 - activation_2_loss: 3.5966e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4458e-05 - val_activation_1_loss: 2.9886e-06 - val_activation_2_loss: 2.1469e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4525e-05 - activation_1_loss: 3.1737e-06 - activation_2_loss: 4.1351e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.6813e-05 - val_activation_1_loss: 2.4866e-06 - val_activation_2_loss: 5.4327e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8674e-05 - activation_1_loss: 7.0918e-06 - activation_2_loss: 1.1582e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.8635e-05 - val_activation_1_loss: 2.3911e-06 - val_activation_2_loss: 3.6244e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4193e-05 - activation_1_loss: 1.8021e-06 - activation_2_loss: 4.2390e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9006e-04 - val_activation_1_loss: 3.6885e-06 - val_activation_2_loss: 2.8637e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6670e-04 - activation_1_loss: 8.0693e-06 - activation_2_loss: 1.5863e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6899e-04 - val_activation_1_loss: 1.0616e-05 - val_activation_2_loss: 1.5837e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7699e-05 - activation_1_loss: 2.5939e-06 - activation_2_loss: 2.5106e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2453e-05 - val_activation_1_loss: 1.6879e-06 - val_activation_2_loss: 1.0765e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2611e-05 - activation_1_loss: 2.5019e-06 - activation_2_loss: 2.0109e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7561e-05 - val_activation_1_loss: 1.6475e-06 - val_activation_2_loss: 1.5914e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5226e-05 - activation_1_loss: 2.4907e-06 - activation_2_loss: 2.2735e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0233e-05 - val_activation_1_loss: 2.5594e-06 - val_activation_2_loss: 7.6734e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.0299e-05 - activation_1_loss: 1.8124e-06 - activation_2_loss: 6.8486e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7863e-05 - val_activation_1_loss: 3.1657e-05 - val_activation_2_loss: 2.6206e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2127e-04 - activation_1_loss: 2.7006e-06 - activation_2_loss: 1.1857e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4093e-05 - val_activation_1_loss: 3.2645e-06 - val_activation_2_loss: 1.0828e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1886e-04 - activation_1_loss: 1.2794e-05 - activation_2_loss: 2.0607e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.0563e-04 - val_activation_1_loss: 3.2435e-06 - val_activation_2_loss: 8.0239e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8911e-04 - activation_1_loss: 3.9399e-05 - activation_2_loss: 2.4971e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.2973e-04 - val_activation_1_loss: 1.0874e-05 - val_activation_2_loss: 1.1886e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6631e-04 - activation_1_loss: 9.1348e-06 - activation_2_loss: 1.5717e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9160e-05 - val_activation_1_loss: 2.5615e-06 - val_activation_2_loss: 3.6598e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.7110e-05 - activation_1_loss: 1.1783e-05 - activation_2_loss: 8.5327e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8758e-05 - val_activation_1_loss: 3.6776e-06 - val_activation_2_loss: 6.5080e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0077e-04 - activation_1_loss: 6.8859e-06 - activation_2_loss: 9.3883e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1282e-04 - val_activation_1_loss: 1.3156e-05 - val_activation_2_loss: 1.9967e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.2692e-04 - activation_1_loss: 3.9080e-04 - activation_2_loss: 4.3613e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4551e-05 - val_activation_1_loss: 6.5066e-06 - val_activation_2_loss: 2.8044e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0732e-05 - activation_1_loss: 1.2248e-05 - activation_2_loss: 1.8484e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1399e-05 - val_activation_1_loss: 3.6154e-06 - val_activation_2_loss: 1.7783e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3064e-05 - activation_1_loss: 5.3923e-06 - activation_2_loss: 1.7672e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7114e-05 - val_activation_1_loss: 2.4558e-06 - val_activation_2_loss: 5.4658e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2492e-05 - activation_1_loss: 3.0444e-06 - activation_2_loss: 2.9448e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1765e-04 - val_activation_1_loss: 3.3658e-06 - val_activation_2_loss: 1.1429e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.6922e-05 - activation_1_loss: 1.9356e-06 - activation_2_loss: 5.4986e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0052e-04 - val_activation_1_loss: 2.7952e-06 - val_activation_2_loss: 9.7726e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8570e-05 - activation_1_loss: 5.9140e-06 - activation_2_loss: 2.2656e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9113e-05 - val_activation_1_loss: 1.9804e-06 - val_activation_2_loss: 3.7132e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4763e-06 - activation_1_loss: 1.6690e-06 - activation_2_loss: 3.8073e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5191e-05 - val_activation_1_loss: 1.9867e-06 - val_activation_2_loss: 4.3204e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1331e-05 - activation_1_loss: 2.4172e-06 - activation_2_loss: 2.8914e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1480e-05 - val_activation_1_loss: 1.5518e-06 - val_activation_2_loss: 3.9928e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1912e-04 - activation_1_loss: 1.0615e-05 - activation_2_loss: 1.0851e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2118e-04 - val_activation_1_loss: 4.6291e-05 - val_activation_2_loss: 1.7489e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7414e-04 - activation_1_loss: 1.1887e-05 - activation_2_loss: 2.6225e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.9087e-04 - val_activation_1_loss: 4.7340e-06 - val_activation_2_loss: 1.8613e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2085e-04 - activation_1_loss: 1.2227e-04 - activation_2_loss: 1.9858e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0922e-04 - val_activation_1_loss: 8.8755e-06 - val_activation_2_loss: 1.0035e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5837e-04 - activation_1_loss: 4.4045e-04 - activation_2_loss: 4.1792e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0023 - val_activation_1_loss: 8.5922e-04 - val_activation_2_loss: 0.0014 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6389e-04 - activation_1_loss: 6.9494e-05 - activation_2_loss: 9.4397e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0500e-04 - val_activation_1_loss: 5.3285e-06 - val_activation_2_loss: 1.9967e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3567e-04 - activation_1_loss: 8.2047e-05 - activation_2_loss: 5.3619e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0316e-04 - val_activation_1_loss: 3.2023e-06 - val_activation_2_loss: 9.9958e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8322e-05 - activation_1_loss: 7.6756e-06 - activation_2_loss: 7.0647e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4393e-05 - val_activation_1_loss: 6.2246e-06 - val_activation_2_loss: 1.8168e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2527e-05 - activation_1_loss: 4.5404e-06 - activation_2_loss: 2.7987e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.0394e-06 - val_activation_1_loss: 1.3540e-06 - val_activation_2_loss: 3.6854e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.5165e-06 - activation_1_loss: 1.7949e-06 - activation_2_loss: 5.7216e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9951e-05 - val_activation_1_loss: 5.5227e-06 - val_activation_2_loss: 1.4428e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3244e-05 - activation_1_loss: 2.4142e-06 - activation_2_loss: 5.0830e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5125e-04 - val_activation_1_loss: 1.3584e-05 - val_activation_2_loss: 3.3766e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5941e-04 - activation_1_loss: 1.1968e-05 - activation_2_loss: 1.4744e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.3221e-05 - val_activation_1_loss: 1.8690e-06 - val_activation_2_loss: 9.1352e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9972e-04 - activation_1_loss: 1.3374e-04 - activation_2_loss: 3.6598e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.9599e-04 - val_activation_1_loss: 5.1357e-05 - val_activation_2_loss: 2.4463e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3432e-04 - activation_1_loss: 7.3405e-05 - activation_2_loss: 3.6091e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7263e-04 - val_activation_1_loss: 2.2925e-05 - val_activation_2_loss: 1.4971e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1007e-04 - activation_1_loss: 7.1913e-05 - activation_2_loss: 2.3816e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.7743e-04 - val_activation_1_loss: 3.4649e-06 - val_activation_2_loss: 2.7396e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.8480e-05 - activation_1_loss: 1.3429e-05 - activation_2_loss: 4.5051e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5191e-04 - val_activation_1_loss: 3.6007e-06 - val_activation_2_loss: 1.4831e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1587e-05 - activation_1_loss: 1.5018e-05 - activation_2_loss: 4.6569e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3996e-05 - val_activation_1_loss: 3.0293e-06 - val_activation_2_loss: 7.0967e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2236e-05 - activation_1_loss: 1.9608e-05 - activation_2_loss: 5.2629e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4172e-05 - val_activation_1_loss: 6.8352e-06 - val_activation_2_loss: 2.7337e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1820e-05 - activation_1_loss: 5.8702e-06 - activation_2_loss: 5.5950e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6985e-05 - val_activation_1_loss: 1.6988e-06 - val_activation_2_loss: 1.5286e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2548e-04 - activation_1_loss: 2.2115e-06 - activation_2_loss: 1.2327e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.6772e-05 - val_activation_1_loss: 3.5311e-06 - val_activation_2_loss: 8.3241e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.2311e-05 - activation_1_loss: 8.2121e-06 - activation_2_loss: 5.4098e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4215e-04 - val_activation_1_loss: 2.9350e-06 - val_activation_2_loss: 1.3922e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5296e-05 - activation_1_loss: 3.3251e-06 - activation_2_loss: 6.1971e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3907e-05 - val_activation_1_loss: 1.9506e-06 - val_activation_2_loss: 5.1957e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9028e-05 - activation_1_loss: 5.9836e-06 - activation_2_loss: 3.3044e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.1762e-05 - val_activation_1_loss: 6.5986e-06 - val_activation_2_loss: 7.5164e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8791e-05 - activation_1_loss: 4.6165e-06 - activation_2_loss: 1.4174e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5572e-06 - val_activation_1_loss: 1.2788e-06 - val_activation_2_loss: 3.2784e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2771e-05 - activation_1_loss: 2.2112e-06 - activation_2_loss: 1.0560e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3973e-05 - val_activation_1_loss: 2.1260e-06 - val_activation_2_loss: 2.1847e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9539e-06 - activation_1_loss: 1.9465e-06 - activation_2_loss: 5.0074e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1121e-06 - val_activation_1_loss: 1.8824e-06 - val_activation_2_loss: 2.2296e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6895e-05 - activation_1_loss: 2.0249e-06 - activation_2_loss: 3.4870e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4121e-05 - val_activation_1_loss: 1.9439e-05 - val_activation_2_loss: 1.4683e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8962e-05 - activation_1_loss: 1.5460e-06 - activation_2_loss: 1.7416e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3313e-04 - val_activation_1_loss: 2.5758e-06 - val_activation_2_loss: 1.3055e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1644e-04 - activation_1_loss: 7.3892e-06 - activation_2_loss: 2.0905e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6451e-04 - val_activation_1_loss: 2.5196e-06 - val_activation_2_loss: 2.6199e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8340e-04 - activation_1_loss: 2.4173e-04 - activation_2_loss: 4.4167e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.8789e-04 - val_activation_1_loss: 1.6175e-05 - val_activation_2_loss: 1.7171e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3807e-05 - activation_1_loss: 1.2107e-05 - activation_2_loss: 4.1700e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1542e-04 - val_activation_1_loss: 3.7975e-04 - val_activation_2_loss: 3.3567e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8939e-04 - activation_1_loss: 1.2953e-05 - activation_2_loss: 1.7643e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.0764e-04 - val_activation_1_loss: 1.0197e-04 - val_activation_2_loss: 1.0567e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7933e-04 - activation_1_loss: 4.1948e-05 - activation_2_loss: 1.3738e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.9223e-05 - val_activation_1_loss: 1.6987e-05 - val_activation_2_loss: 4.2236e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9421e-05 - activation_1_loss: 2.9591e-06 - activation_2_loss: 4.6461e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.6348e-05 - val_activation_1_loss: 3.4138e-06 - val_activation_2_loss: 7.2934e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0233e-04 - activation_1_loss: 3.9040e-06 - activation_2_loss: 9.8425e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7505e-04 - val_activation_1_loss: 2.8590e-06 - val_activation_2_loss: 2.7219e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9796e-04 - activation_1_loss: 2.4869e-05 - activation_2_loss: 1.7309e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.2695e-05 - val_activation_1_loss: 2.0607e-06 - val_activation_2_loss: 8.0634e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4749e-05 - activation_1_loss: 4.7427e-06 - activation_2_loss: 6.0007e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.0597e-05 - val_activation_1_loss: 1.0538e-05 - val_activation_2_loss: 6.0059e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0963e-05 - activation_1_loss: 6.1036e-06 - activation_2_loss: 4.4859e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4779e-04 - val_activation_1_loss: 6.6568e-06 - val_activation_2_loss: 1.4114e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.3252e-05 - activation_1_loss: 1.7423e-05 - activation_2_loss: 5.5829e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.7054e-05 - val_activation_1_loss: 3.1618e-06 - val_activation_2_loss: 9.3892e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0327e-05 - activation_1_loss: 7.9434e-06 - activation_2_loss: 4.2383e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9397e-04 - val_activation_1_loss: 7.3200e-04 - val_activation_2_loss: 2.6197e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.1632e-04 - activation_1_loss: 1.6963e-04 - activation_2_loss: 3.4669e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.8276e-04 - val_activation_1_loss: 2.4737e-06 - val_activation_2_loss: 2.8028e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.7342e-05 - activation_1_loss: 3.6079e-06 - activation_2_loss: 7.3734e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1542e-05 - val_activation_1_loss: 3.9726e-06 - val_activation_2_loss: 4.7569e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7404e-05 - activation_1_loss: 1.0621e-05 - activation_2_loss: 5.6783e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0756e-04 - val_activation_1_loss: 4.9489e-06 - val_activation_2_loss: 2.0261e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1590e-05 - activation_1_loss: 1.8567e-06 - activation_2_loss: 1.9734e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9564e-05 - val_activation_1_loss: 6.8728e-06 - val_activation_2_loss: 2.2691e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9846e-04 - activation_1_loss: 3.0194e-06 - activation_2_loss: 1.9545e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.1238e-04 - val_activation_1_loss: 1.4844e-04 - val_activation_2_loss: 1.6394e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4288e-04 - activation_1_loss: 3.0525e-06 - activation_2_loss: 2.3983e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.5042e-04 - val_activation_1_loss: 2.9724e-06 - val_activation_2_loss: 3.4744e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4885e-05 - activation_1_loss: 5.5720e-06 - activation_2_loss: 3.9313e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3306e-05 - val_activation_1_loss: 1.0275e-05 - val_activation_2_loss: 2.3030e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.3709e-05 - activation_1_loss: 2.5001e-05 - activation_2_loss: 4.8708e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.2588e-05 - val_activation_1_loss: 7.9764e-06 - val_activation_2_loss: 7.4612e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2302e-04 - activation_1_loss: 6.0444e-06 - activation_2_loss: 1.1698e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2517e-05 - val_activation_1_loss: 1.1044e-05 - val_activation_2_loss: 5.1474e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0586e-04 - activation_1_loss: 1.2828e-05 - activation_2_loss: 9.3030e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6983e-04 - val_activation_1_loss: 1.3996e-05 - val_activation_2_loss: 2.5583e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.9055e-05 - activation_1_loss: 8.9630e-06 - activation_2_loss: 9.0092e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.6566e-05 - val_activation_1_loss: 9.9659e-06 - val_activation_2_loss: 4.6600e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4256e-04 - activation_1_loss: 2.8225e-05 - activation_2_loss: 1.1434e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.5408e-05 - val_activation_1_loss: 1.0129e-05 - val_activation_2_loss: 6.5279e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5211e-04 - activation_1_loss: 2.8695e-05 - activation_2_loss: 2.2342e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0014 - val_activation_1_loss: 6.4300e-04 - val_activation_2_loss: 7.5275e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3755e-04 - activation_1_loss: 3.2303e-05 - activation_2_loss: 1.0524e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0398e-04 - val_activation_1_loss: 1.2334e-05 - val_activation_2_loss: 1.9164e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9177e-04 - activation_1_loss: 2.0380e-05 - activation_2_loss: 1.7139e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0432e-04 - val_activation_1_loss: 3.6205e-06 - val_activation_2_loss: 2.0070e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0564e-04 - activation_1_loss: 5.6231e-06 - activation_2_loss: 2.0002e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0035e-04 - val_activation_1_loss: 5.6823e-06 - val_activation_2_loss: 9.4669e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1548e-04 - activation_1_loss: 4.3812e-06 - activation_2_loss: 1.1110e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4631e-04 - val_activation_1_loss: 4.7286e-06 - val_activation_2_loss: 1.4158e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.1168e-05 - activation_1_loss: 8.2915e-06 - activation_2_loss: 8.2876e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.3976e-05 - val_activation_1_loss: 1.2401e-05 - val_activation_2_loss: 8.1575e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0010 - activation_1_loss: 4.3365e-04 - activation_2_loss: 5.9632e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.3003e-04 - val_activation_1_loss: 3.4000e-04 - val_activation_2_loss: 4.9003e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3361e-05 - activation_1_loss: 8.3407e-06 - activation_2_loss: 4.5020e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1412e-04 - val_activation_1_loss: 3.8760e-06 - val_activation_2_loss: 3.1025e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2230e-04 - activation_1_loss: 6.3892e-06 - activation_2_loss: 1.1591e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3459e-05 - val_activation_1_loss: 1.5263e-06 - val_activation_2_loss: 3.1933e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3402e-05 - activation_1_loss: 2.6809e-06 - activation_2_loss: 5.0721e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0012 - val_activation_1_loss: 2.3115e-06 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0248e-04 - activation_1_loss: 3.1230e-06 - activation_2_loss: 9.9361e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7407e-04 - val_activation_1_loss: 1.2399e-06 - val_activation_2_loss: 3.7283e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8681e-04 - activation_1_loss: 1.5215e-04 - activation_2_loss: 3.4667e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3427e-04 - val_activation_1_loss: 5.5287e-06 - val_activation_2_loss: 1.2874e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4889e-04 - activation_1_loss: 1.9716e-04 - activation_2_loss: 3.5173e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.1136e-04 - val_activation_1_loss: 1.3318e-05 - val_activation_2_loss: 3.9804e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5971e-05 - activation_1_loss: 5.8500e-06 - activation_2_loss: 6.0121e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0114e-04 - val_activation_1_loss: 4.7335e-06 - val_activation_2_loss: 9.6402e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.0148e-05 - activation_1_loss: 1.4638e-05 - activation_2_loss: 7.5511e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.5619e-04 - val_activation_1_loss: 6.5880e-06 - val_activation_2_loss: 6.4960e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5001e-04 - activation_1_loss: 2.8825e-04 - activation_2_loss: 6.6176e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6412e-04 - val_activation_1_loss: 2.6734e-05 - val_activation_2_loss: 1.3738e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5797e-04 - activation_1_loss: 2.3743e-05 - activation_2_loss: 2.3422e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2062e-04 - val_activation_1_loss: 6.6658e-06 - val_activation_2_loss: 2.1396e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4481e-04 - activation_1_loss: 1.4315e-04 - activation_2_loss: 1.0165e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1469e-04 - val_activation_1_loss: 4.6744e-06 - val_activation_2_loss: 1.1001e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.5589e-05 - activation_1_loss: 1.5831e-05 - activation_2_loss: 5.9759e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1484e-05 - val_activation_1_loss: 2.8320e-06 - val_activation_2_loss: 4.8652e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4402e-05 - activation_1_loss: 4.1059e-06 - activation_2_loss: 5.0296e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5880e-05 - val_activation_1_loss: 3.0370e-06 - val_activation_2_loss: 4.2843e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2878e-05 - activation_1_loss: 4.3394e-06 - activation_2_loss: 6.8539e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.8683e-05 - val_activation_1_loss: 1.7911e-06 - val_activation_2_loss: 9.6892e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1215e-04 - activation_1_loss: 1.5735e-05 - activation_2_loss: 9.6412e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1107e-04 - val_activation_1_loss: 2.1020e-06 - val_activation_2_loss: 1.0897e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.1408e-05 - activation_1_loss: 2.1385e-06 - activation_2_loss: 7.9270e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5835e-05 - val_activation_1_loss: 3.8822e-06 - val_activation_2_loss: 2.1953e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2117e-05 - activation_1_loss: 2.3582e-06 - activation_2_loss: 2.9759e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.6406e-05 - val_activation_1_loss: 1.2619e-05 - val_activation_2_loss: 5.3788e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8297e-05 - activation_1_loss: 2.4385e-06 - activation_2_loss: 7.5859e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0011 - val_activation_1_loss: 8.5739e-04 - val_activation_2_loss: 1.9268e-04 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1093e-05 - activation_1_loss: 2.4791e-06 - activation_2_loss: 2.8614e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5036e-05 - val_activation_1_loss: 4.9522e-06 - val_activation_2_loss: 1.0084e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5502e-05 - activation_1_loss: 1.8819e-06 - activation_2_loss: 9.3620e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4510e-05 - val_activation_1_loss: 1.6546e-06 - val_activation_2_loss: 5.2855e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0734e-04 - activation_1_loss: 4.7616e-05 - activation_2_loss: 5.9728e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2579e-05 - val_activation_1_loss: 5.2399e-06 - val_activation_2_loss: 1.7339e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5634e-05 - activation_1_loss: 7.6675e-06 - activation_2_loss: 7.7966e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1752e-05 - val_activation_1_loss: 3.6363e-06 - val_activation_2_loss: 8.1153e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9102e-04 - activation_1_loss: 2.3567e-05 - activation_2_loss: 1.6745e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.4151e-06 - val_activation_1_loss: 3.2196e-06 - val_activation_2_loss: 4.1955e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4656e-04 - activation_1_loss: 1.0635e-05 - activation_2_loss: 1.3592e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5839e-05 - val_activation_1_loss: 5.1539e-06 - val_activation_2_loss: 1.0685e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.6787e-05 - activation_1_loss: 2.8187e-06 - activation_2_loss: 8.3969e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4136e-04 - val_activation_1_loss: 4.2158e-06 - val_activation_2_loss: 1.3714e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6719e-05 - activation_1_loss: 4.5102e-06 - activation_2_loss: 2.2209e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4961e-06 - val_activation_1_loss: 2.0043e-06 - val_activation_2_loss: 3.4918e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0187e-05 - activation_1_loss: 2.2841e-06 - activation_2_loss: 1.7903e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0544e-05 - val_activation_1_loss: 1.9584e-06 - val_activation_2_loss: 8.5856e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1347e-05 - activation_1_loss: 6.0223e-06 - activation_2_loss: 5.3252e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6692e-05 - val_activation_1_loss: 1.0105e-05 - val_activation_2_loss: 6.5868e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.4330e-06 - activation_1_loss: 3.6378e-06 - activation_2_loss: 5.7952e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0541e-06 - val_activation_1_loss: 2.8030e-06 - val_activation_2_loss: 3.2511e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5199e-05 - activation_1_loss: 4.2056e-06 - activation_2_loss: 1.0993e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9054e-05 - val_activation_1_loss: 9.3799e-06 - val_activation_2_loss: 1.9674e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0512e-06 - activation_1_loss: 1.5963e-06 - activation_2_loss: 3.4549e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1281e-06 - val_activation_1_loss: 1.2632e-06 - val_activation_2_loss: 2.8650e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7432e-05 - activation_1_loss: 1.0556e-05 - activation_2_loss: 1.6876e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.1119e-06 - val_activation_1_loss: 2.2626e-06 - val_activation_2_loss: 5.8492e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7099e-04 - activation_1_loss: 3.0068e-06 - activation_2_loss: 1.6798e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5498e-04 - val_activation_1_loss: 1.3904e-06 - val_activation_2_loss: 2.5359e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1550e-04 - activation_1_loss: 1.1834e-04 - activation_2_loss: 2.9716e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.4045e-05 - val_activation_1_loss: 8.5782e-06 - val_activation_2_loss: 6.5467e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3436e-04 - activation_1_loss: 7.7139e-06 - activation_2_loss: 1.2665e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2860e-04 - val_activation_1_loss: 1.1358e-05 - val_activation_2_loss: 2.1725e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7874e-04 - activation_1_loss: 1.3035e-05 - activation_2_loss: 1.6571e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1544e-04 - val_activation_1_loss: 4.1950e-06 - val_activation_2_loss: 1.1125e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0052e-05 - activation_1_loss: 4.2568e-06 - activation_2_loss: 7.5796e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9792e-05 - val_activation_1_loss: 3.4979e-06 - val_activation_2_loss: 1.6294e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6625e-05 - activation_1_loss: 3.5536e-06 - activation_2_loss: 2.3071e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9516e-05 - val_activation_1_loss: 1.3958e-06 - val_activation_2_loss: 4.8120e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3623e-04 - activation_1_loss: 3.9902e-06 - activation_2_loss: 1.3224e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1714e-04 - val_activation_1_loss: 1.5125e-06 - val_activation_2_loss: 1.1563e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3511e-05 - activation_1_loss: 2.6960e-06 - activation_2_loss: 4.0815e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4745e-05 - val_activation_1_loss: 1.3907e-06 - val_activation_2_loss: 5.3354e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.1811e-05 - activation_1_loss: 2.6798e-06 - activation_2_loss: 7.9131e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.8286e-05 - val_activation_1_loss: 4.0252e-06 - val_activation_2_loss: 3.4261e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7082e-04 - activation_1_loss: 2.3069e-04 - activation_2_loss: 1.4013e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9731e-05 - val_activation_1_loss: 2.1343e-05 - val_activation_2_loss: 1.8388e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3764e-04 - activation_1_loss: 1.0203e-05 - activation_2_loss: 1.2744e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3799e-04 - val_activation_1_loss: 6.8774e-06 - val_activation_2_loss: 1.3112e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.2717e-05 - activation_1_loss: 1.8174e-05 - activation_2_loss: 6.4542e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2322e-04 - val_activation_1_loss: 1.1580e-05 - val_activation_2_loss: 1.1164e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5009e-05 - activation_1_loss: 2.5216e-05 - activation_2_loss: 5.9793e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5011e-05 - val_activation_1_loss: 4.0465e-05 - val_activation_2_loss: 4.5465e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5261e-05 - activation_1_loss: 3.3507e-06 - activation_2_loss: 4.1910e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6982e-04 - val_activation_1_loss: 2.2961e-05 - val_activation_2_loss: 2.4686e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.3146e-06 - activation_1_loss: 2.3220e-06 - activation_2_loss: 6.9926e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2532e-05 - val_activation_1_loss: 2.1211e-06 - val_activation_2_loss: 1.0411e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5198e-05 - activation_1_loss: 3.4501e-06 - activation_2_loss: 1.1748e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9106e-05 - val_activation_1_loss: 1.6120e-06 - val_activation_2_loss: 7.7494e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9934e-05 - activation_1_loss: 9.1869e-06 - activation_2_loss: 4.0747e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2029e-04 - val_activation_1_loss: 9.5778e-05 - val_activation_2_loss: 2.4516e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2670e-04 - activation_1_loss: 1.0839e-04 - activation_2_loss: 1.8307e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2797e-04 - val_activation_1_loss: 9.5789e-05 - val_activation_2_loss: 3.2180e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.5800e-05 - activation_1_loss: 5.4377e-06 - activation_2_loss: 7.0362e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.8336e-05 - val_activation_1_loss: 1.0052e-05 - val_activation_2_loss: 7.8284e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.5611e-05 - activation_1_loss: 1.7999e-05 - activation_2_loss: 6.7612e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4687e-05 - val_activation_1_loss: 7.6091e-06 - val_activation_2_loss: 2.7078e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3529e-04 - activation_1_loss: 1.4126e-04 - activation_2_loss: 9.4029e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2363e-04 - val_activation_1_loss: 2.8606e-05 - val_activation_2_loss: 9.5023e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.6434e-05 - activation_1_loss: 1.2748e-05 - activation_2_loss: 8.3686e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2391e-04 - val_activation_1_loss: 3.1846e-06 - val_activation_2_loss: 1.2072e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5747e-04 - activation_1_loss: 1.9199e-04 - activation_2_loss: 6.5478e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9574e-05 - val_activation_1_loss: 3.1366e-06 - val_activation_2_loss: 3.6437e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2842e-04 - activation_1_loss: 8.0028e-06 - activation_2_loss: 1.2041e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6988e-04 - val_activation_1_loss: 2.2315e-06 - val_activation_2_loss: 1.6765e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.6021e-05 - activation_1_loss: 2.1669e-06 - activation_2_loss: 7.3854e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5153e-05 - val_activation_1_loss: 9.7415e-06 - val_activation_2_loss: 5.4111e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4176e-05 - activation_1_loss: 1.7827e-06 - activation_2_loss: 4.2393e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9155e-04 - val_activation_1_loss: 5.3328e-06 - val_activation_2_loss: 1.8621e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.8000e-05 - activation_1_loss: 8.2248e-06 - activation_2_loss: 7.9775e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2365e-05 - val_activation_1_loss: 1.2979e-06 - val_activation_2_loss: 2.1067e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2614e-05 - activation_1_loss: 2.2681e-05 - activation_2_loss: 4.9933e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7283e-05 - val_activation_1_loss: 1.3255e-06 - val_activation_2_loss: 1.5958e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1396e-05 - activation_1_loss: 1.9562e-06 - activation_2_loss: 1.9440e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1946e-05 - val_activation_1_loss: 3.9008e-06 - val_activation_2_loss: 2.8046e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2256e-05 - activation_1_loss: 3.6994e-06 - activation_2_loss: 8.5564e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4795e-05 - val_activation_1_loss: 1.4656e-06 - val_activation_2_loss: 1.3329e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1061e-04 - activation_1_loss: 2.1823e-06 - activation_2_loss: 1.0843e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1049e-06 - val_activation_1_loss: 1.0167e-06 - val_activation_2_loss: 3.0883e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2238e-04 - activation_1_loss: 2.1217e-06 - activation_2_loss: 1.2026e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0794e-04 - val_activation_1_loss: 3.8086e-06 - val_activation_2_loss: 2.0413e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1334e-04 - activation_1_loss: 7.8130e-06 - activation_2_loss: 2.0553e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.5383e-05 - val_activation_1_loss: 6.0594e-06 - val_activation_2_loss: 8.9324e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3379e-05 - activation_1_loss: 5.0682e-06 - activation_2_loss: 1.8311e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4952e-05 - val_activation_1_loss: 1.8523e-05 - val_activation_2_loss: 6.4289e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0845e-05 - activation_1_loss: 1.3513e-06 - activation_2_loss: 4.9493e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9791e-05 - val_activation_1_loss: 8.4405e-05 - val_activation_2_loss: 1.5387e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3908e-05 - activation_1_loss: 1.5708e-05 - activation_2_loss: 2.8200e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4754e-05 - val_activation_1_loss: 1.8927e-05 - val_activation_2_loss: 2.5826e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0198e-04 - activation_1_loss: 2.6982e-04 - activation_2_loss: 2.3216e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 8.4580e-04 - val_activation_1_loss: 3.8079e-04 - val_activation_2_loss: 4.6501e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3116e-04 - activation_1_loss: 1.3918e-05 - activation_2_loss: 1.1724e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8529e-05 - val_activation_1_loss: 2.9845e-05 - val_activation_2_loss: 3.8685e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.1066e-05 - activation_1_loss: 1.0564e-05 - activation_2_loss: 6.0502e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7825e-05 - val_activation_1_loss: 2.3348e-06 - val_activation_2_loss: 3.5490e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0744e-04 - activation_1_loss: 1.3220e-04 - activation_2_loss: 7.5244e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7749e-05 - val_activation_1_loss: 3.1424e-06 - val_activation_2_loss: 3.4607e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0905e-05 - activation_1_loss: 9.4742e-06 - activation_2_loss: 2.1431e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.0206e-06 - val_activation_1_loss: 2.6425e-06 - val_activation_2_loss: 5.3781e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0944e-05 - activation_1_loss: 1.2245e-05 - activation_2_loss: 8.6989e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8711e-06 - val_activation_1_loss: 1.8934e-06 - val_activation_2_loss: 4.9777e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.1246e-05 - activation_1_loss: 2.7522e-05 - activation_2_loss: 6.3724e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.6984e-05 - val_activation_1_loss: 4.3540e-06 - val_activation_2_loss: 6.2630e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0640e-05 - activation_1_loss: 5.7961e-06 - activation_2_loss: 2.4844e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2358e-05 - val_activation_1_loss: 1.1439e-05 - val_activation_2_loss: 1.0919e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8456e-05 - activation_1_loss: 6.3996e-06 - activation_2_loss: 4.2056e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4760e-05 - val_activation_1_loss: 1.6002e-06 - val_activation_2_loss: 4.3159e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1597e-04 - activation_1_loss: 1.9159e-05 - activation_2_loss: 1.9681e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.1442e-04 - val_activation_1_loss: 5.1039e-05 - val_activation_2_loss: 3.6338e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0185e-04 - activation_1_loss: 1.3324e-05 - activation_2_loss: 1.8853e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.2120e-05 - val_activation_1_loss: 8.6225e-06 - val_activation_2_loss: 5.3497e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9958e-05 - activation_1_loss: 1.9748e-05 - activation_2_loss: 5.0209e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0013e-04 - val_activation_1_loss: 1.3870e-05 - val_activation_2_loss: 1.8626e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3080e-04 - activation_1_loss: 5.9892e-06 - activation_2_loss: 1.2482e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2286e-05 - val_activation_1_loss: 5.6728e-06 - val_activation_2_loss: 6.6134e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6035e-04 - activation_1_loss: 1.6687e-05 - activation_2_loss: 1.4366e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1084e-04 - val_activation_1_loss: 2.5018e-06 - val_activation_2_loss: 1.0834e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6354e-05 - activation_1_loss: 8.1867e-06 - activation_2_loss: 5.8167e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3573e-05 - val_activation_1_loss: 2.7348e-05 - val_activation_2_loss: 6.2251e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7600e-04 - activation_1_loss: 4.7179e-06 - activation_2_loss: 2.7128e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.9930e-05 - val_activation_1_loss: 9.1731e-06 - val_activation_2_loss: 3.0757e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5114e-05 - activation_1_loss: 5.2965e-06 - activation_2_loss: 3.9818e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4669e-04 - val_activation_1_loss: 2.0559e-06 - val_activation_2_loss: 1.4464e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.2787e-05 - activation_1_loss: 2.2125e-06 - activation_2_loss: 9.0574e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8092e-05 - val_activation_1_loss: 1.9714e-06 - val_activation_2_loss: 1.6121e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8264e-04 - activation_1_loss: 1.3700e-04 - activation_2_loss: 4.5644e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3163e-05 - val_activation_1_loss: 5.0758e-05 - val_activation_2_loss: 2.2405e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5205e-06 - activation_1_loss: 1.6959e-06 - activation_2_loss: 7.8246e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.7521e-06 - val_activation_1_loss: 4.5800e-06 - val_activation_2_loss: 2.1722e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9085e-06 - activation_1_loss: 1.6109e-06 - activation_2_loss: 5.2976e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0947e-06 - val_activation_1_loss: 3.4707e-06 - val_activation_2_loss: 2.6240e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3676e-04 - activation_1_loss: 1.0662e-04 - activation_2_loss: 1.3014e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3602e-04 - val_activation_1_loss: 5.1721e-06 - val_activation_2_loss: 4.3085e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8782e-05 - activation_1_loss: 4.5828e-06 - activation_2_loss: 3.4199e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3499e-05 - val_activation_1_loss: 3.8118e-05 - val_activation_2_loss: 3.5381e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7247e-04 - activation_1_loss: 8.4269e-06 - activation_2_loss: 1.6404e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0012e-04 - val_activation_1_loss: 3.5756e-06 - val_activation_2_loss: 9.6547e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2680e-04 - activation_1_loss: 4.9498e-06 - activation_2_loss: 1.2185e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3173e-04 - val_activation_1_loss: 2.5770e-04 - val_activation_2_loss: 7.4028e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0362e-04 - activation_1_loss: 1.5421e-04 - activation_2_loss: 3.4941e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.7027e-04 - val_activation_1_loss: 9.6335e-06 - val_activation_2_loss: 1.6063e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.9261e-04 - activation_1_loss: 5.4037e-04 - activation_2_loss: 2.5224e-04 - activation_1_acc: 0.9999 - activation_2_acc: 1.0000 - val_loss: 9.8481e-05 - val_activation_1_loss: 8.4770e-06 - val_activation_2_loss: 9.0004e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.1037e-05 - activation_1_loss: 9.2513e-06 - activation_2_loss: 8.1786e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.1222e-05 - val_activation_1_loss: 2.9129e-05 - val_activation_2_loss: 3.2093e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2045e-04 - activation_1_loss: 6.1981e-06 - activation_2_loss: 1.1425e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.3672e-05 - val_activation_1_loss: 1.3532e-06 - val_activation_2_loss: 6.2319e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.9022e-04 - activation_1_loss: 2.6414e-04 - activation_2_loss: 3.2608e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.9333e-05 - val_activation_1_loss: 2.0919e-06 - val_activation_2_loss: 7.7241e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2505e-04 - activation_1_loss: 7.2468e-05 - activation_2_loss: 1.5259e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5761e-05 - val_activation_1_loss: 2.8157e-06 - val_activation_2_loss: 1.2946e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2393e-04 - activation_1_loss: 2.2659e-05 - activation_2_loss: 1.0127e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2723e-05 - val_activation_1_loss: 2.4650e-06 - val_activation_2_loss: 5.0258e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6468e-05 - activation_1_loss: 7.3991e-06 - activation_2_loss: 9.0687e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.2385e-05 - val_activation_1_loss: 4.2613e-05 - val_activation_2_loss: 9.7713e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2082e-05 - activation_1_loss: 3.0784e-06 - activation_2_loss: 3.9003e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4452e-04 - val_activation_1_loss: 1.9322e-06 - val_activation_2_loss: 1.4259e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0975e-05 - activation_1_loss: 2.0597e-06 - activation_2_loss: 2.8915e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7803e-05 - val_activation_1_loss: 1.6622e-06 - val_activation_2_loss: 2.6141e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8440e-05 - activation_1_loss: 2.1315e-06 - activation_2_loss: 6.6309e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1161e-04 - val_activation_1_loss: 5.7252e-06 - val_activation_2_loss: 1.0588e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.2555e-06 - activation_1_loss: 1.4329e-06 - activation_2_loss: 4.8226e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1180e-05 - val_activation_1_loss: 5.3020e-06 - val_activation_2_loss: 3.5878e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9594e-04 - activation_1_loss: 1.6640e-04 - activation_2_loss: 3.2955e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.6344e-05 - val_activation_1_loss: 3.6272e-06 - val_activation_2_loss: 4.2717e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6526e-04 - activation_1_loss: 7.5382e-05 - activation_2_loss: 8.9883e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4079e-04 - val_activation_1_loss: 1.2151e-05 - val_activation_2_loss: 1.2864e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.8765e-05 - activation_1_loss: 1.5024e-05 - activation_2_loss: 8.3741e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7497e-04 - val_activation_1_loss: 7.1592e-06 - val_activation_2_loss: 1.6781e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1319e-05 - activation_1_loss: 5.3753e-06 - activation_2_loss: 1.5944e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7360e-04 - val_activation_1_loss: 3.5339e-06 - val_activation_2_loss: 2.7006e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1347e-04 - activation_1_loss: 7.2134e-06 - activation_2_loss: 1.0625e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0268e-04 - val_activation_1_loss: 9.0713e-06 - val_activation_2_loss: 9.3608e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7335e-05 - activation_1_loss: 3.3684e-05 - activation_2_loss: 3.3651e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1439e-04 - val_activation_1_loss: 2.1660e-06 - val_activation_2_loss: 1.1222e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4471e-05 - activation_1_loss: 3.4113e-06 - activation_2_loss: 6.1060e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8230e-05 - val_activation_1_loss: 2.5475e-06 - val_activation_2_loss: 1.5682e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3134e-05 - activation_1_loss: 2.6318e-06 - activation_2_loss: 1.0502e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.0718e-06 - val_activation_1_loss: 2.9676e-06 - val_activation_2_loss: 4.1042e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0223e-05 - activation_1_loss: 3.4250e-06 - activation_2_loss: 2.6798e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7602e-05 - val_activation_1_loss: 3.4512e-06 - val_activation_2_loss: 1.4150e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.5115e-05 - activation_1_loss: 2.1606e-06 - activation_2_loss: 5.2955e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2409e-05 - val_activation_1_loss: 4.6985e-06 - val_activation_2_loss: 7.7100e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.6600e-04 - activation_1_loss: 8.6751e-06 - activation_2_loss: 4.5733e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5166e-04 - val_activation_1_loss: 5.4523e-06 - val_activation_2_loss: 1.4621e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6178e-04 - activation_1_loss: 3.4329e-06 - activation_2_loss: 1.5834e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.8926e-04 - val_activation_1_loss: 3.7194e-06 - val_activation_2_loss: 2.8554e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5746e-04 - activation_1_loss: 3.0880e-06 - activation_2_loss: 1.5437e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9716e-05 - val_activation_1_loss: 1.8314e-06 - val_activation_2_loss: 2.7885e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.3860e-05 - activation_1_loss: 9.5563e-06 - activation_2_loss: 4.4304e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9004e-05 - val_activation_1_loss: 8.9679e-06 - val_activation_2_loss: 2.0036e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2500e-04 - activation_1_loss: 4.2655e-06 - activation_2_loss: 2.2074e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8241e-04 - val_activation_1_loss: 4.9237e-06 - val_activation_2_loss: 1.7749e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3323e-04 - activation_1_loss: 1.8322e-05 - activation_2_loss: 2.1491e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 9.6565e-05 - val_activation_1_loss: 2.0523e-06 - val_activation_2_loss: 9.4512e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4151e-04 - activation_1_loss: 3.6392e-06 - activation_2_loss: 1.3787e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1325e-05 - val_activation_1_loss: 1.3312e-06 - val_activation_2_loss: 3.9994e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3862e-05 - activation_1_loss: 2.8691e-06 - activation_2_loss: 4.0993e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1261e-05 - val_activation_1_loss: 2.5308e-06 - val_activation_2_loss: 8.7305e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1319e-05 - activation_1_loss: 5.2083e-06 - activation_2_loss: 3.6111e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2319e-06 - val_activation_1_loss: 1.8046e-06 - val_activation_2_loss: 4.4273e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.2686e-05 - activation_1_loss: 4.5015e-06 - activation_2_loss: 8.8185e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4163e-04 - val_activation_1_loss: 1.0127e-06 - val_activation_2_loss: 1.4062e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.4937e-05 - activation_1_loss: 1.4508e-06 - activation_2_loss: 5.3487e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.1352e-05 - val_activation_1_loss: 1.5345e-06 - val_activation_2_loss: 5.9817e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3222e-04 - activation_1_loss: 1.6274e-04 - activation_2_loss: 1.6948e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3906e-05 - val_activation_1_loss: 1.8968e-06 - val_activation_2_loss: 1.2010e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4526e-05 - activation_1_loss: 1.1331e-05 - activation_2_loss: 1.3196e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7749e-05 - val_activation_1_loss: 1.0933e-05 - val_activation_2_loss: 6.8157e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2826e-05 - activation_1_loss: 2.6585e-05 - activation_2_loss: 4.6241e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2470e-05 - val_activation_1_loss: 5.4621e-06 - val_activation_2_loss: 1.7008e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8179e-04 - activation_1_loss: 2.3018e-05 - activation_2_loss: 1.5877e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4225e-04 - val_activation_1_loss: 1.1438e-05 - val_activation_2_loss: 1.3082e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0011 - activation_1_loss: 6.3400e-04 - activation_2_loss: 4.7723e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 2.4097e-04 - val_activation_1_loss: 1.6580e-04 - val_activation_2_loss: 7.5169e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0532e-04 - activation_1_loss: 4.1861e-05 - activation_2_loss: 1.6346e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.1405e-04 - val_activation_1_loss: 6.1314e-06 - val_activation_2_loss: 1.0792e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4250e-04 - activation_1_loss: 8.6620e-06 - activation_2_loss: 1.3384e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.4966e-04 - val_activation_1_loss: 6.6654e-06 - val_activation_2_loss: 1.4299e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.5868e-05 - activation_1_loss: 4.4408e-06 - activation_2_loss: 5.1427e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0475e-05 - val_activation_1_loss: 2.1159e-06 - val_activation_2_loss: 1.8359e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.5997e-05 - activation_1_loss: 4.2171e-06 - activation_2_loss: 5.1780e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9810e-04 - val_activation_1_loss: 9.9928e-05 - val_activation_2_loss: 9.8167e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5756e-05 - activation_1_loss: 6.8890e-06 - activation_2_loss: 2.8867e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1651e-04 - val_activation_1_loss: 1.4530e-04 - val_activation_2_loss: 7.1219e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2288e-05 - activation_1_loss: 3.2507e-06 - activation_2_loss: 1.9038e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4911e-05 - val_activation_1_loss: 6.6135e-06 - val_activation_2_loss: 1.8297e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3799e-04 - activation_1_loss: 8.4880e-05 - activation_2_loss: 5.3108e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0366e-04 - val_activation_1_loss: 4.7922e-06 - val_activation_2_loss: 9.8869e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7700e-04 - activation_1_loss: 1.6583e-04 - activation_2_loss: 5.1117e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.0266e-05 - val_activation_1_loss: 3.3784e-06 - val_activation_2_loss: 5.6887e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6083e-04 - activation_1_loss: 2.9096e-05 - activation_2_loss: 1.3174e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1951e-05 - val_activation_1_loss: 5.2345e-06 - val_activation_2_loss: 2.6717e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.2246e-05 - activation_1_loss: 1.4917e-05 - activation_2_loss: 6.7329e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8738e-04 - val_activation_1_loss: 6.0615e-06 - val_activation_2_loss: 1.8132e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5551e-05 - activation_1_loss: 1.8828e-05 - activation_2_loss: 4.6723e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.9192e-06 - val_activation_1_loss: 2.0674e-06 - val_activation_2_loss: 5.8518e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1448e-04 - activation_1_loss: 1.9532e-05 - activation_2_loss: 9.4949e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1483e-04 - val_activation_1_loss: 7.0521e-05 - val_activation_2_loss: 4.4312e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1978e-05 - activation_1_loss: 2.0245e-05 - activation_2_loss: 4.1733e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2758e-05 - val_activation_1_loss: 2.8217e-06 - val_activation_2_loss: 3.9937e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.4399e-05 - activation_1_loss: 7.9376e-06 - activation_2_loss: 6.6462e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6678e-05 - val_activation_1_loss: 2.8623e-06 - val_activation_2_loss: 2.3816e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4291e-04 - activation_1_loss: 1.4504e-05 - activation_2_loss: 1.2841e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0597e-05 - val_activation_1_loss: 1.0765e-05 - val_activation_2_loss: 2.9832e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8285e-05 - activation_1_loss: 9.2117e-06 - activation_2_loss: 5.9073e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9854e-05 - val_activation_1_loss: 4.5562e-06 - val_activation_2_loss: 8.5298e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9643e-05 - activation_1_loss: 2.7455e-06 - activation_2_loss: 4.6897e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7634e-05 - val_activation_1_loss: 3.9044e-06 - val_activation_2_loss: 5.3729e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0107e-05 - activation_1_loss: 6.8737e-06 - activation_2_loss: 7.3233e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7979e-04 - val_activation_1_loss: 1.9598e-05 - val_activation_2_loss: 3.6019e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1063e-05 - activation_1_loss: 3.0340e-06 - activation_2_loss: 3.8029e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4207e-05 - val_activation_1_loss: 3.4899e-06 - val_activation_2_loss: 2.0717e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1370e-04 - activation_1_loss: 2.8011e-05 - activation_2_loss: 8.5688e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.6700e-06 - val_activation_1_loss: 3.9238e-06 - val_activation_2_loss: 5.7461e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1839e-04 - activation_1_loss: 8.5017e-06 - activation_2_loss: 1.0989e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3657e-04 - val_activation_1_loss: 1.5837e-06 - val_activation_2_loss: 4.3499e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7161e-05 - activation_1_loss: 2.9009e-06 - activation_2_loss: 1.4260e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2909e-06 - val_activation_1_loss: 3.1798e-06 - val_activation_2_loss: 3.1111e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2458e-04 - activation_1_loss: 4.2604e-06 - activation_2_loss: 1.2032e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.1004e-05 - val_activation_1_loss: 2.7344e-06 - val_activation_2_loss: 4.8270e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4511e-04 - activation_1_loss: 5.2289e-06 - activation_2_loss: 1.3988e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.6695e-05 - val_activation_1_loss: 5.0045e-06 - val_activation_2_loss: 4.1691e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3593e-05 - activation_1_loss: 2.7696e-06 - activation_2_loss: 3.0823e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4306e-05 - val_activation_1_loss: 2.3670e-05 - val_activation_2_loss: 4.0636e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.4904e-04 - activation_1_loss: 2.1200e-06 - activation_2_loss: 1.4692e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1449e-04 - val_activation_1_loss: 7.7640e-05 - val_activation_2_loss: 3.6847e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5000e-05 - activation_1_loss: 1.5872e-05 - activation_2_loss: 1.9128e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4434e-04 - val_activation_1_loss: 4.0296e-05 - val_activation_2_loss: 1.0404e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7880e-05 - activation_1_loss: 2.0290e-06 - activation_2_loss: 3.5851e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4784e-05 - val_activation_1_loss: 1.7180e-06 - val_activation_2_loss: 6.3066e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1997e-05 - activation_1_loss: 2.1906e-06 - activation_2_loss: 5.9807e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0031 - val_activation_1_loss: 0.0015 - val_activation_2_loss: 0.0016 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.9821e-05 - activation_1_loss: 2.6475e-06 - activation_2_loss: 9.7173e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.0750e-04 - val_activation_1_loss: 5.2983e-05 - val_activation_2_loss: 4.5452e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2503e-04 - activation_1_loss: 5.0639e-06 - activation_2_loss: 2.1997e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6650e-05 - val_activation_1_loss: 1.7456e-06 - val_activation_2_loss: 1.4905e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0903e-04 - activation_1_loss: 1.2043e-04 - activation_2_loss: 8.8599e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5472e-04 - val_activation_1_loss: 6.3463e-05 - val_activation_2_loss: 9.1258e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.8176e-05 - activation_1_loss: 2.3187e-06 - activation_2_loss: 6.5857e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2800e-05 - val_activation_1_loss: 2.3184e-06 - val_activation_2_loss: 1.0481e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1687e-04 - activation_1_loss: 1.7776e-06 - activation_2_loss: 1.1509e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4491e-05 - val_activation_1_loss: 2.0331e-06 - val_activation_2_loss: 6.2458e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6994e-04 - activation_1_loss: 4.1432e-06 - activation_2_loss: 1.6580e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7632e-04 - val_activation_1_loss: 1.8302e-05 - val_activation_2_loss: 3.5802e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6510e-04 - activation_1_loss: 9.0524e-05 - activation_2_loss: 1.7457e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.0312e-05 - val_activation_1_loss: 3.1202e-05 - val_activation_2_loss: 5.9110e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9992e-04 - activation_1_loss: 1.0670e-04 - activation_2_loss: 9.3221e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1728e-05 - val_activation_1_loss: 3.1672e-05 - val_activation_2_loss: 4.0056e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2536e-04 - activation_1_loss: 5.0446e-05 - activation_2_loss: 7.4916e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9320e-06 - val_activation_1_loss: 4.4346e-06 - val_activation_2_loss: 5.4974e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2818e-04 - activation_1_loss: 2.7216e-04 - activation_2_loss: 5.6022e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8941e-05 - val_activation_1_loss: 2.0254e-06 - val_activation_2_loss: 6.6915e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5475e-05 - activation_1_loss: 2.3539e-05 - activation_2_loss: 2.1936e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3026e-05 - val_activation_1_loss: 3.0661e-06 - val_activation_2_loss: 3.9960e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.2212e-05 - activation_1_loss: 7.1207e-06 - activation_2_loss: 6.5091e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4909e-06 - val_activation_1_loss: 1.3728e-06 - val_activation_2_loss: 3.1181e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3177e-05 - activation_1_loss: 4.3275e-06 - activation_2_loss: 2.8850e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3238e-05 - val_activation_1_loss: 1.7388e-06 - val_activation_2_loss: 3.1499e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.9306e-06 - activation_1_loss: 2.0176e-06 - activation_2_loss: 4.9130e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0484e-05 - val_activation_1_loss: 3.3458e-06 - val_activation_2_loss: 7.1383e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.0169e-05 - activation_1_loss: 1.5311e-06 - activation_2_loss: 6.8638e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1087e-05 - val_activation_1_loss: 1.4736e-06 - val_activation_2_loss: 1.9613e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.1607e-05 - activation_1_loss: 2.3228e-05 - activation_2_loss: 1.8380e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5306e-06 - val_activation_1_loss: 1.4528e-06 - val_activation_2_loss: 3.0778e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0503e-04 - activation_1_loss: 4.9751e-06 - activation_2_loss: 1.0006e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7141e-05 - val_activation_1_loss: 1.8911e-06 - val_activation_2_loss: 3.5250e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6813e-04 - activation_1_loss: 1.1783e-05 - activation_2_loss: 1.5635e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.6004e-04 - val_activation_1_loss: 5.2029e-05 - val_activation_2_loss: 1.0801e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9092e-04 - activation_1_loss: 2.5760e-05 - activation_2_loss: 1.6516e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 4.5493e-04 - val_activation_1_loss: 3.0075e-04 - val_activation_2_loss: 1.5418e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1368e-05 - activation_1_loss: 3.6803e-06 - activation_2_loss: 5.7688e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8145e-05 - val_activation_1_loss: 3.7833e-06 - val_activation_2_loss: 4.4362e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5009e-05 - activation_1_loss: 6.9178e-06 - activation_2_loss: 3.8091e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0691e-05 - val_activation_1_loss: 5.6742e-06 - val_activation_2_loss: 5.0169e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5619e-05 - activation_1_loss: 2.3513e-06 - activation_2_loss: 1.3268e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3261e-05 - val_activation_1_loss: 4.9290e-06 - val_activation_2_loss: 8.3323e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0214e-06 - activation_1_loss: 1.6322e-06 - activation_2_loss: 3.3893e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9462e-05 - val_activation_1_loss: 1.4807e-05 - val_activation_2_loss: 4.6557e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.0420e-05 - activation_1_loss: 3.6696e-06 - activation_2_loss: 6.6750e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0307e-06 - val_activation_1_loss: 1.4611e-06 - val_activation_2_loss: 4.5697e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5940e-04 - activation_1_loss: 1.2067e-04 - activation_2_loss: 1.3872e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.4292e-04 - val_activation_1_loss: 7.6290e-05 - val_activation_2_loss: 6.6663e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.7820e-05 - activation_1_loss: 2.4457e-05 - activation_2_loss: 5.3363e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0016 - val_activation_1_loss: 4.1638e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5122e-04 - activation_1_loss: 1.8196e-05 - activation_2_loss: 4.3302e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 7.6300e-05 - val_activation_1_loss: 3.0286e-06 - val_activation_2_loss: 7.3271e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3679e-04 - activation_1_loss: 1.3663e-04 - activation_2_loss: 2.0016e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3004e-04 - val_activation_1_loss: 6.5104e-06 - val_activation_2_loss: 1.2353e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3429e-04 - activation_1_loss: 3.8347e-06 - activation_2_loss: 1.3045e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.6292e-05 - val_activation_1_loss: 2.0570e-05 - val_activation_2_loss: 4.5723e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7831e-05 - activation_1_loss: 8.5110e-06 - activation_2_loss: 7.9320e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6459e-04 - val_activation_1_loss: 4.9823e-06 - val_activation_2_loss: 1.5961e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6414e-04 - activation_1_loss: 9.7442e-05 - activation_2_loss: 1.6669e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4285e-04 - val_activation_1_loss: 6.6664e-05 - val_activation_2_loss: 7.6189e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.1772e-04 - activation_1_loss: 2.1778e-04 - activation_2_loss: 9.9938e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.8567e-05 - val_activation_1_loss: 1.6487e-06 - val_activation_2_loss: 4.6918e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7874e-05 - activation_1_loss: 1.8181e-05 - activation_2_loss: 6.9693e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5336e-05 - val_activation_1_loss: 5.5976e-06 - val_activation_2_loss: 2.9738e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5770e-05 - activation_1_loss: 1.9609e-06 - activation_2_loss: 1.3809e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7897e-05 - val_activation_1_loss: 1.7357e-06 - val_activation_2_loss: 3.6161e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4826e-05 - activation_1_loss: 1.9688e-06 - activation_2_loss: 2.2857e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.7127e-05 - val_activation_1_loss: 1.7353e-05 - val_activation_2_loss: 2.9774e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6899e-04 - activation_1_loss: 2.3905e-05 - activation_2_loss: 1.4508e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.4023e-04 - val_activation_1_loss: 1.2411e-05 - val_activation_2_loss: 5.2782e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9343e-04 - activation_1_loss: 2.8230e-05 - activation_2_loss: 2.6520e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.6711e-04 - val_activation_1_loss: 1.7273e-05 - val_activation_2_loss: 2.4984e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6016e-04 - activation_1_loss: 2.5080e-05 - activation_2_loss: 2.3508e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.3216e-04 - val_activation_1_loss: 2.2214e-06 - val_activation_2_loss: 3.2994e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.8082e-05 - activation_1_loss: 3.2892e-06 - activation_2_loss: 9.4793e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0378e-04 - val_activation_1_loss: 5.6190e-06 - val_activation_2_loss: 9.8164e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.9135e-05 - activation_1_loss: 8.3085e-06 - activation_2_loss: 8.0827e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5952e-05 - val_activation_1_loss: 6.2826e-06 - val_activation_2_loss: 2.9669e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5742e-05 - activation_1_loss: 3.7830e-06 - activation_2_loss: 3.1959e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3211e-05 - val_activation_1_loss: 1.0293e-05 - val_activation_2_loss: 4.2918e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.3180e-05 - activation_1_loss: 1.2941e-05 - activation_2_loss: 8.0238e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5346e-05 - val_activation_1_loss: 1.7052e-06 - val_activation_2_loss: 1.3641e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8918e-05 - activation_1_loss: 1.3327e-05 - activation_2_loss: 6.5592e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3677e-04 - val_activation_1_loss: 1.2705e-06 - val_activation_2_loss: 1.3550e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4209e-05 - activation_1_loss: 3.3424e-06 - activation_2_loss: 2.0867e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8021e-06 - val_activation_1_loss: 2.8758e-06 - val_activation_2_loss: 3.9263e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.9038e-05 - activation_1_loss: 6.8477e-06 - activation_2_loss: 4.2190e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6300e-05 - val_activation_1_loss: 4.5078e-06 - val_activation_2_loss: 1.1793e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0576e-04 - activation_1_loss: 3.0784e-05 - activation_2_loss: 7.4977e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0885e-05 - val_activation_1_loss: 5.9339e-06 - val_activation_2_loss: 4.9509e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2373e-04 - activation_1_loss: 5.0584e-06 - activation_2_loss: 1.1867e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9454e-05 - val_activation_1_loss: 2.5746e-06 - val_activation_2_loss: 8.6880e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4713e-05 - activation_1_loss: 4.4863e-06 - activation_2_loss: 4.0227e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.8645e-05 - val_activation_1_loss: 5.8941e-06 - val_activation_2_loss: 3.2751e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7377e-05 - activation_1_loss: 2.0773e-06 - activation_2_loss: 3.5299e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4340e-05 - val_activation_1_loss: 1.8025e-06 - val_activation_2_loss: 1.2537e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0458e-05 - activation_1_loss: 2.1672e-06 - activation_2_loss: 8.2905e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.2747e-05 - val_activation_1_loss: 1.3758e-06 - val_activation_2_loss: 3.1371e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4882e-05 - activation_1_loss: 4.8875e-06 - activation_2_loss: 7.9994e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.2979e-05 - val_activation_1_loss: 1.6978e-06 - val_activation_2_loss: 2.1281e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0126e-05 - activation_1_loss: 1.2314e-05 - activation_2_loss: 3.7812e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2974e-05 - val_activation_1_loss: 2.5245e-06 - val_activation_2_loss: 4.0450e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0118e-05 - activation_1_loss: 3.0112e-06 - activation_2_loss: 1.7107e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0513e-04 - val_activation_1_loss: 4.1560e-05 - val_activation_2_loss: 3.6357e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8638e-06 - activation_1_loss: 1.3772e-06 - activation_2_loss: 3.4866e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5781e-06 - val_activation_1_loss: 7.3080e-07 - val_activation_2_loss: 2.8473e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0066e-04 - activation_1_loss: 1.7215e-05 - activation_2_loss: 1.8345e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.5990e-04 - val_activation_1_loss: 3.5474e-06 - val_activation_2_loss: 1.5635e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.0374e-04 - activation_1_loss: 3.3375e-05 - activation_2_loss: 2.7036e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0632e-04 - val_activation_1_loss: 6.7764e-06 - val_activation_2_loss: 9.9547e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.5745e-04 - activation_1_loss: 3.1386e-04 - activation_2_loss: 3.4358e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 2.1827e-04 - val_activation_1_loss: 3.2000e-05 - val_activation_2_loss: 1.8627e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2215e-04 - activation_1_loss: 2.7421e-05 - activation_2_loss: 9.4730e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9050e-04 - val_activation_1_loss: 6.7849e-06 - val_activation_2_loss: 1.8371e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3187e-04 - activation_1_loss: 2.6153e-05 - activation_2_loss: 1.0572e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6462e-04 - val_activation_1_loss: 1.0940e-05 - val_activation_2_loss: 1.5368e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.7636e-05 - activation_1_loss: 9.3027e-06 - activation_2_loss: 3.8333e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.1920e-05 - val_activation_1_loss: 7.4368e-06 - val_activation_2_loss: 1.4483e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.6708e-05 - activation_1_loss: 1.8507e-06 - activation_2_loss: 6.4857e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.8584e-05 - val_activation_1_loss: 1.8119e-05 - val_activation_2_loss: 6.0465e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7162e-05 - activation_1_loss: 4.8137e-06 - activation_2_loss: 3.2348e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4875e-05 - val_activation_1_loss: 3.8016e-06 - val_activation_2_loss: 1.1073e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9981e-05 - activation_1_loss: 4.7008e-06 - activation_2_loss: 1.5280e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.5232e-05 - val_activation_1_loss: 5.9151e-06 - val_activation_2_loss: 9.3166e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.7783e-05 - activation_1_loss: 4.9699e-06 - activation_2_loss: 3.2813e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3502e-05 - val_activation_1_loss: 8.8693e-07 - val_activation_2_loss: 1.2615e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.7413e-05 - activation_1_loss: 3.8419e-05 - activation_2_loss: 1.8995e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.0533e-06 - val_activation_1_loss: 4.8081e-06 - val_activation_2_loss: 1.2452e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.6232e-06 - activation_1_loss: 1.2204e-06 - activation_2_loss: 4.4028e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9033e-06 - val_activation_1_loss: 1.2164e-06 - val_activation_2_loss: 1.6869e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.6950e-05 - activation_1_loss: 1.0610e-06 - activation_2_loss: 4.5889e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.4475e-05 - val_activation_1_loss: 2.0256e-06 - val_activation_2_loss: 3.2450e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.2837e-05 - activation_1_loss: 2.1513e-06 - activation_2_loss: 3.0686e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4452e-04 - val_activation_1_loss: 8.3132e-05 - val_activation_2_loss: 1.6139e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7175e-04 - activation_1_loss: 3.8610e-05 - activation_2_loss: 1.3314e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5477e-05 - val_activation_1_loss: 9.8239e-06 - val_activation_2_loss: 3.5653e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9012e-04 - activation_1_loss: 1.7342e-04 - activation_2_loss: 2.1670e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.9269e-05 - val_activation_1_loss: 1.7017e-06 - val_activation_2_loss: 6.7568e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5027e-04 - activation_1_loss: 1.7373e-04 - activation_2_loss: 1.7654e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.1601e-04 - val_activation_1_loss: 1.6162e-04 - val_activation_2_loss: 2.5439e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8561e-04 - activation_1_loss: 3.6262e-05 - activation_2_loss: 1.4935e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4809e-04 - val_activation_1_loss: 2.7573e-06 - val_activation_2_loss: 1.4533e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4095e-05 - activation_1_loss: 7.0076e-06 - activation_2_loss: 1.7087e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2647e-05 - val_activation_1_loss: 1.4336e-06 - val_activation_2_loss: 1.1213e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5393e-04 - activation_1_loss: 5.2895e-05 - activation_2_loss: 1.0104e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7014e-05 - val_activation_1_loss: 2.6782e-06 - val_activation_2_loss: 2.4336e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0704e-04 - activation_1_loss: 2.1475e-06 - activation_2_loss: 2.0489e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 6.9464e-05 - val_activation_1_loss: 1.9719e-06 - val_activation_2_loss: 6.7492e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.3150e-05 - activation_1_loss: 1.6121e-05 - activation_2_loss: 2.7029e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.7532e-05 - val_activation_1_loss: 1.0705e-05 - val_activation_2_loss: 4.6827e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8059e-05 - activation_1_loss: 1.3574e-05 - activation_2_loss: 6.4485e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.9371e-05 - val_activation_1_loss: 2.8823e-05 - val_activation_2_loss: 4.0548e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.4504e-05 - activation_1_loss: 2.2218e-06 - activation_2_loss: 8.2283e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.3638e-06 - val_activation_1_loss: 1.3188e-06 - val_activation_2_loss: 7.0449e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3787e-05 - activation_1_loss: 1.7166e-06 - activation_2_loss: 2.2071e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8677e-04 - val_activation_1_loss: 9.1757e-07 - val_activation_2_loss: 1.8585e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.3523e-06 - activation_1_loss: 3.5619e-06 - activation_2_loss: 5.7904e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9394e-06 - val_activation_1_loss: 1.7209e-06 - val_activation_2_loss: 3.2186e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8864e-04 - activation_1_loss: 5.0664e-05 - activation_2_loss: 1.3798e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4378e-04 - val_activation_1_loss: 6.2708e-04 - val_activation_2_loss: 1.6699e-05 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5571e-04 - activation_1_loss: 1.0293e-04 - activation_2_loss: 5.2782e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3948e-05 - val_activation_1_loss: 3.6840e-05 - val_activation_2_loss: 7.1077e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5639e-04 - activation_1_loss: 1.4708e-04 - activation_2_loss: 9.3099e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4708e-05 - val_activation_1_loss: 1.4997e-06 - val_activation_2_loss: 1.3208e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9097e-04 - activation_1_loss: 1.4845e-04 - activation_2_loss: 4.2515e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7823e-05 - val_activation_1_loss: 3.3490e-06 - val_activation_2_loss: 1.4474e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.5189e-04 - activation_1_loss: 8.3999e-05 - activation_2_loss: 2.6789e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.4929e-05 - val_activation_1_loss: 8.9026e-06 - val_activation_2_loss: 5.6026e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.4341e-05 - activation_1_loss: 3.6518e-06 - activation_2_loss: 6.0690e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9714e-04 - val_activation_1_loss: 2.8728e-05 - val_activation_2_loss: 2.6841e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.9276e-04 - activation_1_loss: 1.6088e-05 - activation_2_loss: 1.7668e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.2335e-05 - val_activation_1_loss: 1.8483e-06 - val_activation_2_loss: 4.0487e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3467e-04 - activation_1_loss: 3.5757e-05 - activation_2_loss: 9.8917e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.0627e-05 - val_activation_1_loss: 4.0960e-06 - val_activation_2_loss: 6.6531e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.9122e-05 - activation_1_loss: 4.0809e-06 - activation_2_loss: 3.5041e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0856e-04 - val_activation_1_loss: 9.8355e-06 - val_activation_2_loss: 1.9872e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3857e-04 - activation_1_loss: 1.3291e-05 - activation_2_loss: 1.2528e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4891e-05 - val_activation_1_loss: 2.0641e-06 - val_activation_2_loss: 2.2826e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.0926e-05 - activation_1_loss: 9.3418e-06 - activation_2_loss: 5.1584e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.0780e-04 - val_activation_1_loss: 1.1716e-05 - val_activation_2_loss: 3.9609e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.0277e-05 - activation_1_loss: 2.1450e-06 - activation_2_loss: 1.8132e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9602e-05 - val_activation_1_loss: 1.8072e-05 - val_activation_2_loss: 1.5300e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.2285e-05 - activation_1_loss: 9.1599e-06 - activation_2_loss: 4.3126e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5943e-04 - val_activation_1_loss: 2.9810e-06 - val_activation_2_loss: 2.5645e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.5474e-05 - activation_1_loss: 2.3945e-06 - activation_2_loss: 4.3079e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.4419e-05 - val_activation_1_loss: 2.6933e-06 - val_activation_2_loss: 1.1726e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.8326e-05 - activation_1_loss: 2.1022e-06 - activation_2_loss: 2.6223e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 0.0014 - val_activation_1_loss: 2.9121e-04 - val_activation_2_loss: 0.0011 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9998\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8507e-04 - activation_1_loss: 1.4129e-04 - activation_2_loss: 2.4378e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.4076e-05 - val_activation_1_loss: 5.7672e-06 - val_activation_2_loss: 3.8308e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.0521e-05 - activation_1_loss: 1.0978e-05 - activation_2_loss: 2.9543e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1906e-05 - val_activation_1_loss: 2.2109e-06 - val_activation_2_loss: 9.6952e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8615e-05 - activation_1_loss: 2.6466e-06 - activation_2_loss: 1.5968e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.3865e-05 - val_activation_1_loss: 1.2851e-06 - val_activation_2_loss: 9.2580e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.6423e-05 - activation_1_loss: 2.8522e-06 - activation_2_loss: 9.3571e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6872e-05 - val_activation_1_loss: 2.5582e-06 - val_activation_2_loss: 1.4314e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2513e-05 - activation_1_loss: 3.5218e-06 - activation_2_loss: 1.8991e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0459e-05 - val_activation_1_loss: 1.1722e-06 - val_activation_2_loss: 9.2868e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3213e-04 - activation_1_loss: 2.5526e-06 - activation_2_loss: 1.2957e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0554e-05 - val_activation_1_loss: 1.1864e-06 - val_activation_2_loss: 9.3676e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7136e-05 - activation_1_loss: 1.4912e-06 - activation_2_loss: 1.5644e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9241e-04 - val_activation_1_loss: 1.9940e-06 - val_activation_2_loss: 1.9042e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2123e-04 - activation_1_loss: 2.1998e-06 - activation_2_loss: 2.1903e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9690e-04 - val_activation_1_loss: 4.6260e-04 - val_activation_2_loss: 4.3430e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1319e-04 - activation_1_loss: 1.5626e-06 - activation_2_loss: 1.1162e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2752e-05 - val_activation_1_loss: 2.0627e-06 - val_activation_2_loss: 6.0690e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.5666e-04 - activation_1_loss: 1.5963e-05 - activation_2_loss: 1.4069e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.9006e-05 - val_activation_1_loss: 1.5284e-05 - val_activation_2_loss: 1.3722e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1254e-05 - activation_1_loss: 3.7072e-06 - activation_2_loss: 5.7546e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.9119e-05 - val_activation_1_loss: 1.3791e-05 - val_activation_2_loss: 3.5328e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.3794e-05 - activation_1_loss: 6.5693e-05 - activation_2_loss: 2.8101e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7873e-05 - val_activation_1_loss: 4.7325e-06 - val_activation_2_loss: 1.3141e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9973e-04 - activation_1_loss: 1.2078e-04 - activation_2_loss: 1.7895e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8053e-05 - val_activation_1_loss: 6.5510e-06 - val_activation_2_loss: 1.1502e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.0669e-05 - activation_1_loss: 7.0101e-06 - activation_2_loss: 8.3659e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.8482e-05 - val_activation_1_loss: 4.3188e-06 - val_activation_2_loss: 6.4163e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0838e-04 - activation_1_loss: 8.8410e-06 - activation_2_loss: 9.9543e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.0455e-05 - val_activation_1_loss: 2.9609e-06 - val_activation_2_loss: 1.7494e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2209e-05 - activation_1_loss: 8.4068e-06 - activation_2_loss: 1.3802e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6784e-05 - val_activation_1_loss: 1.2681e-06 - val_activation_2_loss: 2.5516e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.3182e-05 - activation_1_loss: 2.0683e-06 - activation_2_loss: 2.1113e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1330e-04 - val_activation_1_loss: 1.6789e-06 - val_activation_2_loss: 1.1162e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.0964e-05 - activation_1_loss: 1.7793e-06 - activation_2_loss: 3.9185e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.3346e-06 - val_activation_1_loss: 2.7766e-06 - val_activation_2_loss: 2.5580e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.0487e-05 - activation_1_loss: 3.8268e-06 - activation_2_loss: 4.6661e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.9744e-05 - val_activation_1_loss: 2.1343e-06 - val_activation_2_loss: 1.7610e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.4162e-05 - activation_1_loss: 3.5858e-06 - activation_2_loss: 7.0577e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3808e-05 - val_activation_1_loss: 2.6040e-06 - val_activation_2_loss: 2.1204e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3187e-04 - activation_1_loss: 1.1955e-05 - activation_2_loss: 1.1992e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.3201e-05 - val_activation_1_loss: 1.3324e-05 - val_activation_2_loss: 1.9877e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.6581e-05 - activation_1_loss: 7.5115e-06 - activation_2_loss: 3.9069e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7186e-05 - val_activation_1_loss: 3.1128e-06 - val_activation_2_loss: 2.4073e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1523e-04 - activation_1_loss: 2.4143e-06 - activation_2_loss: 1.1281e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2762e-04 - val_activation_1_loss: 9.2021e-06 - val_activation_2_loss: 1.1841e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 5.1757e-05 - activation_1_loss: 1.7281e-06 - activation_2_loss: 5.0029e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.7523e-04 - val_activation_1_loss: 3.3221e-05 - val_activation_2_loss: 4.4200e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1622e-05 - activation_1_loss: 1.9695e-06 - activation_2_loss: 1.9652e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.3966e-04 - val_activation_1_loss: 1.3345e-04 - val_activation_2_loss: 6.2113e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.1715e-05 - activation_1_loss: 2.0389e-06 - activation_2_loss: 1.9676e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6710e-05 - val_activation_1_loss: 3.5495e-06 - val_activation_2_loss: 1.3160e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6075e-04 - activation_1_loss: 2.6536e-06 - activation_2_loss: 1.5810e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.3241e-05 - val_activation_1_loss: 1.7298e-06 - val_activation_2_loss: 4.1511e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8914e-05 - activation_1_loss: 1.1741e-05 - activation_2_loss: 2.7174e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.7620e-05 - val_activation_1_loss: 9.1961e-07 - val_activation_2_loss: 1.6701e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.7252e-04 - activation_1_loss: 2.0755e-06 - activation_2_loss: 1.7045e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.7250e-04 - val_activation_1_loss: 2.6640e-06 - val_activation_2_loss: 2.6984e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.4436e-04 - activation_1_loss: 7.8764e-05 - activation_2_loss: 2.6559e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2200e-05 - val_activation_1_loss: 4.4127e-06 - val_activation_2_loss: 5.7788e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3750e-04 - activation_1_loss: 6.7448e-05 - activation_2_loss: 7.0054e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.0884e-04 - val_activation_1_loss: 2.0914e-05 - val_activation_2_loss: 2.8792e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0077e-04 - activation_1_loss: 4.2484e-06 - activation_2_loss: 9.6522e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.7979e-05 - val_activation_1_loss: 1.1630e-05 - val_activation_2_loss: 2.6350e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.7872e-05 - activation_1_loss: 1.1963e-05 - activation_2_loss: 1.5909e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.2604e-05 - val_activation_1_loss: 1.9561e-06 - val_activation_2_loss: 8.0648e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2511e-05 - activation_1_loss: 3.9907e-06 - activation_2_loss: 8.5203e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.6233e-05 - val_activation_1_loss: 3.7357e-06 - val_activation_2_loss: 1.2498e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.5383e-04 - activation_1_loss: 1.2553e-04 - activation_2_loss: 1.2830e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.8082e-04 - val_activation_1_loss: 2.6654e-05 - val_activation_2_loss: 1.5416e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6625e-05 - activation_1_loss: 1.4773e-05 - activation_2_loss: 2.1852e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.3754e-05 - val_activation_1_loss: 1.9673e-05 - val_activation_2_loss: 4.0818e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6885e-05 - activation_1_loss: 2.5276e-06 - activation_2_loss: 2.4357e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1237e-04 - val_activation_1_loss: 1.3918e-06 - val_activation_2_loss: 1.1098e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6456e-05 - activation_1_loss: 8.0364e-06 - activation_2_loss: 8.4200e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1348e-05 - val_activation_1_loss: 1.7109e-06 - val_activation_2_loss: 9.6371e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6879e-05 - activation_1_loss: 9.9488e-06 - activation_2_loss: 6.9303e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.2004e-06 - val_activation_1_loss: 2.0363e-06 - val_activation_2_loss: 7.1641e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.6726e-06 - activation_1_loss: 1.8113e-06 - activation_2_loss: 7.8614e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0981e-05 - val_activation_1_loss: 1.7132e-06 - val_activation_2_loss: 9.2679e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3095e-05 - activation_1_loss: 2.2053e-06 - activation_2_loss: 1.0890e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.5756e-04 - val_activation_1_loss: 1.5722e-06 - val_activation_2_loss: 3.5599e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.6861e-05 - activation_1_loss: 1.4438e-06 - activation_2_loss: 3.5417e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.5597e-04 - val_activation_1_loss: 8.9794e-07 - val_activation_2_loss: 2.5507e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.0453e-06 - activation_1_loss: 1.2429e-06 - activation_2_loss: 4.8024e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.5458e-05 - val_activation_1_loss: 8.7947e-07 - val_activation_2_loss: 7.4578e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6935e-04 - activation_1_loss: 3.3370e-06 - activation_2_loss: 1.6602e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1503e-05 - val_activation_1_loss: 2.0937e-06 - val_activation_2_loss: 2.9410e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.0852e-04 - activation_1_loss: 3.6701e-06 - activation_2_loss: 1.0485e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 4.5108e-06 - val_activation_1_loss: 1.4064e-06 - val_activation_2_loss: 3.1045e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.2928e-04 - activation_1_loss: 8.0664e-06 - activation_2_loss: 2.2121e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 3.0167e-05 - val_activation_1_loss: 2.8879e-06 - val_activation_2_loss: 2.7279e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6140e-04 - activation_1_loss: 7.4559e-06 - activation_2_loss: 1.5395e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.4294e-05 - val_activation_1_loss: 9.7995e-06 - val_activation_2_loss: 8.4495e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.6793e-04 - activation_1_loss: 1.1026e-05 - activation_2_loss: 2.5690e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 0.0018 - val_activation_1_loss: 5.6508e-04 - val_activation_2_loss: 0.0012 - val_activation_1_acc: 0.9999 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 0.0010 - activation_1_loss: 3.5645e-04 - activation_2_loss: 6.4803e-04 - activation_1_acc: 0.9999 - activation_2_acc: 0.9999 - val_loss: 2.8134e-04 - val_activation_1_loss: 1.5561e-05 - val_activation_2_loss: 2.6578e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 0.9999\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.4553e-04 - activation_1_loss: 1.9633e-05 - activation_2_loss: 2.2589e-04 - activation_1_acc: 1.0000 - activation_2_acc: 0.9999 - val_loss: 1.0396e-04 - val_activation_1_loss: 4.7403e-06 - val_activation_2_loss: 9.9216e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 26s 3ms/step - loss: 7.8592e-05 - activation_1_loss: 3.8323e-05 - activation_2_loss: 4.0269e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.0379e-04 - val_activation_1_loss: 6.4643e-05 - val_activation_2_loss: 3.9152e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.1062e-05 - activation_1_loss: 1.9089e-05 - activation_2_loss: 4.1973e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.1353e-06 - val_activation_1_loss: 2.7614e-06 - val_activation_2_loss: 6.3738e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.8219e-05 - activation_1_loss: 5.2368e-06 - activation_2_loss: 3.2982e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 3.1049e-05 - val_activation_1_loss: 3.0493e-06 - val_activation_2_loss: 2.8000e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.0229e-05 - activation_1_loss: 4.6148e-06 - activation_2_loss: 7.5614e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 6.2679e-05 - val_activation_1_loss: 1.8237e-06 - val_activation_2_loss: 6.0856e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 9.5843e-05 - activation_1_loss: 1.6201e-05 - activation_2_loss: 7.9642e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.9351e-05 - val_activation_1_loss: 4.1324e-06 - val_activation_2_loss: 9.5219e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 3.3266e-05 - activation_1_loss: 2.2612e-06 - activation_2_loss: 3.1004e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2959e-05 - val_activation_1_loss: 1.7005e-06 - val_activation_2_loss: 1.1258e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.2195e-05 - activation_1_loss: 1.3801e-05 - activation_2_loss: 2.8393e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 9.2506e-06 - val_activation_1_loss: 1.1511e-06 - val_activation_2_loss: 8.0995e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 8.7598e-05 - activation_1_loss: 2.9747e-06 - activation_2_loss: 8.4623e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.6972e-05 - val_activation_1_loss: 3.9480e-06 - val_activation_2_loss: 2.3024e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.1731e-04 - activation_1_loss: 6.5024e-05 - activation_2_loss: 5.2291e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.1425e-06 - val_activation_1_loss: 1.3139e-06 - val_activation_2_loss: 5.8286e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.8114e-05 - activation_1_loss: 3.7947e-06 - activation_2_loss: 4.4320e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.3239e-06 - val_activation_1_loss: 1.5788e-06 - val_activation_2_loss: 6.7451e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 2.9033e-05 - activation_1_loss: 4.4142e-06 - activation_2_loss: 2.4619e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.2502e-04 - val_activation_1_loss: 9.6252e-07 - val_activation_2_loss: 1.2406e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 4.4488e-05 - activation_1_loss: 4.9341e-06 - activation_2_loss: 3.9553e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 7.3746e-06 - val_activation_1_loss: 7.8391e-07 - val_activation_2_loss: 6.5907e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.6369e-05 - activation_1_loss: 9.9894e-07 - activation_2_loss: 1.5370e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 8.9553e-06 - val_activation_1_loss: 7.6069e-07 - val_activation_2_loss: 8.1947e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.8955e-04 - activation_1_loss: 1.2970e-05 - activation_2_loss: 1.7658e-04 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 2.4635e-04 - val_activation_1_loss: 7.3548e-06 - val_activation_2_loss: 2.3900e-04 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 1.3989e-05 - activation_1_loss: 4.1720e-06 - activation_2_loss: 9.8167e-06 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 5.6229e-05 - val_activation_1_loss: 2.8199e-06 - val_activation_2_loss: 5.3409e-05 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 26s 3ms/step - loss: 6.7656e-05 - activation_1_loss: 3.2742e-06 - activation_2_loss: 6.4382e-05 - activation_1_acc: 1.0000 - activation_2_acc: 1.0000 - val_loss: 1.1202e-05 - val_activation_1_loss: 3.8478e-06 - val_activation_2_loss: 7.3543e-06 - val_activation_1_acc: 1.0000 - val_activation_2_acc: 1.0000\n",
      "10000/10000 [==============================] - 7s 699us/step\n",
      " a1 is unknown . help\n",
      " if a1 then a9 . a1 is unknown .\n",
      " a1 is false\n",
      "10000/10000 [==============================] - 7s 709us/step\n",
      "[0.000207402402167736, 3.089155576117264e-05, 0.0001765108459907424, 0.999992857170105, 0.9999678569793701]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Line below is for building new model!\n",
    "\n",
    "new_network_flag = True\n",
    "\n",
    "if new_network_flag:\n",
    "\n",
    "    test_entity = NN_Entity_1(id_number=1, gen_data_sets=True,\n",
    "                              max_data_sets=256,\n",
    "                              start_training_epoch=0,\n",
    "                              max_training_epoch=2049)\n",
    "else:\n",
    "    # Lines below are for using a pre-built model!\n",
    "\n",
    "    test_entity = NN_Entity_1(id_number=1,\n",
    "                          nn_file=\"%s/trained_model_prop_new_2048.h5\" % (DATA_PATH,),\n",
    "                          data_set_file='%s/data_set_0' % (DATA_PATH,))\n",
    "\n",
    "\n",
    "test_entity_2 = NN_Entity_1(id_number=2,\n",
    "                          nn_file=\"%s/trained_model_prop_new_2048.h5\" % (DATA_PATH,),\n",
    "                          data_set_file='%s/data_set_0' % (DATA_PATH,))\n",
    "\n",
    "# test_entity.add_knowledge(\"if a2 then a3\")\n",
    "# test_entity.add_knowledge(\"a1 is false\")\n",
    "# test_entity_2.add_knowledge(\"if a3 then a1\")\n",
    "\n",
    "test_entity.add_knowledge(\"a7 is false\")\n",
    "test_entity_2.add_knowledge(\"if a1 then a9\")\n",
    "\n",
    "# Ask first entity for value of a3.  Get its answer\n",
    "# and convert answer into format entity 2 can use.\n",
    "\n",
    "the_question = \"what is a1 ?\"\n",
    "return_dict = test_entity.ask_question_remember_answer(the_question)\n",
    "return_string = return_dict['network_answer_string2']\n",
    "print(return_string)\n",
    "\n",
    "return_sentences = return_string.split(\".\")\n",
    "\n",
    "return_list = []\n",
    "\n",
    "regex_help = re.compile(\"help\")\n",
    "\n",
    "help_flag = False # Only goes true if first entity asks for help.\n",
    "for sentence in return_sentences:\n",
    "    new_sentence = sentence.strip()\n",
    "    if regex_help.search(new_sentence) is None:\n",
    "        return_list.append(sentence)\n",
    "        test_entity_2.add_knowledge(sentence)\n",
    "    else:\n",
    "        help_flag = True\n",
    "\n",
    "# If first entity asked for help, then second entity responds with\n",
    "# dump of its own knowledge.\n",
    "\n",
    "if help_flag:\n",
    "    return_dict_2 = test_entity_2.ask_question_remember_answer(\"help\")\n",
    "\n",
    "    return_string_2 = return_dict_2['network_answer_string2']\n",
    "\n",
    "    print (return_string_2)\n",
    "\n",
    "    return_list_2 = return_string_2.split(\".\")\n",
    "\n",
    "    for sentence in return_list_2:\n",
    "\n",
    "        new_sentence = sentence.strip()\n",
    "        test_entity.add_knowledge(new_sentence)\n",
    "\n",
    "    # RE-run\n",
    "\n",
    "    new_dictionary = test_entity.ask_question_remember_answer(the_question)\n",
    "\n",
    "    new_answer = new_dictionary['network_answer_string2']\n",
    "else:\n",
    "    new_answer = None\n",
    "\n",
    "print (new_answer)\n",
    "\n",
    "evaluation_result = test_entity.test_on_data_set(0)\n",
    "\n",
    "print (evaluation_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
